\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts, bm}
\usepackage{geometry}
\usepackage{hyperref}
\geometry{margin=1in}

\title{A Multiplicative EKF with Latent OU Acceleration for Drift-Robust Wave Kinematics: \\
Theory, Discretization (Rodrigues, Van Loan, Pad\'e(6)), and Temperature-Dependent Bias Compensation}
\author{Mikhail Grushinskiy}
\date{2025}

\begin{document}
\maketitle

\begin{abstract}
We present a detailed mathematical development of a quaternion multiplicative EKF (MEKF) fused with an extended 
linear kinematic chain for ocean-wave motion estimation. 
The method augments attitude (with optional gyroscope bias) by the linear states velocity $\bm v$, displacement $\bm p$, 
and the integral of displacement $\bm S$, driven by a \emph{latent} world-frame acceleration $\bm a_w$ modeled as an Ornstein--Uhlenbeck (OU) process. 
The OU prior confers bounded variance and realistic temporal correlation, preventing the drift explosion typical of double integration of noisy accelerometer data. 
Biases are explicitly modeled: gyroscope bias as a random walk, accelerometer bias both as random walk and as systematic temperature-dependent drift. 
A pseudo-measurement is introduced on $\bm S$ to control triple integral divergence. 
We derive continuous- and discrete-time process models, show Rodrigues and Van Loan discretizations, 
explain Pad\'e(6) approximation with scaling and squaring, and derive explicit Jacobians for accelerometer and magnetometer updates. 
Finally, we discuss tuning strategies and the prospect of adaptive parameter estimation.
\end{abstract}

\section{Introduction}
Estimating wave-induced motion from an IMU is fundamentally challenging. The IMU provides angular velocity and specific force, 
but extracting displacement requires triple integration if treated naively. Biases and noise cause unbounded drift. 
Moreover, wave accelerations are not white but correlated in time, reflecting the physics of sea surface gravity waves. 
Thus, a specialized state-space formulation is required. 

The \texttt{Kalman3D\_Wave} filter is designed with these challenges in mind. 
It is a multiplicative EKF in which the quaternion is the central orientation representation, 
augmented by translational kinematics driven by a latent Ornstein--Uhlenbeck acceleration process. 
This design provides bounded variance, stability, and physical realism.

The contributions of this paper are:
\begin{itemize}
\item A rigorous derivation of the state-space model with biases and OU latent acceleration.
\item Exact and approximate discretization methods: Rodrigues, Van Loan, Pad\'e(6).
\item Explicit Jacobians for accelerometer and magnetometer updates.
\item Introduction of a pseudo-measurement on the triple integral to suppress drift.
\item Discussion of tuning and future adaptive strategies.
\end{itemize}

\section{State Definition}

We define the full augmented error-state vector as
\begin{equation}
\bm{x} =
\begin{bmatrix}
\delta\bm\theta & \bm b_g & \bm v & \bm p & \bm S & \bm a_w & \bm b_{a0}
\end{bmatrix}^\top \in \mathbb{R}^n,
\label{eq:state_vector}
\end{equation}
with the following components:
\begin{itemize}
\item $\delta\bm\theta \in \mathbb{R}^3$: the \emph{attitude error}, parameterized as a small rotation vector in the multiplicative EKF framework.
\item $\bm b_g \in \mathbb{R}^3$: the gyroscope bias, modeled as a random walk driven by white noise.
\item $\bm v \in \mathbb{R}^3$: the velocity of the sensor in the world (NED) frame.
\item $\bm p \in \mathbb{R}^3$: the displacement (position) in the world frame.
\item $\bm S \in \mathbb{R}^3$: the \emph{integral of displacement}, i.e.
  \[
  \bm S(t) = \int_0^t \bm p(\tau)\, d\tau,
  \]
  which, although not physically measured, serves as a control variable for drift suppression.
\item $\bm a_w \in \mathbb{R}^3$: the latent world-frame acceleration, modeled as an Ornstein--Uhlenbeck (OU) process to enforce bounded variance and temporal correlation.
\item $\bm b_{a0} \in \mathbb{R}^3$: the baseline accelerometer bias at a fixed reference temperature $T_\text{ref}$.
\end{itemize}

The \emph{temperature-dependent accelerometer bias model} is given by
\begin{equation}
\bm b_a(T) = \bm b_{a0} + \bm k_a \,\big(T - T_\text{ref}\big),
\label{eq:accel_bias_temp}
\end{equation}
where $\bm k_a \in \mathbb{R}^3$ is a vector of per-axis temperature coefficients. 
This accounts for the systematic drift of MEMS accelerometers with changing temperature, 
typically on the order of $0.002$--$0.005 \,\text{m/s}^2$ per ${}^\circ$C in modern sensors.

\subsection{Quaternion Representation}
The orientation of the body frame with respect to the world (NED) frame is represented by a quaternion $q \in \mathbb{H}$. 
We adopt a right-multiplicative error convention:
\begin{equation}
q^+ = q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\otimes$ denotes quaternion multiplication and
\begin{equation}
\delta q(\delta\bm\theta) \approx
\begin{bmatrix}
1 \\ \tfrac{1}{2}\delta\bm\theta
\end{bmatrix}.
\label{eq:small_angle_quaternion}
\end{equation}

\subsection{State Dimension}
The total state dimension is
\[
n =
\begin{cases}
18 & \text{if gyro and accel biases are included}, \\
15 & \text{if only gyro bias is included}, \\
12 & \text{if no biases are included}.
\end{cases}
\]
This flexible design allows the filter to adapt to the sensor suite available and to application requirements.

\section{Attitude Dynamics}

The orientation of the sensor platform is represented by a quaternion $q(t)$ mapping from the world 
(North--East--Down, NED) frame to the body frame. 
We employ the \emph{multiplicative extended Kalman filter} (MEKF) convention: 
the mean orientation is stored as a quaternion $q$, while the small attitude error 
is represented as a 3-vector $\delta\bm\theta$ living in the tangent space $\mathfrak{so}(3)$.

\subsection{Quaternion Kinematics}
The quaternion time evolution is governed by the angular velocity measured by the gyroscope:
\begin{equation}
\dot q(t) = \tfrac{1}{2} \, \Omega(\bm\omega_b(t)) \, q(t),
\label{eq:quat_kinematics}
\end{equation}
where $\bm\omega_b$ is the angular velocity in the body frame, 
and $\Omega(\bm\omega)$ is the quaternion multiplication matrix:
\begin{equation}
\Omega(\bm\omega) =
\begin{bmatrix}
0 & -\bm\omega^\top \\
\bm\omega & -[\bm\omega]_\times
\end{bmatrix}.
\end{equation}

Here $[\bm\omega]_\times$ denotes the skew-symmetric matrix such that $[\bm\omega]_\times \bm v = \bm\omega \times \bm v$.

\subsection{Error Representation}
Instead of estimating $q$ directly, the MEKF keeps track of the \emph{error quaternion}:
\begin{equation}
q = \hat q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\hat q$ is the nominal quaternion and $\delta q$ is a small correction. 
This choice ensures that the state covariance remains minimal in dimension (3 instead of 4), 
while preserving the unit norm of $q$.

\subsection{Rodrigues' Formula for Discrete Propagation}
To propagate the quaternion over a sampling interval $\Delta t$, 
we use the matrix exponential of the skew operator:
\begin{equation}
R(t+\Delta t) = R(t) \exp\!\left([\bm\omega]_\times \Delta t\right).
\label{eq:rot_exp}
\end{equation}

Rodrigues' rotation formula provides a closed form for this exponential:
\begin{equation}
\exp([\bm\omega]_\times \Delta t) = I 
+ \frac{\sin \theta}{\theta} [\bm u]_\times
+ \frac{1 - \cos \theta}{\theta^2} [\bm u]_\times^2,
\label{eq:rodrigues}
\end{equation}
where $\theta = \|\bm\omega\| \Delta t$ is the rotation angle, 
and $\bm u = \bm\omega / \|\bm\omega\|$ is the unit rotation axis.

\paragraph{Interpretation.}
Equation \eqref{eq:rodrigues} shows how the rotation matrix can be expressed 
directly in terms of the angular increment. 
For small angles, a Taylor expansion recovers the familiar linearized form:
\[
\exp([\bm\omega]_\times \Delta t) \approx I + [\bm\omega]_\times \Delta t + \tfrac{1}{2} [\bm\omega]_\times^2 \Delta t^2.
\]
This makes Rodrigues' formula both numerically stable and exact for finite rotations.

\subsection{Error-State Dynamics}
The small attitude error $\delta\bm\theta$ evolves according to
\begin{equation}
\dot{\delta\bm\theta} = -[\bm\omega_b - \bm b_g]_\times \, \delta\bm\theta - \delta\bm b_g + \bm n_\theta,
\label{eq:att_err_dyn}
\end{equation}
where $\bm b_g$ is the gyro bias and $\bm n_\theta$ is gyro measurement noise mapped into the attitude error dynamics.

Equation \eqref{eq:att_err_dyn} highlights two important points:
\begin{enumerate}
\item The gyro bias directly drives the attitude error, which motivates its inclusion in the state vector.
\item The dynamics are linear in the small error, allowing standard EKF propagation.
\end{enumerate}

\section{Ornstein--Uhlenbeck (OU) Process: Mean/Variance, Autocorrelation, Discrete-Time, and Coefficient Integrals}
\label{sec:ou-detailed}

This section develops the OU dynamics used for the latent world-frame acceleration $a(t)$
(per axis; the 3D case is component-wise identical). We give the continuous-time SDE,
solve it in closed form, derive the exact discrete-time equivalent, compute the
autocorrelation and spectrum, and then derive the integral coefficients that appear
in the discrete propagation of $(v,p,S)$.

\subsection{Two Equivalent Formulations of OU}
There are two standard ways to write the OU process.

\paragraph{(i) It\^o SDE form.}
\begin{equation}
da(t) \;=\; -\frac{1}{\tau}\,a(t)\,dt \;+\; \sqrt{\frac{2\sigma^2}{\tau}}\; dW_t,
\label{eq:ou-ito}
\end{equation}
where $\tau>0$ is the correlation time, $\sigma^2$ is the stationary variance, and $W_t$
is a standard Wiener process.

\paragraph{(ii) LTI with white process input.}
\begin{equation}
\dot a(t) \;=\; -\frac{1}{\tau}\,a(t) \;+\; w(t),\qquad
\mathbb{E}\big[w(t)w(s)\big] \;=\; \Sigma_c\,\delta(t-s),
\label{eq:ou-lti}
\end{equation}
with the white-noise \emph{power} chosen as
\begin{equation}
\Sigma_c \;=\; \frac{2}{\tau}\,\sigma^2,
\label{eq:ou-sigmapower}
\end{equation}
which makes the stationary variance of $a(t)$ equal to $\sigma^2$ (same as in \eqref{eq:ou-ito}).

Both forms are equivalent; the It\^o diffusion coefficient $\sqrt{2\sigma^2/\tau}$ corresponds to
the white-noise power $\Sigma_c = 2\sigma^2/\tau$ in the LTI description.

\subsection{Closed-Form Solution and Moments}
Solving \eqref{eq:ou-lti} with constant $\tau$ over $[t,t+\Delta]$:
\begin{equation}
a(t+\Delta) \;=\; \rho\,a(t) \;+\; \int_0^\Delta e^{-(\Delta-s)/\tau}\,w(t+s)\,ds,
\qquad
\rho \;\triangleq\; e^{-\Delta/\tau}.
\label{eq:ou-sol}
\end{equation}
Therefore,
\begin{align}
\mathbb{E}[\,a(t+\Delta)\,|\,a(t)=a_k] &= \rho\,a_k, \label{eq:ou-mean}\\
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] 
&= \int_0^\Delta\!\!\int_0^\Delta e^{-(\Delta-s)/\tau}e^{-(\Delta-u)/\tau}\,\Sigma_c\,\delta(s-u)\,ds\,du
\nonumber\\
&= \Sigma_c \int_0^\Delta e^{-2(\Delta-s)/\tau}\,ds
= \frac{\Sigma_c\tau}{2}\,\big(1-\rho^2\big).
\end{align}
Using \eqref{eq:ou-sigmapower} gives the standard result
\begin{equation}
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] \;=\; \sigma^2\big(1-\rho^2\big).
\label{eq:ou-var-step}
\end{equation}

\subsection{Autocorrelation and Spectrum}
At stationarity,
\begin{equation}
R_a(\Delta) \;\triangleq\; \mathbb{E}\big[a(t)\,a(t+\Delta)\big] \;=\; \sigma^2\,e^{-|\Delta|/\tau}.
\label{eq:ou-autocorr}
\end{equation}
The one-sided power spectral density (PSD) is the Lorentzian
\begin{equation}
S_a(\omega) \;=\; \int_{-\infty}^{\infty} R_a(\Delta)\,e^{-j\omega \Delta}\,d\Delta
\;=\; \frac{2\sigma^2\tau}{1+(\omega\tau)^2}.
\label{eq:ou-psd}
\end{equation}
Hence $\tau$ sets the correlation (and an approximate cutoff $f_c \approx (2\pi\tau)^{-1}$),
and $\sigma$ sets the RMS magnitude of $a$.

\subsection{Exact Discrete-Time Equivalent (AR(1))}
Discretizing at step $\Delta$,
\begin{equation}
a_{k+1} \;=\; \rho\,a_k \;+\; \eta_k,
\qquad
\rho \;=\; e^{-\Delta/\tau}, 
\qquad
\eta_k \sim \mathcal{N}\!\big(0,\ \sigma^2(1-\rho^2)\big),
\label{eq:ou-ar1}
\end{equation}
with $\eta_k$ independent of $a_k$. This AR(1) exactly preserves the OU mean, variance,
and autocorrelation at sampling instants.

\subsection{Integral Functionals of OU: Deterministic Coefficient Derivations}
Let $a(t)$ follow OU as above. Over one step $[t,t+\Delta]$, define the weighted
integrals needed by the kinematic chain:
\begin{equation}
I_0 \;\triangleq\; \int_0^\Delta a(t+s)\,ds,\qquad
I_1 \;\triangleq\; \int_0^\Delta (\Delta-s)\,a(t+s)\,ds,\qquad
I_2 \;\triangleq\; \int_0^\Delta \frac{(\Delta-s)^2}{2}\,a(t+s)\,ds.
\label{eq:ou-I012}
\end{equation}
Using the conditional mean $\mathbb{E}[a(t+s)\mid a(t){=}a_k]=e^{-s/\tau} a_k$,
the \emph{deterministic coefficients} multiplying $a_k$ in the discrete updates are:
\begin{align}
c_v(\Delta,\tau)
&= \int_0^\Delta e^{-s/\tau}\,ds
= \tau\big(1-e^{-\Delta/\tau}\big)
\;=\; \tau E_0, 
\label{eq:cv-ou}
\\
c_p(\Delta,\tau)
&= \int_0^\Delta (\Delta-s)\,e^{-s/\tau}\,ds
= \tau\Big(\Delta - \tau\big(1-e^{-\Delta/\tau}\big)\Big)
\;=\; \tau E_1, 
\label{eq:cp-ou}
\\
c_S(\Delta,\tau)
&= \int_0^\Delta \frac{(\Delta-s)^2}{2}\,e^{-s/\tau}\,ds
= \tau\left(\frac{\Delta^2}{2} - \tau\Delta + \tau^2\big(1-e^{-\Delta/\tau}\big)\right)
\;=\; \tau E_2.
\label{eq:cS-ou}
\end{align}
We have introduced the convenient polynomials
\begin{equation}
E_0(\Delta,\tau)=1-\rho,\qquad
E_1(\Delta,\tau)=\Delta - \tau(1-\rho),\qquad
E_2(\Delta,\tau)=\frac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho),
\label{eq:E012}
\end{equation}
with $\rho=e^{-\Delta/\tau}$. For later use (e.g., in higher-order kernels), also define
\begin{equation}
E_3(\Delta,\tau)
\;\triangleq\;
\frac{\Delta^3}{6} - \frac{\tau\Delta^2}{2} + \tau^2\Delta - \tau^3(1-\rho).
\label{eq:E3}
\end{equation}

\paragraph{Resulting exact conditional means.}
The discrete kinematic updates with OU-driven acceleration are
\begin{align}
v_{k+1} &= v_k + c_v(\Delta,\tau)\,a_k + \varepsilon_v, \label{eq:v-disc-mean}\\
p_{k+1} &= p_k + \Delta v_k + c_p(\Delta,\tau)\,a_k + \varepsilon_p, \label{eq:p-disc-mean}\\
S_{k+1} &= S_k + \Delta p_k + \frac{\Delta^2}{2} v_k + c_S(\Delta,\tau)\,a_k + \varepsilon_S, \label{eq:S-disc-mean}
\end{align}
where the zero-mean random terms $(\varepsilon_v,\varepsilon_p,\varepsilon_S)$ are jointly Gaussian and arise from the
stochastic part of $a(t+s)$ (i.e., the integral of the noise term in \eqref{eq:ou-sol} through the integrator kernels).

\subsection{Variances and Covariances of the Integrated OU Terms}
Let $R_a(\delta)=\sigma^2 e^{-|\delta|/\tau}$ be the stationary autocorrelation \eqref{eq:ou-autocorr}.
For any weights $w(s)$, $u(s)$ supported on $[0,\Delta]$,
\begin{equation}
\mathrm{Cov}\!\left[\int_0^\Delta w(s) a(t+s)\,ds,\ \int_0^\Delta u(s) a(t+s)\,ds\right]
= \int_0^\Delta\!\!\int_0^\Delta w(s)\,u(u)\,R_a(s-u)\,ds\,du.
\label{eq:kernel-cov}
\end{equation}
Using symmetry $R_a(|s-u|)=\sigma^2 e^{-|s-u|/\tau}$ and splitting the domain $0\le u\le s\le \Delta$,
\begin{align}
\mathrm{Cov}
&= 2\sigma^2 \int_0^\Delta \left(\int_0^s w(s)\,u(u)\,e^{-(s-u)/\tau}\,du\right) ds.
\label{eq:kernel-cov-2}
\end{align}
We now list the key entries needed to build the exact discrete process covariance $Q_d$
for $(v,p,S,a)$ in one step. Denote $\rho=e^{-\Delta/\tau}$, and recall \eqref{eq:E012}.

\paragraph{Single-integral variance and cross-covariance.}
With $w_0(s)=1$ and $w_1(s)=\Delta-s$,
\begin{align}
\mathrm{Var}\!\left[\int_0^\Delta a\right]
&= 2\sigma^2 \tau\,E_1,
\label{eq:var-I0}
\\
\mathrm{Cov}\!\left[\int_0^\Delta a,\ \int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\,E_2,
\label{eq:cov-I0-I1}
\\
\mathrm{Var}\!\left[\int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\left(\frac{\Delta^3}{3} - \tau\Delta^2 + 2\tau^2\Delta - 2\tau^3(1-\rho)\right).
\label{eq:var-I1}
\end{align}

\paragraph{Cross-covariances with $a_{k+1}$.}
From $\mathrm{cov}\{a(t+s),a(t+\Delta)\}=\sigma^2 e^{-(\Delta-s)/\tau}$:
\begin{align}
\mathrm{Cov}\!\left[\int_0^\Delta a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2 \tau (1-\rho)
= \sigma^2 \tau E_0,
\label{eq:cov-I0-ak1}
\\
\mathrm{Cov}\!\left[\int_0^\Delta (\Delta-s)a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2\left(\tau^2(1-\rho) - \tau\Delta\,\rho\right).
\label{eq:cov-I1-ak1}
\end{align}
(Analogous expressions for the $S$-weighted integral follow the same recipe but are longer; see the coefficient identity below.)

\paragraph{General exponential--polynomial identity.}
All required integrals reduce to the elementary identity
\begin{equation}
\int_0^\Delta s^n e^{-s/\tau} ds
= \tau^{n+1}\,n!\left(1 - e^{-\Delta/\tau}\sum_{j=0}^{n}\frac{(\Delta/\tau)^j}{j!}\right),
\qquad n=0,1,2,\dots,
\label{eq:exp-poly}
\end{equation}
together with the binomial expansion $(\Delta-s)^m=\sum_{i=0}^m \binom{m}{i}\Delta^{m-i}(-s)^i$.
Using \eqref{eq:exp-poly} yields closed forms for \emph{all} entries of $Q_d$ (including the $S$-block).

\subsection{Exact Axis Transition for $(v,p,S,a)$}
Collecting the deterministic coefficients \eqref{eq:cv-ou}--\eqref{eq:cS-ou} and the OU state update \eqref{eq:ou-ar1},
the \emph{exact} one-axis transition matrix is
\begin{equation}
\Phi_{\text{axis}}(\Delta,\tau) \;=\;
\begin{bmatrix}
1 & 0 & 0 & \tau(1-\rho)\\
0 & 1 & 0 & \tau\big(\Delta - \tau(1-\rho)\big)\\
0 & 0 & 1 & \tau\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right)\\
0 & 0 & 0 & \rho
\end{bmatrix}.
\label{eq:Phi-axis-ou}
\end{equation}
In 3D, $\Phi_{vpsa}=\Phi_{\text{axis}}\otimes I_3$.

\paragraph{Discrete process covariance $Q_d$.}
The random vector $(\varepsilon_v,\varepsilon_p,\varepsilon_S,\eta_a)$ has covariance determined by
\eqref{eq:var-I0}--\eqref{eq:var-I1}, \eqref{eq:cov-I0-ak1}--\eqref{eq:cov-I1-ak1}, and their $S$-weighted analogs
(constructed via \eqref{eq:exp-poly}). For compactness and guaranteed SPD, we also obtain $Q_d$
by the Van Loan method applied to the continuous pair $(A,G,\Sigma_c)$ (see the discretization section):
\[
Q_d \;=\; \int_0^\Delta e^{A s} G \Sigma_c G^\top e^{A^\top s} ds.
\]
Both routes are analytically equivalent; Van Loan is the numerically convenient implementation.

\subsection{Small-Step Expansions and Limiting Cases}
For $\Delta\ll\tau$ ($\rho \approx 1-\Delta/\tau$):
\begin{align}
c_v &= \tau(1-\rho) \approx \Delta - \tfrac{\Delta^2}{2\tau} + \mathcal{O}(\Delta^3),\\
c_p &= \tau\big(\Delta - \tau(1-\rho)\big) \approx \tfrac{\Delta^2}{2} - \tfrac{\Delta^3}{6\tau} + \mathcal{O}(\Delta^4),\\
c_S &= \tau\!\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right) \approx \tfrac{\Delta^3}{6} - \tfrac{\Delta^4}{24\tau} + \mathcal{O}(\Delta^5).
\end{align}
These match the deterministic integrals of a constant acceleration over small intervals.

As $\tau\to\infty$ with $\sigma^2$ fixed, $\rho\to 1$, the innovation variance $\sigma^2(1-\rho^2)\to 0$,
and $a$ becomes quasi-constant (very slow mean reversion). As $\tau\to 0$, $\rho\to 0$ and
the process approaches temporally white acceleration (with variance $\sigma^2$ at the sampling instants),
recovering the uncorrelated case.

\section{Exact Discretization of $(v,p,S,a)$ by the Van Loan Method}
\label{sec:van-loan}

This section derives the exact discrete-time pair $(\Phi,Q_d)$ for the linear OU-driven kinematic block
over one sampling period $\Delta>0$. We begin from the continuous-time linear stochastic system
\begin{equation}
\dot{\bm x}(t) \;=\; A\,\bm x(t) \;+\; G\,w(t), 
\qquad
\mathbb{E}\!\left[w(t)w(s)^\top\right] \;=\; \Sigma_c\,\delta(t-s),
\label{eq:lti-sde}
\end{equation}
with $A\in\mathbb{R}^{n\times n}$, $G\in\mathbb{R}^{n\times r}$, and constant white-noise power $\Sigma_c\succeq 0$.

\subsection{Fundamental Solution and Covariance Integral}
The exact discrete-time transition over $\Delta$ is
\begin{equation}
\bm x(t+\Delta) \;=\; \Phi\,\bm x(t) \;+\; \bm \eta,\qquad
\Phi \;=\; e^{A\Delta},\qquad
\bm\eta \sim \mathcal{N}\!\Big(0,\; Q_d \Big), 
\label{eq:phi-qd-def}
\end{equation}
where the process covariance is the \emph{Lyapunov integral}
\begin{equation}
Q_d \;=\; \int_0^\Delta e^{A s}\,G\,\Sigma_c\,G^\top\,e^{A^\top s}\,ds.
\label{eq:qd-integral}
\end{equation}
The integrand is symmetric positive semidefinite for each $s$, hence $Q_d\succeq 0$ by construction.

\subsection{Van Loan’s Block-Exponential Construction}
Direct numerical evaluation of \eqref{eq:qd-integral} is impractical. Van Loan’s method builds
both $e^{A\Delta}$ and $Q_d$ from a \emph{single} matrix exponential. Define the $2n\times 2n$ block matrix
\begin{equation}
M(\Delta) \;=\; 
\begin{bmatrix}
-\,A\Delta & G\,\Sigma_c\,G^\top\,\Delta\\[2pt]
0 & A^\top\Delta
\end{bmatrix}.
\label{eq:vanloan-M}
\end{equation}
Then
\begin{equation}
\exp\!\big(M(\Delta)\big) \;=\;
\begin{bmatrix}
M_{11} & M_{12}\\[2pt]
0 & M_{22}
\end{bmatrix},
\label{eq:vanloan-exp}
\end{equation}
and the discrete-time pair is recovered by the identities
\begin{equation}
\Phi \;=\; M_{22}^\top,\qquad
Q_d \;=\; \Phi\,M_{12}.
\label{eq:vanloan-unpack}
\end{equation}

\paragraph{Sketch of proof.}
Consider the differential equation in $s$ for the block matrix
\(
\Xi(s)=
\begin{bmatrix}
X(s) & Y(s)\\ 0 & Z(s)
\end{bmatrix}
\)
with $\dot\Xi = 
\begin{bmatrix}
- A & G\Sigma_c G^\top\\ 0 & A^\top
\end{bmatrix}\Xi$, $\Xi(0)=I$.
Solving yields $Z(s)=e^{A^\top s}$, $X(s)=e^{-As}$,
and $Y(s)=\int_0^s e^{-A(s-u)} G\Sigma_c G^\top e^{A^\top u}\,du$.
Evaluating at $s=\Delta$ and rearranging produces \eqref{eq:vanloan-unpack}.
The construction ensures $Q_d\succeq 0$ and is numerically robust when $\exp(\cdot)$ is.

\subsection{Application to the OU-Driven Chain}
For one spatial axis with state $\bm x_{\rm lin}=[v,\,p,\,S,\,a]^\top$, the continuous matrices are
\begin{equation}
A_{\rm axis} \;=\;
\begin{bmatrix}
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & -\tfrac{1}{\tau}
\end{bmatrix},
\qquad
G_{\rm axis} \;=\;
\begin{bmatrix}0\\0\\0\\1\end{bmatrix},
\qquad
\Sigma_c \;=\; \frac{2}{\tau}\,\sigma^2.
\label{eq:Aaxis-Gaxis}
\end{equation}
For 3D, use $A = A_{\rm axis}\otimes I_3$ and $G=G_{\rm axis}\otimes I_3$ with $\Sigma_c$ diagonal
($\Sigma_c = \tfrac{2}{\tau}\,\Sigma_{aw}^{\rm stat}$). The Van Loan method yields:
\begin{equation}
\Phi_{vpsa} \;=\; \Phi_{\rm axis}\otimes I_3,
\qquad
Q_{d,\;vpsa} \;=\; \big(Q_{d,\,\rm axis}\big)\otimes I_3,
\label{eq:axis-3d}
\end{equation}
where $\Phi_{\rm axis}$ is exactly \eqref{eq:Phi-axis-ou}. The covariance $Q_{d,\,\rm axis}$ equals the kernel integrals
derived in the OU section (means and key entries listed there), and is guaranteed SPD by \eqref{eq:vanloan-unpack}.

\subsection{Consistency Checks}
\paragraph{Small-step limit.} As $\Delta\to 0$, $\Phi=I+A\Delta+\mathcal{O}(\Delta^2)$ and $Q_d=G\Sigma_c G^\top\,\Delta+\mathcal{O}(\Delta^2)$.
\paragraph{Stationarity of $a$.} The last row/column of $Q_{d,\,\rm axis}$ reproduces $\mathrm{Var}(a_{k+1}-\rho a_k)=\sigma^2(1-\rho^2)$,
consistent with the AR(1) in \eqref{eq:ou-ar1}.
\paragraph{Symmetry/PSD.} By construction, $Q_d= \int_0^\Delta (\cdot)(\cdot)^\top ds$ is symmetric and PSD; Van Loan inherits this property.
\vspace{1ex}

\section{Matrix Exponential via Pad\'e(6) with Scaling and Squaring}
\label{sec:pade6}

For embedded targets, we compute $\exp(M)$ in \eqref{eq:vanloan-exp} by a \emph{Pad\'e(6)} rational approximation
with \emph{scaling and squaring}. This offers an excellent accuracy--cost tradeoff for the
small matrices encountered here ($4\times 4$ or $8\times 8$ per axis, or $24\times 24$ for 3D Van Loan).

\subsection{Pad\'e(6) Rational Approximant}
A $[6/6]$ Pad\'e approximant to $e^A$ is
\begin{equation}
e^A \;\approx\; R_6(A) \;=\; \big(V(A)-U(A)\big)^{-1}\big(V(A)+U(A)\big),
\label{eq:pade-rational}
\end{equation}
with
\begin{align}
U(A) &= A\Big(c_2 I + c_6 A^2\Big), 
\label{eq:U-def}\\
V(A) &= c_0 I + c_4 A^2 + c_6' A^4 + c_8 A^6,
\label{eq:V-def}
\end{align}
and coefficients
\begin{equation}
c_0 = 1,\qquad c_2 = \tfrac{1}{2},\qquad c_4 = \tfrac{1}{24},\qquad
c_6 = \tfrac{1}{720},\qquad c_6'=\tfrac{1}{24},\qquad c_8 = \tfrac{1}{5040}.
\label{eq:pade-coeffs}
\end{equation}
This is algebraically equivalent to writing
\(
V= I + c_4 A^2 + \tfrac{1}{5040}A^6
\)
and
\(
U= A\big(\tfrac12 I + \tfrac{1}{720}A^2\big),
\)
as used in compact implementations.

\subsection{Scaling and Squaring}
Accuracy is improved by reducing $\|A\|$ before applying $R_6$. Choose the integer $s\ge 0$ so that
\begin{equation}
\|A/2^s\|_1 \;\le\; \theta_6,
\label{eq:theta-choice}
\end{equation}
where $\theta_6$ is a practical threshold (for Pad\'e(6), $\theta_6 \approx 3$ for small matrices).
Compute the rational approximation at the scaled matrix, then square:
\begin{equation}
e^A \;\approx\; \Big(R_6(A/2^s)\Big)^{2^s}.
\label{eq:scale-square}
\end{equation}
This standard technique preserves stability and keeps polynomial degrees low.

\subsection{Why Pad\'e(6) is a Good Fit Here}
\begin{itemize}
\item The Van Loan matrix $M(\Delta)$ is small (up to $24\times 24$ in 3D) and moderately scaled for typical $\Delta$; Pad\'e(6) with a few squarings is accurate.
\item The cost is dominated by a handful of dense matrix multiplications and one linear solve with $(V-U)$, which is inexpensive at these sizes.
\item Numerical behavior is well studied; together with Joseph’s form for the covariance update and symmetrization $P\leftarrow \tfrac12(P+P^\top)$, it yields a robust pipeline.
\end{itemize}

\subsection{Cross-Check with Series and OU Coefficients}
Expanding $R_6(A)$ around $A=0$ reproduces the first $13$ terms of the Taylor series of $e^A$ (since it is a $[6/6]$ approximant),
hence the local error is $\mathcal{O}(\|A\|^{13})$. When applied to the block matrix $M(\Delta)$ in \eqref{eq:vanloan-M}, this accuracy carries to both
$\Phi$ and $Q_d$ recovered via \eqref{eq:vanloan-unpack}, matching the OU-derived coefficients $E_0,E_1,E_2$ (means) and the covariance entries
listed in the OU section up to roundoff.

\subsection{Practical Notes}
\begin{enumerate}
\item \textbf{Conditioning.} Use the matrix one-norm to choose $s$; for typical IMU sampling ($\Delta\le 0.02$\,s) and $\tau$ in $[0.5,5]$\,s,
$s\in\{0,1,2\}$ is usually sufficient.
\item \textbf{SPD Preservation.} Van Loan’s construction plus a numerically stable exponential preserves $Q_d\succeq 0$ up to roundoff; if needed, enforce symmetry by $Q_d\leftarrow \tfrac12(Q_d+Q_d^\top)$.
\item \textbf{Embedded Efficiency.} Precompute powers $A^2,A^4,A^6$ for $U,V$; reuse buffers; prefer LU solve for $(V-U)X=(V+U)$ given matrix sizes.
\end{enumerate}

\section{Sensor Bias Models and Compensation}
\label{sec:biases}

A central element in inertial navigation Kalman filters is the explicit modeling of 
\emph{sensor biases}. Without including bias states, residual integration of even tiny 
constant offsets rapidly dominates wave kinematics. In this section we justify the bias 
state design of the filter, detail their dynamics, and explain temperature compensation.

\subsection{Gyroscope Bias}
Let the gyroscope measurement be
\begin{equation}
\bm\omega_{\rm meas}(t) \;=\; \bm\omega(t) + \bm b_g(t) + \bm\eta_g(t),
\label{eq:gyro-meas}
\end{equation}
where $\bm\omega(t)$ is the true body angular velocity, $\bm b_g(t)$ is the bias,
and $\bm\eta_g(t)$ is zero-mean white noise. In the filter, $\bm b_g$ is included as
a \emph{random walk} process:
\begin{equation}
\dot{\bm b}_g(t) = w_{bg}(t),\qquad
\mathbb{E}[w_{bg}(t)w_{bg}(s)^\top] = Q_{bg}\,\delta(t-s).
\label{eq:gyro-bias-model}
\end{equation}
This is the simplest effective choice: gyroscope biases drift slowly with temperature, vibration,
and time, and a random walk captures unmodeled bias variation while allowing the filter to absorb
constant offsets. The discrete process covariance for $\bm b_g$ is
\begin{equation}
Q_{bg,d} = Q_{bg}\,\Delta,
\label{eq:gyro-bias-qd}
\end{equation}
consistent with the implementation in the extended process covariance $Q_a$.

\subsection{Accelerometer Bias with Temperature Drift}
Accelerometer measurement model:
\begin{equation}
\bm f_{\rm meas}(t) = \bm f_b(t) + \bm b_a(t,T) + \bm\eta_a(t),
\label{eq:acc-meas}
\end{equation}
where $\bm f_b=R_{wb}(a_w-g)$ is the specific force predicted from states, and 
$\bm b_a(t,T)$ is the bias dependent on both slow random drift and \emph{temperature} $T$.

\paragraph{Nominal bias.}
We model the bias at a reference temperature $T_0$ as a state $\bm b_{a0}(t)$,
propagated as a random walk:
\begin{equation}
\dot{\bm b}_{a0}(t) = w_{ba}(t),\qquad
\mathrm{Cov}[w_{ba}] = Q_{ba}.
\label{eq:acc-bias-base}
\end{equation}

\paragraph{Temperature coefficient.}
Empirically, MEMS accelerometers exhibit nearly linear bias variation with temperature.
Thus we extend the bias model as
\begin{equation}
\bm b_a(t,T) = \bm b_{a0}(t) + K_a\,(T-T_0),
\label{eq:acc-bias-temp}
\end{equation}
where $K_a=\mathrm{diag}(k_x,k_y,k_z)$ is a diagonal matrix of temperature coefficients
in units of $[\mathrm{m/s^2}/^\circ\mathrm{C}]$.

\paragraph{Filter incorporation.}
In measurement prediction, \eqref{eq:acc-bias-temp} adds to the predicted force. During
filter updates, the Jacobian wrt the bias state is identity, while the temperature term
acts as a known deterministic offset. Explicit modeling prevents spurious innovation
terms whenever the platform warms or cools.

\subsection{Summary of Bias Roles}
\begin{itemize}
\item \textbf{Gyroscope bias:} modeled as random walk, essential for avoiding long-term
drift in integrated orientation.
\item \textbf{Accelerometer bias:} modeled as random walk plus linear temperature
dependence, essential for consistent specific force innovations and preventing systematic
tilt misestimation.
\item \textbf{Covariances $Q_{bg},Q_{ba}$:} tuning these governs how fast the filter
is willing to adapt biases; too small values cause long convergence times, too large values
inject excess noise.
\end{itemize}
The chosen model balances computational simplicity with sufficient realism for IMU-grade
sensors such as BMI270 and BMM150.


\section{Pseudo-Measurement on the Third Integral}
\label{sec:pseudo-S}

A unique element of this filter is the inclusion of the third integral state
\[
S(t) \;=\; \int_0^t p(\tau)\,d\tau,
\]
where $p(t)$ is the displacement in world coordinates.
This integral accumulates position over time and thus represents a 
\emph{triple integration} of acceleration. Without regularization, $S(t)$
would be dominated by low-frequency drift and quickly diverge.

\subsection{Why Include $S$ at All?}
One might ask why include $S$ when displacement $p$ already contains drift.
The answer lies in the structure of stochastic processes: by explicitly modeling
$S$, we can apply a pseudo-measurement that constrains the lowest-frequency drift
mode of the integrator chain. This prevents the covariance from exploding in the
null space of repeated integration.

\subsection{Zero Pseudo-Measurement}
The pseudo-measurement enforces the soft constraint
\begin{equation}
z_S = 0 \;\;\approx\;\; H_S\,x + \nu_S,
\label{eq:ps-meas}
\end{equation}
where $H_S$ selects the $S$ block of the state vector, and $\nu_S\sim\mathcal{N}(0,R_S)$
is fictitious Gaussian noise. In implementation:
\begin{equation}
H_S = \begin{bmatrix}0 & \cdots & I_3 & \cdots & 0\end{bmatrix},
\qquad
R_S = \mathrm{diag}(\sigma_{S,x}^2,\,\sigma_{S,y}^2,\,\sigma_{S,z}^2).
\label{eq:ps-HR}
\end{equation}

\subsection{Kalman Update}
The innovation for the pseudo-measurement is simply
\begin{equation}
\tilde y = -S_k,
\end{equation}
since the measurement is identically zero. The Kalman gain is
\begin{equation}
K_S = P H_S^\top (H_S P H_S^\top + R_S)^{-1},
\end{equation}
and the update is
\begin{align}
x^+ &= x + K_S\tilde y,\\
P^+ &= (I-K_SH_S)P(I-K_SH_S)^\top + K_SR_SK_S^\top.
\end{align}
Thus $S$ is softly driven toward zero, and its covariance is bounded.

\subsection{Interpretation of $R_S$}
The choice of $R_S$ is critical. A small $R_S$ enforces a tight pseudo-measurement,
essentially pinning $S\approx 0$ and aggressively damping drift. A large $R_S$ relaxes
the constraint, letting $S$ wander but still preventing unbounded variance growth.

Physically, $S$ has no direct observable meaning (it is an auxiliary integral).
Therefore, $R_S$ does not correspond to sensor noise, but rather to a 
\emph{design knob}:
\begin{itemize}
\item If the application tolerates only bounded displacements (e.g.\ buoy motion limited
by mooring), use smaller $R_S$.
\item If slow drift is acceptable, increase $R_S$ to reduce artificial feedback.
\end{itemize}

\subsection{Effect on Stability}
By including $S$ and its pseudo-measurement, we guarantee that the extended covariance $P$
does not develop an uncontrollable growth mode. In linear systems terminology, the augmented
system becomes \emph{detectable}: even though $S$ is unobservable in a strict sense, the 
pseudo-measurement provides an artificial observation that stabilizes the filter numerics.

\paragraph{Key insight.} 
The $S$ pseudo-measurement is not “cheating,” but rather a principled
regularization. It adds just enough fictitious information to ensure 
bounded variance in triple integrals of noisy acceleration, 
while leaving physically observable states ($q,v,p,a_w$) unbiased.

\section{Measurement Models: Accelerometer and Magnetometer}
\label{sec:meas-models}

The filter fuses inertial and magnetic measurements to anchor attitude and
linear states. Here we derive the measurement functions and their Jacobians.

\subsection{Accelerometer Measurement Model}
The accelerometer provides the specific force in the body frame:
\begin{equation}
\bm f_{\rm meas} 
= R_{wb}\,\big(\bm a_w - \bm g\big) + \bm b_a(T) + \bm\eta_a,
\label{eq:accel-meas}
\end{equation}
where
\begin{itemize}
\item $R_{wb}$ is the world-to-body rotation,
\item $\bm a_w$ is the latent world-frame acceleration (OU state),
\item $\bm g = (0,0,g)$ is gravity in NED coordinates,
\item $\bm b_a(T)$ is the accelerometer bias with temperature drift,
\item $\bm\eta_a \sim \mathcal{N}(0,R_a)$ is zero-mean measurement noise.
\end{itemize}

\paragraph{Role.}
At rest, \eqref{eq:accel-meas} reduces to $\bm f_{\rm meas} \approx R_{wb}\,(-\bm g)$,
which gives roll and pitch observability. During motion, $\bm a_w$ separates wave-induced
accelerations from gravity, preventing tilt corruption.

\subsection{Accelerometer Jacobians}
The innovation function is
\[
\bm y_a = \bm f_{\rm meas} - \hat{\bm f}_b,
\qquad
\hat{\bm f}_b = R_{wb}(\hat{\bm a}_w - \bm g) + \hat{\bm b}_a(T).
\]
Linearizing yields Jacobians:
\begin{align}
\frac{\partial \hat{\bm f}_b}{\partial \delta\bm\theta} &= -\,[\hat{\bm f}_b]_\times,
\label{eq:accel-jac-att}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm a_w} &= R_{wb},
\label{eq:accel-jac-aw}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm b_a} &= I_3,
\label{eq:accel-jac-bias}
\end{align}
where $\delta\bm\theta$ is the small-angle error and $[\cdot]_\times$ is the skew-symmetric matrix.

\subsection{Magnetometer Measurement Model}
The magnetometer senses the geomagnetic field in the body frame:
\begin{equation}
\bm m_{\rm meas} = R_{wb}\,\bm B_w + \bm\eta_m,
\label{eq:mag-meas}
\end{equation}
where $\bm B_w$ is the known reference magnetic field in the world frame,
and $\bm\eta_m \sim \mathcal{N}(0,R_m)$ is measurement noise.

\paragraph{Role.}
The magnetometer provides yaw observability. By choosing $\bm B_w$ appropriately:
\begin{itemize}
\item Use the full geomagnetic vector for full 3D correction,
\item Use the horizontal projection $(B_N,B_E,0)$ for yaw-only correction.
\end{itemize}

\subsection{Magnetometer Jacobians}
Predicted measurement:
\[
\hat{\bm m}_b = R_{wb}\bm B_w.
\]
Linearization:
\begin{equation}
\frac{\partial \hat{\bm m}_b}{\partial \delta\bm\theta} = -\,[\hat{\bm m}_b]_\times.
\label{eq:mag-jac-att}
\end{equation}
No other state appears in \eqref{eq:mag-meas}, so all other Jacobians are zero.

\subsection{Combined Measurement Vector}
The full measurement vector is
\[
\bm y = \begin{bmatrix}\bm f_{\rm meas}\\ \bm m_{\rm meas}\end{bmatrix},
\qquad
\hat{\bm y} = \begin{bmatrix}\hat{\bm f}_b\\ \hat{\bm m}_b\end{bmatrix},
\]
with innovation covariance
\begin{equation}
S = C P C^\top + R,
\qquad
R = \begin{bmatrix} R_a & 0 \\ 0 & R_m \end{bmatrix},
\label{eq:meas-cov}
\end{equation}
where $C$ is the stacked Jacobian from \eqref{eq:accel-jac-att}--\eqref{eq:accel-jac-bias} and \eqref{eq:mag-jac-att}.

\subsection{Physical Interpretation}
\begin{itemize}
\item The accelerometer primarily constrains roll and pitch, while respecting wave accelerations
through $\bm a_w$.
\item The magnetometer anchors yaw against drift, with flexibility to restrict to yaw-only updates.
\item Together they ensure full 3D attitude observability.
\item Inclusion of $\bm b_a(T)$ makes the innovations insensitive to slow sensor thermal drift.
\end{itemize}


