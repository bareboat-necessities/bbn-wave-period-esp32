\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts, bm}
\usepackage{geometry}
\usepackage{hyperref}
\geometry{margin=1in}

\title{A Multiplicative EKF with Latent OU Acceleration for Drift-Robust Wave Kinematics: \\
Theory, Discretization (Rodrigues, Van Loan, Pad\'e(6)), and Temperature-Dependent Bias Compensation}
\author{Mikhail Grushinskiy}
\date{2025}

\begin{document}
\maketitle

\begin{abstract}
We present a detailed mathematical development of a quaternion multiplicative EKF (MEKF) fused with an extended 
linear kinematic chain for ocean-wave motion estimation. 
The method augments attitude (with optional gyroscope bias) by the linear states velocity $\bm v$, displacement $\bm p$, 
and the integral of displacement $\bm S$, driven by a \emph{latent} world-frame acceleration $\bm a_w$ modeled as an Ornstein--Uhlenbeck (OU) process. 
The OU prior confers bounded variance and realistic temporal correlation, preventing the drift explosion typical of double integration of noisy accelerometer data. 
Biases are explicitly modeled: gyroscope bias as a random walk, accelerometer bias both as random walk and as systematic temperature-dependent drift. 
A pseudo-measurement is introduced on $\bm S$ to control triple integral divergence. 
We derive continuous- and discrete-time process models, show Rodrigues and Van Loan discretizations, 
explain Pad\'e(6) approximation with scaling and squaring, and derive explicit Jacobians for accelerometer and magnetometer updates. 
Finally, we discuss tuning strategies and the prospect of adaptive parameter estimation.
\end{abstract}

\section{Introduction}
Estimating wave-induced motion from an IMU is fundamentally challenging. The IMU provides angular velocity and specific force, 
but extracting displacement requires triple integration if treated naively. Biases and noise cause unbounded drift. 
Moreover, wave accelerations are not white but correlated in time, reflecting the physics of sea surface gravity waves. 
Thus, a specialized state-space formulation is required. 

The \texttt{Kalman3D\_Wave} filter is designed with these challenges in mind. 
It is a multiplicative EKF in which the quaternion is the central orientation representation, 
augmented by translational kinematics driven by a latent Ornstein--Uhlenbeck acceleration process. 
This design provides bounded variance, stability, and physical realism.

The contributions of this paper are:
\begin{itemize}
\item A rigorous derivation of the state-space model with biases and OU latent acceleration.
\item Exact and approximate discretization methods: Rodrigues, Van Loan, Pad\'e(6).
\item Explicit Jacobians for accelerometer and magnetometer updates.
\item Introduction of a pseudo-measurement on the triple integral to suppress drift.
\item Discussion of tuning and future adaptive strategies.
\end{itemize}

\section{State Definition}

We define the full augmented error-state vector as
\begin{equation}
\bm{x} =
\begin{bmatrix}
\delta\bm\theta & \bm b_g & \bm v & \bm p & \bm S & \bm a_w & \bm b_{a0}
\end{bmatrix}^\top \in \mathbb{R}^n,
\label{eq:state_vector}
\end{equation}
with the following components:
\begin{itemize}
\item $\delta\bm\theta \in \mathbb{R}^3$: the \emph{attitude error}, parameterized as a small rotation vector in the multiplicative EKF framework.
\item $\bm b_g \in \mathbb{R}^3$: the gyroscope bias, modeled as a random walk driven by white noise.
\item $\bm v \in \mathbb{R}^3$: the velocity of the sensor in the world (NED) frame.
\item $\bm p \in \mathbb{R}^3$: the displacement (position) in the world frame.
\item $\bm S \in \mathbb{R}^3$: the \emph{integral of displacement}, i.e.
  \[
  \bm S(t) = \int_0^t \bm p(\tau)\, d\tau,
  \]
  which, although not physically measured, serves as a control variable for drift suppression.
\item $\bm a_w \in \mathbb{R}^3$: the latent world-frame acceleration, modeled as an Ornstein--Uhlenbeck (OU) process to enforce bounded variance and temporal correlation.
\item $\bm b_{a0} \in \mathbb{R}^3$: the baseline accelerometer bias at a fixed reference temperature $T_\text{ref}$.
\end{itemize}

The \emph{temperature-dependent accelerometer bias model} is given by
\begin{equation}
\bm b_a(T) = \bm b_{a0} + \bm k_a \,\big(T - T_\text{ref}\big),
\label{eq:accel_bias_temp}
\end{equation}
where $\bm k_a \in \mathbb{R}^3$ is a vector of per-axis temperature coefficients. 
This accounts for the systematic drift of MEMS accelerometers with changing temperature, 
typically on the order of $0.002$--$0.005 \,\text{m/s}^2$ per ${}^\circ$C in modern sensors.

\subsection{Quaternion Representation}
The orientation of the body frame with respect to the world (NED) frame is represented by a quaternion $q \in \mathbb{H}$. 
We adopt a right-multiplicative error convention:
\begin{equation}
q^+ = q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\otimes$ denotes quaternion multiplication and
\begin{equation}
\delta q(\delta\bm\theta) \approx
\begin{bmatrix}
1 \\ \tfrac{1}{2}\delta\bm\theta
\end{bmatrix}.
\label{eq:small_angle_quaternion}
\end{equation}

\subsection{State Dimension}
The total state dimension is
\[
n =
\begin{cases}
18 & \text{if gyro and accel biases are included}, \\
15 & \text{if only gyro bias is included}, \\
12 & \text{if no biases are included}.
\end{cases}
\]
This flexible design allows the filter to adapt to the sensor suite available and to application requirements.

\section{Attitude Dynamics}

The orientation of the sensor platform is represented by a quaternion $q(t)$ mapping from the world 
(North--East--Down, NED) frame to the body frame. 
We employ the \emph{multiplicative extended Kalman filter} (MEKF) convention: 
the mean orientation is stored as a quaternion $q$, while the small attitude error 
is represented as a 3-vector $\delta\bm\theta$ living in the tangent space $\mathfrak{so}(3)$.

\subsection{Quaternion Kinematics}
The quaternion time evolution is governed by the angular velocity measured by the gyroscope:
\begin{equation}
\dot q(t) = \tfrac{1}{2} \, \Omega(\bm\omega_b(t)) \, q(t),
\label{eq:quat_kinematics}
\end{equation}
where $\bm\omega_b$ is the angular velocity in the body frame, 
and $\Omega(\bm\omega)$ is the quaternion multiplication matrix:
\begin{equation}
\Omega(\bm\omega) =
\begin{bmatrix}
0 & -\bm\omega^\top \\
\bm\omega & -[\bm\omega]_\times
\end{bmatrix}.
\end{equation}

Here $[\bm\omega]_\times$ denotes the skew-symmetric matrix such that $[\bm\omega]_\times \bm v = \bm\omega \times \bm v$.

\subsection{Error Representation}
Instead of estimating $q$ directly, the MEKF keeps track of the \emph{error quaternion}:
\begin{equation}
q = \hat q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\hat q$ is the nominal quaternion and $\delta q$ is a small correction. 
This choice ensures that the state covariance remains minimal in dimension (3 instead of 4), 
while preserving the unit norm of $q$.

\subsection{Rodrigues' Formula for Discrete Propagation}
To propagate the quaternion over a sampling interval $\Delta t$, 
we use the matrix exponential of the skew operator:
\begin{equation}
R(t+\Delta t) = R(t) \exp\!\left([\bm\omega]_\times \Delta t\right).
\label{eq:rot_exp}
\end{equation}

Rodrigues' rotation formula provides a closed form for this exponential:
\begin{equation}
\exp([\bm\omega]_\times \Delta t) = I 
+ \frac{\sin \theta}{\theta} [\bm u]_\times
+ \frac{1 - \cos \theta}{\theta^2} [\bm u]_\times^2,
\label{eq:rodrigues}
\end{equation}
where $\theta = \|\bm\omega\| \Delta t$ is the rotation angle, 
and $\bm u = \bm\omega / \|\bm\omega\|$ is the unit rotation axis.

\paragraph{Interpretation.}
Equation \eqref{eq:rodrigues} shows how the rotation matrix can be expressed 
directly in terms of the angular increment. 
For small angles, a Taylor expansion recovers the familiar linearized form:
\[
\exp([\bm\omega]_\times \Delta t) \approx I + [\bm\omega]_\times \Delta t + \tfrac{1}{2} [\bm\omega]_\times^2 \Delta t^2.
\]
This makes Rodrigues' formula both numerically stable and exact for finite rotations.

\subsection{Error-State Dynamics}
The small attitude error $\delta\bm\theta$ evolves according to
\begin{equation}
\dot{\delta\bm\theta} = -[\bm\omega_b - \bm b_g]_\times \, \delta\bm\theta - \delta\bm b_g + \bm n_\theta,
\label{eq:att_err_dyn}
\end{equation}
where $\bm b_g$ is the gyro bias and $\bm n_\theta$ is gyro measurement noise mapped into the attitude error dynamics.

Equation \eqref{eq:att_err_dyn} highlights two important points:
\begin{enumerate}
\item The gyro bias directly drives the attitude error, which motivates its inclusion in the state vector.
\item The dynamics are linear in the small error, allowing standard EKF propagation.
\end{enumerate}

\section{Ornstein--Uhlenbeck (OU) Process: Mean/Variance, Autocorrelation, Discrete-Time, and Coefficient Integrals}
\label{sec:ou-detailed}

This section develops the OU dynamics used for the latent world-frame acceleration $a(t)$
(per axis; the 3D case is component-wise identical). We give the continuous-time SDE,
solve it in closed form, derive the exact discrete-time equivalent, compute the
autocorrelation and spectrum, and then derive the integral coefficients that appear
in the discrete propagation of $(v,p,S)$.

\subsection{Two Equivalent Formulations of OU}
There are two standard ways to write the OU process.

\paragraph{(i) It\^o SDE form.}
\begin{equation}
da(t) \;=\; -\frac{1}{\tau}\,a(t)\,dt \;+\; \sqrt{\frac{2\sigma^2}{\tau}}\; dW_t,
\label{eq:ou-ito}
\end{equation}
where $\tau>0$ is the correlation time, $\sigma^2$ is the stationary variance, and $W_t$
is a standard Wiener process.

\paragraph{(ii) LTI with white process input.}
\begin{equation}
\dot a(t) \;=\; -\frac{1}{\tau}\,a(t) \;+\; w(t),\qquad
\mathbb{E}\big[w(t)w(s)\big] \;=\; \Sigma_c\,\delta(t-s),
\label{eq:ou-lti}
\end{equation}
with the white-noise \emph{power} chosen as
\begin{equation}
\Sigma_c \;=\; \frac{2}{\tau}\,\sigma^2,
\label{eq:ou-sigmapower}
\end{equation}
which makes the stationary variance of $a(t)$ equal to $\sigma^2$ (same as in \eqref{eq:ou-ito}).

Both forms are equivalent; the It\^o diffusion coefficient $\sqrt{2\sigma^2/\tau}$ corresponds to
the white-noise power $\Sigma_c = 2\sigma^2/\tau$ in the LTI description.

\subsection{Closed-Form Solution and Moments}
Solving \eqref{eq:ou-lti} with constant $\tau$ over $[t,t+\Delta]$:
\begin{equation}
a(t+\Delta) \;=\; \rho\,a(t) \;+\; \int_0^\Delta e^{-(\Delta-s)/\tau}\,w(t+s)\,ds,
\qquad
\rho \;\triangleq\; e^{-\Delta/\tau}.
\label{eq:ou-sol}
\end{equation}
Therefore,
\begin{align}
\mathbb{E}[\,a(t+\Delta)\,|\,a(t)=a_k] &= \rho\,a_k, \label{eq:ou-mean}\\
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] 
&= \int_0^\Delta\!\!\int_0^\Delta e^{-(\Delta-s)/\tau}e^{-(\Delta-u)/\tau}\,\Sigma_c\,\delta(s-u)\,ds\,du
\nonumber\\
&= \Sigma_c \int_0^\Delta e^{-2(\Delta-s)/\tau}\,ds
= \frac{\Sigma_c\tau}{2}\,\big(1-\rho^2\big).
\end{align}
Using \eqref{eq:ou-sigmapower} gives the standard result
\begin{equation}
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] \;=\; \sigma^2\big(1-\rho^2\big).
\label{eq:ou-var-step}
\end{equation}

\subsection{Autocorrelation and Spectrum}
At stationarity,
\begin{equation}
R_a(\Delta) \;\triangleq\; \mathbb{E}\big[a(t)\,a(t+\Delta)\big] \;=\; \sigma^2\,e^{-|\Delta|/\tau}.
\label{eq:ou-autocorr}
\end{equation}
The one-sided power spectral density (PSD) is the Lorentzian
\begin{equation}
S_a(\omega) \;=\; \int_{-\infty}^{\infty} R_a(\Delta)\,e^{-j\omega \Delta}\,d\Delta
\;=\; \frac{2\sigma^2\tau}{1+(\omega\tau)^2}.
\label{eq:ou-psd}
\end{equation}
Hence $\tau$ sets the correlation (and an approximate cutoff $f_c \approx (2\pi\tau)^{-1}$),
and $\sigma$ sets the RMS magnitude of $a$.

\subsection{Exact Discrete-Time Equivalent (AR(1))}
Discretizing at step $\Delta$,
\begin{equation}
a_{k+1} \;=\; \rho\,a_k \;+\; \eta_k,
\qquad
\rho \;=\; e^{-\Delta/\tau}, 
\qquad
\eta_k \sim \mathcal{N}\!\big(0,\ \sigma^2(1-\rho^2)\big),
\label{eq:ou-ar1}
\end{equation}
with $\eta_k$ independent of $a_k$. This AR(1) exactly preserves the OU mean, variance,
and autocorrelation at sampling instants.

\subsection{Integral Functionals of OU: Deterministic Coefficient Derivations}
Let $a(t)$ follow OU as above. Over one step $[t,t+\Delta]$, define the weighted
integrals needed by the kinematic chain:
\begin{equation}
I_0 \;\triangleq\; \int_0^\Delta a(t+s)\,ds,\qquad
I_1 \;\triangleq\; \int_0^\Delta (\Delta-s)\,a(t+s)\,ds,\qquad
I_2 \;\triangleq\; \int_0^\Delta \frac{(\Delta-s)^2}{2}\,a(t+s)\,ds.
\label{eq:ou-I012}
\end{equation}
Using the conditional mean $\mathbb{E}[a(t+s)\mid a(t){=}a_k]=e^{-s/\tau} a_k$,
the \emph{deterministic coefficients} multiplying $a_k$ in the discrete updates are:
\begin{align}
c_v(\Delta,\tau)
&= \int_0^\Delta e^{-s/\tau}\,ds
= \tau\big(1-e^{-\Delta/\tau}\big)
\;=\; \tau E_0, 
\label{eq:cv-ou}
\\
c_p(\Delta,\tau)
&= \int_0^\Delta (\Delta-s)\,e^{-s/\tau}\,ds
= \tau\Big(\Delta - \tau\big(1-e^{-\Delta/\tau}\big)\Big)
\;=\; \tau E_1, 
\label{eq:cp-ou}
\\
c_S(\Delta,\tau)
&= \int_0^\Delta \frac{(\Delta-s)^2}{2}\,e^{-s/\tau}\,ds
= \tau\left(\frac{\Delta^2}{2} - \tau\Delta + \tau^2\big(1-e^{-\Delta/\tau}\big)\right)
\;=\; \tau E_2.
\label{eq:cS-ou}
\end{align}
We have introduced the convenient polynomials
\begin{equation}
E_0(\Delta,\tau)=1-\rho,\qquad
E_1(\Delta,\tau)=\Delta - \tau(1-\rho),\qquad
E_2(\Delta,\tau)=\frac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho),
\label{eq:E012}
\end{equation}
with $\rho=e^{-\Delta/\tau}$. For later use (e.g., in higher-order kernels), also define
\begin{equation}
E_3(\Delta,\tau)
\;\triangleq\;
\frac{\Delta^3}{6} - \frac{\tau\Delta^2}{2} + \tau^2\Delta - \tau^3(1-\rho).
\label{eq:E3}
\end{equation}

\paragraph{Resulting exact conditional means.}
The discrete kinematic updates with OU-driven acceleration are
\begin{align}
v_{k+1} &= v_k + c_v(\Delta,\tau)\,a_k + \varepsilon_v, \label{eq:v-disc-mean}\\
p_{k+1} &= p_k + \Delta v_k + c_p(\Delta,\tau)\,a_k + \varepsilon_p, \label{eq:p-disc-mean}\\
S_{k+1} &= S_k + \Delta p_k + \frac{\Delta^2}{2} v_k + c_S(\Delta,\tau)\,a_k + \varepsilon_S, \label{eq:S-disc-mean}
\end{align}
where the zero-mean random terms $(\varepsilon_v,\varepsilon_p,\varepsilon_S)$ are jointly Gaussian and arise from the
stochastic part of $a(t+s)$ (i.e., the integral of the noise term in \eqref{eq:ou-sol} through the integrator kernels).

\subsection{Variances and Covariances of the Integrated OU Terms}
Let $R_a(\delta)=\sigma^2 e^{-|\delta|/\tau}$ be the stationary autocorrelation \eqref{eq:ou-autocorr}.
For any weights $w(s)$, $u(s)$ supported on $[0,\Delta]$,
\begin{equation}
\mathrm{Cov}\!\left[\int_0^\Delta w(s) a(t+s)\,ds,\ \int_0^\Delta u(s) a(t+s)\,ds\right]
= \int_0^\Delta\!\!\int_0^\Delta w(s)\,u(u)\,R_a(s-u)\,ds\,du.
\label{eq:kernel-cov}
\end{equation}
Using symmetry $R_a(|s-u|)=\sigma^2 e^{-|s-u|/\tau}$ and splitting the domain $0\le u\le s\le \Delta$,
\begin{align}
\mathrm{Cov}
&= 2\sigma^2 \int_0^\Delta \left(\int_0^s w(s)\,u(u)\,e^{-(s-u)/\tau}\,du\right) ds.
\label{eq:kernel-cov-2}
\end{align}
We now list the key entries needed to build the exact discrete process covariance $Q_d$
for $(v,p,S,a)$ in one step. Denote $\rho=e^{-\Delta/\tau}$, and recall \eqref{eq:E012}.

\paragraph{Single-integral variance and cross-covariance.}
With $w_0(s)=1$ and $w_1(s)=\Delta-s$,
\begin{align}
\mathrm{Var}\!\left[\int_0^\Delta a\right]
&= 2\sigma^2 \tau\,E_1,
\label{eq:var-I0}
\\
\mathrm{Cov}\!\left[\int_0^\Delta a,\ \int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\,E_2,
\label{eq:cov-I0-I1}
\\
\mathrm{Var}\!\left[\int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\left(\frac{\Delta^3}{3} - \tau\Delta^2 + 2\tau^2\Delta - 2\tau^3(1-\rho)\right).
\label{eq:var-I1}
\end{align}

\paragraph{Cross-covariances with $a_{k+1}$.}
From $\mathrm{cov}\{a(t+s),a(t+\Delta)\}=\sigma^2 e^{-(\Delta-s)/\tau}$:
\begin{align}
\mathrm{Cov}\!\left[\int_0^\Delta a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2 \tau (1-\rho)
= \sigma^2 \tau E_0,
\label{eq:cov-I0-ak1}
\\
\mathrm{Cov}\!\left[\int_0^\Delta (\Delta-s)a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2\left(\tau^2(1-\rho) - \tau\Delta\,\rho\right).
\label{eq:cov-I1-ak1}
\end{align}
(Analogous expressions for the $S$-weighted integral follow the same recipe but are longer; see the coefficient identity below.)

\paragraph{General exponential--polynomial identity.}
All required integrals reduce to the elementary identity
\begin{equation}
\int_0^\Delta s^n e^{-s/\tau} ds
= \tau^{n+1}\,n!\left(1 - e^{-\Delta/\tau}\sum_{j=0}^{n}\frac{(\Delta/\tau)^j}{j!}\right),
\qquad n=0,1,2,\dots,
\label{eq:exp-poly}
\end{equation}
together with the binomial expansion $(\Delta-s)^m=\sum_{i=0}^m \binom{m}{i}\Delta^{m-i}(-s)^i$.
Using \eqref{eq:exp-poly} yields closed forms for \emph{all} entries of $Q_d$ (including the $S$-block).

\subsection{Exact Axis Transition for $(v,p,S,a)$}
Collecting the deterministic coefficients \eqref{eq:cv-ou}--\eqref{eq:cS-ou} and the OU state update \eqref{eq:ou-ar1},
the \emph{exact} one-axis transition matrix is
\begin{equation}
\Phi_{\text{axis}}(\Delta,\tau) \;=\;
\begin{bmatrix}
1 & 0 & 0 & \tau(1-\rho)\\
0 & 1 & 0 & \tau\big(\Delta - \tau(1-\rho)\big)\\
0 & 0 & 1 & \tau\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right)\\
0 & 0 & 0 & \rho
\end{bmatrix}.
\label{eq:Phi-axis-ou}
\end{equation}
In 3D, $\Phi_{vpsa}=\Phi_{\text{axis}}\otimes I_3$.

\paragraph{Discrete process covariance $Q_d$.}
The random vector $(\varepsilon_v,\varepsilon_p,\varepsilon_S,\eta_a)$ has covariance determined by
\eqref{eq:var-I0}--\eqref{eq:var-I1}, \eqref{eq:cov-I0-ak1}--\eqref{eq:cov-I1-ak1}, and their $S$-weighted analogs
(constructed via \eqref{eq:exp-poly}). For compactness and guaranteed SPD, we also obtain $Q_d$
by the Van Loan method applied to the continuous pair $(A,G,\Sigma_c)$ (see the discretization section):
\[
Q_d \;=\; \int_0^\Delta e^{A s} G \Sigma_c G^\top e^{A^\top s} ds.
\]
Both routes are analytically equivalent; Van Loan is the numerically convenient implementation.

\subsection{Small-Step Expansions and Limiting Cases}
For $\Delta\ll\tau$ ($\rho \approx 1-\Delta/\tau$):
\begin{align}
c_v &= \tau(1-\rho) \approx \Delta - \tfrac{\Delta^2}{2\tau} + \mathcal{O}(\Delta^3),\\
c_p &= \tau\big(\Delta - \tau(1-\rho)\big) \approx \tfrac{\Delta^2}{2} - \tfrac{\Delta^3}{6\tau} + \mathcal{O}(\Delta^4),\\
c_S &= \tau\!\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right) \approx \tfrac{\Delta^3}{6} - \tfrac{\Delta^4}{24\tau} + \mathcal{O}(\Delta^5).
\end{align}
These match the deterministic integrals of a constant acceleration over small intervals.

As $\tau\to\infty$ with $\sigma^2$ fixed, $\rho\to 1$, the innovation variance $\sigma^2(1-\rho^2)\to 0$,
and $a$ becomes quasi-constant (very slow mean reversion). As $\tau\to 0$, $\rho\to 0$ and
the process approaches temporally white acceleration (with variance $\sigma^2$ at the sampling instants),
recovering the uncorrelated case.

\section{Exact Discretization of $(v,p,S,a)$ by the Van Loan Method}
\label{sec:van-loan}

This section derives the exact discrete-time pair $(\Phi,Q_d)$ for the linear OU-driven kinematic block
over one sampling period $\Delta>0$. We begin from the continuous-time linear stochastic system
\begin{equation}
\dot{\bm x}(t) \;=\; A\,\bm x(t) \;+\; G\,w(t), 
\qquad
\mathbb{E}\!\left[w(t)w(s)^\top\right] \;=\; \Sigma_c\,\delta(t-s),
\label{eq:lti-sde}
\end{equation}
with $A\in\mathbb{R}^{n\times n}$, $G\in\mathbb{R}^{n\times r}$, and constant white-noise power $\Sigma_c\succeq 0$.

\subsection{Fundamental Solution and Covariance Integral}
The exact discrete-time transition over $\Delta$ is
\begin{equation}
\bm x(t+\Delta) \;=\; \Phi\,\bm x(t) \;+\; \bm \eta,\qquad
\Phi \;=\; e^{A\Delta},\qquad
\bm\eta \sim \mathcal{N}\!\Big(0,\; Q_d \Big), 
\label{eq:phi-qd-def}
\end{equation}
where the process covariance is the \emph{Lyapunov integral}
\begin{equation}
Q_d \;=\; \int_0^\Delta e^{A s}\,G\,\Sigma_c\,G^\top\,e^{A^\top s}\,ds.
\label{eq:qd-integral}
\end{equation}
The integrand is symmetric positive semidefinite for each $s$, hence $Q_d\succeq 0$ by construction.

\subsection{Van Loan’s Block-Exponential Construction}
Direct numerical evaluation of \eqref{eq:qd-integral} is impractical. Van Loan’s method builds
both $e^{A\Delta}$ and $Q_d$ from a \emph{single} matrix exponential. Define the $2n\times 2n$ block matrix
\begin{equation}
M(\Delta) \;=\; 
\begin{bmatrix}
-\,A\Delta & G\,\Sigma_c\,G^\top\,\Delta\\[2pt]
0 & A^\top\Delta
\end{bmatrix}.
\label{eq:vanloan-M}
\end{equation}
Then
\begin{equation}
\exp\!\big(M(\Delta)\big) \;=\;
\begin{bmatrix}
M_{11} & M_{12}\\[2pt]
0 & M_{22}
\end{bmatrix},
\label{eq:vanloan-exp}
\end{equation}
and the discrete-time pair is recovered by the identities
\begin{equation}
\Phi \;=\; M_{22}^\top,\qquad
Q_d \;=\; \Phi\,M_{12}.
\label{eq:vanloan-unpack}
\end{equation}

\paragraph{Sketch of proof.}
Consider the differential equation in $s$ for the block matrix
\(
\Xi(s)=
\begin{bmatrix}
X(s) & Y(s)\\ 0 & Z(s)
\end{bmatrix}
\)
with $\dot\Xi = 
\begin{bmatrix}
- A & G\Sigma_c G^\top\\ 0 & A^\top
\end{bmatrix}\Xi$, $\Xi(0)=I$.
Solving yields $Z(s)=e^{A^\top s}$, $X(s)=e^{-As}$,
and $Y(s)=\int_0^s e^{-A(s-u)} G\Sigma_c G^\top e^{A^\top u}\,du$.
Evaluating at $s=\Delta$ and rearranging produces \eqref{eq:vanloan-unpack}.
The construction ensures $Q_d\succeq 0$ and is numerically robust when $\exp(\cdot)$ is.

\subsection{Application to the OU-Driven Chain}
For one spatial axis with state $\bm x_{\rm lin}=[v,\,p,\,S,\,a]^\top$, the continuous matrices are
\begin{equation}
A_{\rm axis} \;=\;
\begin{bmatrix}
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & -\tfrac{1}{\tau}
\end{bmatrix},
\qquad
G_{\rm axis} \;=\;
\begin{bmatrix}0\\0\\0\\1\end{bmatrix},
\qquad
\Sigma_c \;=\; \frac{2}{\tau}\,\sigma^2.
\label{eq:Aaxis-Gaxis}
\end{equation}
For 3D, use $A = A_{\rm axis}\otimes I_3$ and $G=G_{\rm axis}\otimes I_3$ with $\Sigma_c$ diagonal
($\Sigma_c = \tfrac{2}{\tau}\,\Sigma_{aw}^{\rm stat}$). The Van Loan method yields:
\begin{equation}
\Phi_{vpsa} \;=\; \Phi_{\rm axis}\otimes I_3,
\qquad
Q_{d,\;vpsa} \;=\; \big(Q_{d,\,\rm axis}\big)\otimes I_3,
\label{eq:axis-3d}
\end{equation}
where $\Phi_{\rm axis}$ is exactly \eqref{eq:Phi-axis-ou}. The covariance $Q_{d,\,\rm axis}$ equals the kernel integrals
derived in the OU section (means and key entries listed there), and is guaranteed SPD by \eqref{eq:vanloan-unpack}.

\subsection{Consistency Checks}
\paragraph{Small-step limit.} As $\Delta\to 0$, $\Phi=I+A\Delta+\mathcal{O}(\Delta^2)$ and $Q_d=G\Sigma_c G^\top\,\Delta+\mathcal{O}(\Delta^2)$.
\paragraph{Stationarity of $a$.} The last row/column of $Q_{d,\,\rm axis}$ reproduces $\mathrm{Var}(a_{k+1}-\rho a_k)=\sigma^2(1-\rho^2)$,
consistent with the AR(1) in \eqref{eq:ou-ar1}.
\paragraph{Symmetry/PSD.} By construction, $Q_d= \int_0^\Delta (\cdot)(\cdot)^\top ds$ is symmetric and PSD; Van Loan inherits this property.
\vspace{1ex}

\section{Matrix Exponential via Pad\'e(6) with Scaling and Squaring}
\label{sec:pade6}

For embedded targets, we compute $\exp(M)$ in \eqref{eq:vanloan-exp} by a \emph{Pad\'e(6)} rational approximation
with \emph{scaling and squaring}. This offers an excellent accuracy--cost tradeoff for the
small matrices encountered here ($4\times 4$ or $8\times 8$ per axis, or $24\times 24$ for 3D Van Loan).

\subsection{Pad\'e(6) Rational Approximant}
A $[6/6]$ Pad\'e approximant to $e^A$ is
\begin{equation}
e^A \;\approx\; R_6(A) \;=\; \big(V(A)-U(A)\big)^{-1}\big(V(A)+U(A)\big),
\label{eq:pade-rational}
\end{equation}
with
\begin{align}
U(A) &= A\Big(c_2 I + c_6 A^2\Big), 
\label{eq:U-def}\\
V(A) &= c_0 I + c_4 A^2 + c_6' A^4 + c_8 A^6,
\label{eq:V-def}
\end{align}
and coefficients
\begin{equation}
c_0 = 1,\qquad c_2 = \tfrac{1}{2},\qquad c_4 = \tfrac{1}{24},\qquad
c_6 = \tfrac{1}{720},\qquad c_6'=\tfrac{1}{24},\qquad c_8 = \tfrac{1}{5040}.
\label{eq:pade-coeffs}
\end{equation}
This is algebraically equivalent to writing
\(
V= I + c_4 A^2 + \tfrac{1}{5040}A^6
\)
and
\(
U= A\big(\tfrac12 I + \tfrac{1}{720}A^2\big),
\)
as used in compact implementations.

\subsection{Scaling and Squaring}
Accuracy is improved by reducing $\|A\|$ before applying $R_6$. Choose the integer $s\ge 0$ so that
\begin{equation}
\|A/2^s\|_1 \;\le\; \theta_6,
\label{eq:theta-choice}
\end{equation}
where $\theta_6$ is a practical threshold (for Pad\'e(6), $\theta_6 \approx 3$ for small matrices).
Compute the rational approximation at the scaled matrix, then square:
\begin{equation}
e^A \;\approx\; \Big(R_6(A/2^s)\Big)^{2^s}.
\label{eq:scale-square}
\end{equation}
This standard technique preserves stability and keeps polynomial degrees low.

\subsection{Why Pad\'e(6) is a Good Fit Here}
\begin{itemize}
\item The Van Loan matrix $M(\Delta)$ is small (up to $24\times 24$ in 3D) and moderately scaled for typical $\Delta$; Pad\'e(6) with a few squarings is accurate.
\item The cost is dominated by a handful of dense matrix multiplications and one linear solve with $(V-U)$, which is inexpensive at these sizes.
\item Numerical behavior is well studied; together with Joseph’s form for the covariance update and symmetrization $P\leftarrow \tfrac12(P+P^\top)$, it yields a robust pipeline.
\end{itemize}

\subsection{Cross-Check with Series and OU Coefficients}
Expanding $R_6(A)$ around $A=0$ reproduces the first $13$ terms of the Taylor series of $e^A$ (since it is a $[6/6]$ approximant),
hence the local error is $\mathcal{O}(\|A\|^{13})$. When applied to the block matrix $M(\Delta)$ in \eqref{eq:vanloan-M}, this accuracy carries to both
$\Phi$ and $Q_d$ recovered via \eqref{eq:vanloan-unpack}, matching the OU-derived coefficients $E_0,E_1,E_2$ (means) and the covariance entries
listed in the OU section up to roundoff.

\subsection{Practical Notes}
\begin{enumerate}
\item \textbf{Conditioning.} Use the matrix one-norm to choose $s$; for typical IMU sampling ($\Delta\le 0.02$\,s) and $\tau$ in $[0.5,5]$\,s,
$s\in\{0,1,2\}$ is usually sufficient.
\item \textbf{SPD Preservation.} Van Loan’s construction plus a numerically stable exponential preserves $Q_d\succeq 0$ up to roundoff; if needed, enforce symmetry by $Q_d\leftarrow \tfrac12(Q_d+Q_d^\top)$.
\item \textbf{Embedded Efficiency.} Precompute powers $A^2,A^4,A^6$ for $U,V$; reuse buffers; prefer LU solve for $(V-U)X=(V+U)$ given matrix sizes.
\end{enumerate}

\section{Sensor Bias Models and Compensation}
\label{sec:biases}

A central element in inertial navigation Kalman filters is the explicit modeling of 
\emph{sensor biases}. Without including bias states, residual integration of even tiny 
constant offsets rapidly dominates wave kinematics. In this section we justify the bias 
state design of the filter, detail their dynamics, and explain temperature compensation.

\subsection{Gyroscope Bias}
Let the gyroscope measurement be
\begin{equation}
\bm\omega_{\rm meas}(t) \;=\; \bm\omega(t) + \bm b_g(t) + \bm\eta_g(t),
\label{eq:gyro-meas}
\end{equation}
where $\bm\omega(t)$ is the true body angular velocity, $\bm b_g(t)$ is the bias,
and $\bm\eta_g(t)$ is zero-mean white noise. In the filter, $\bm b_g$ is included as
a \emph{random walk} process:
\begin{equation}
\dot{\bm b}_g(t) = w_{bg}(t),\qquad
\mathbb{E}[w_{bg}(t)w_{bg}(s)^\top] = Q_{bg}\,\delta(t-s).
\label{eq:gyro-bias-model}
\end{equation}
This is the simplest effective choice: gyroscope biases drift slowly with temperature, vibration,
and time, and a random walk captures unmodeled bias variation while allowing the filter to absorb
constant offsets. The discrete process covariance for $\bm b_g$ is
\begin{equation}
Q_{bg,d} = Q_{bg}\,\Delta,
\label{eq:gyro-bias-qd}
\end{equation}
consistent with the implementation in the extended process covariance $Q_a$.

\subsection{Accelerometer Bias with Temperature Drift}
Accelerometer measurement model:
\begin{equation}
\bm f_{\rm meas}(t) = \bm f_b(t) + \bm b_a(t,T) + \bm\eta_a(t),
\label{eq:acc-meas}
\end{equation}
where $\bm f_b=R_{wb}(a_w-g)$ is the specific force predicted from states, and 
$\bm b_a(t,T)$ is the bias dependent on both slow random drift and \emph{temperature} $T$.

\paragraph{Nominal bias.}
We model the bias at a reference temperature $T_0$ as a state $\bm b_{a0}(t)$,
propagated as a random walk:
\begin{equation}
\dot{\bm b}_{a0}(t) = w_{ba}(t),\qquad
\mathrm{Cov}[w_{ba}] = Q_{ba}.
\label{eq:acc-bias-base}
\end{equation}

\paragraph{Temperature coefficient.}
Empirically, MEMS accelerometers exhibit nearly linear bias variation with temperature.
Thus we extend the bias model as
\begin{equation}
\bm b_a(t,T) = \bm b_{a0}(t) + K_a\,(T-T_0),
\label{eq:acc-bias-temp}
\end{equation}
where $K_a=\mathrm{diag}(k_x,k_y,k_z)$ is a diagonal matrix of temperature coefficients
in units of $[\mathrm{m/s^2}/^\circ\mathrm{C}]$.

\paragraph{Filter incorporation.}
In measurement prediction, \eqref{eq:acc-bias-temp} adds to the predicted force. During
filter updates, the Jacobian wrt the bias state is identity, while the temperature term
acts as a known deterministic offset. Explicit modeling prevents spurious innovation
terms whenever the platform warms or cools.

\subsection{Summary of Bias Roles}
\begin{itemize}
\item \textbf{Gyroscope bias:} modeled as random walk, essential for avoiding long-term
drift in integrated orientation.
\item \textbf{Accelerometer bias:} modeled as random walk plus linear temperature
dependence, essential for consistent specific force innovations and preventing systematic
tilt misestimation.
\item \textbf{Covariances $Q_{bg},Q_{ba}$:} tuning these governs how fast the filter
is willing to adapt biases; too small values cause long convergence times, too large values
inject excess noise.
\end{itemize}
The chosen model balances computational simplicity with sufficient realism for IMU-grade
sensors such as BMI270 and BMM150.


\section{Pseudo-Measurement on the Third Integral}
\label{sec:pseudo-S}

A unique element of this filter is the inclusion of the third integral state
\[
S(t) \;=\; \int_0^t p(\tau)\,d\tau,
\]
where $p(t)$ is the displacement in world coordinates.
This integral accumulates position over time and thus represents a 
\emph{triple integration} of acceleration. Without regularization, $S(t)$
would be dominated by low-frequency drift and quickly diverge.

\subsection{Why Include $S$ at All?}
One might ask why include $S$ when displacement $p$ already contains drift.
The answer lies in the structure of stochastic processes: by explicitly modeling
$S$, we can apply a pseudo-measurement that constrains the lowest-frequency drift
mode of the integrator chain. This prevents the covariance from exploding in the
null space of repeated integration.

\subsection{Zero Pseudo-Measurement}
The pseudo-measurement enforces the soft constraint
\begin{equation}
z_S = 0 \;\;\approx\;\; H_S\,x + \nu_S,
\label{eq:ps-meas}
\end{equation}
where $H_S$ selects the $S$ block of the state vector, and $\nu_S\sim\mathcal{N}(0,R_S)$
is fictitious Gaussian noise. In implementation:
\begin{equation}
H_S = \begin{bmatrix}0 & \cdots & I_3 & \cdots & 0\end{bmatrix},
\qquad
R_S = \mathrm{diag}(\sigma_{S,x}^2,\,\sigma_{S,y}^2,\,\sigma_{S,z}^2).
\label{eq:ps-HR}
\end{equation}

\subsection{Kalman Update}
The innovation for the pseudo-measurement is simply
\begin{equation}
\tilde y = -S_k,
\end{equation}
since the measurement is identically zero. The Kalman gain is
\begin{equation}
K_S = P H_S^\top (H_S P H_S^\top + R_S)^{-1},
\end{equation}
and the update is
\begin{align}
x^+ &= x + K_S\tilde y,\\
P^+ &= (I-K_SH_S)P(I-K_SH_S)^\top + K_SR_SK_S^\top.
\end{align}
Thus $S$ is softly driven toward zero, and its covariance is bounded.

\subsection{Interpretation of $R_S$}
The choice of $R_S$ is critical. A small $R_S$ enforces a tight pseudo-measurement,
essentially pinning $S\approx 0$ and aggressively damping drift. A large $R_S$ relaxes
the constraint, letting $S$ wander but still preventing unbounded variance growth.

Physically, $S$ has no direct observable meaning (it is an auxiliary integral).
Therefore, $R_S$ does not correspond to sensor noise, but rather to a 
\emph{design knob}:
\begin{itemize}
\item If the application tolerates only bounded displacements (e.g.\ buoy motion limited
by mooring), use smaller $R_S$.
\item If slow drift is acceptable, increase $R_S$ to reduce artificial feedback.
\end{itemize}

\subsection{Effect on Stability}
By including $S$ and its pseudo-measurement, we guarantee that the extended covariance $P$
does not develop an uncontrollable growth mode. In linear systems terminology, the augmented
system becomes \emph{detectable}: even though $S$ is unobservable in a strict sense, the 
pseudo-measurement provides an artificial observation that stabilizes the filter numerics.

\paragraph{Key insight.} 
The $S$ pseudo-measurement is not “cheating,” but rather a principled
regularization. It adds just enough fictitious information to ensure 
bounded variance in triple integrals of noisy acceleration, 
while leaving physically observable states ($q,v,p,a_w$) unbiased.

\section{Measurement Models: Accelerometer and Magnetometer}
\label{sec:meas-models}

The filter fuses inertial and magnetic measurements to anchor attitude and
linear states. Here we derive the measurement functions and their Jacobians.

\subsection{Accelerometer Measurement Model}
The accelerometer provides the specific force in the body frame:
\begin{equation}
\bm f_{\rm meas} 
= R_{wb}\,\big(\bm a_w - \bm g\big) + \bm b_a(T) + \bm\eta_a,
\label{eq:accel-meas}
\end{equation}
where
\begin{itemize}
\item $R_{wb}$ is the world-to-body rotation,
\item $\bm a_w$ is the latent world-frame acceleration (OU state),
\item $\bm g = (0,0,g)$ is gravity in NED coordinates,
\item $\bm b_a(T)$ is the accelerometer bias with temperature drift,
\item $\bm\eta_a \sim \mathcal{N}(0,R_a)$ is zero-mean measurement noise.
\end{itemize}

\paragraph{Role.}
At rest, \eqref{eq:accel-meas} reduces to $\bm f_{\rm meas} \approx R_{wb}\,(-\bm g)$,
which gives roll and pitch observability. During motion, $\bm a_w$ separates wave-induced
accelerations from gravity, preventing tilt corruption.

\subsection{Accelerometer Jacobians}
The innovation function is
\[
\bm y_a = \bm f_{\rm meas} - \hat{\bm f}_b,
\qquad
\hat{\bm f}_b = R_{wb}(\hat{\bm a}_w - \bm g) + \hat{\bm b}_a(T).
\]
Linearizing yields Jacobians:
\begin{align}
\frac{\partial \hat{\bm f}_b}{\partial \delta\bm\theta} &= -\,[\hat{\bm f}_b]_\times,
\label{eq:accel-jac-att}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm a_w} &= R_{wb},
\label{eq:accel-jac-aw}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm b_a} &= I_3,
\label{eq:accel-jac-bias}
\end{align}
where $\delta\bm\theta$ is the small-angle error and $[\cdot]_\times$ is the skew-symmetric matrix.

\subsection{Magnetometer Measurement Model}
The magnetometer senses the geomagnetic field in the body frame:
\begin{equation}
\bm m_{\rm meas} = R_{wb}\,\bm B_w + \bm\eta_m,
\label{eq:mag-meas}
\end{equation}
where $\bm B_w$ is the known reference magnetic field in the world frame,
and $\bm\eta_m \sim \mathcal{N}(0,R_m)$ is measurement noise.

\paragraph{Role.}
The magnetometer provides yaw observability. By choosing $\bm B_w$ appropriately:
\begin{itemize}
\item Use the full geomagnetic vector for full 3D correction,
\item Use the horizontal projection $(B_N,B_E,0)$ for yaw-only correction.
\end{itemize}

\subsection{Magnetometer Jacobians}
Predicted measurement:
\[
\hat{\bm m}_b = R_{wb}\bm B_w.
\]
Linearization:
\begin{equation}
\frac{\partial \hat{\bm m}_b}{\partial \delta\bm\theta} = -\,[\hat{\bm m}_b]_\times.
\label{eq:mag-jac-att}
\end{equation}
No other state appears in \eqref{eq:mag-meas}, so all other Jacobians are zero.

\subsection{Combined Measurement Vector}
The full measurement vector is
\[
\bm y = \begin{bmatrix}\bm f_{\rm meas}\\ \bm m_{\rm meas}\end{bmatrix},
\qquad
\hat{\bm y} = \begin{bmatrix}\hat{\bm f}_b\\ \hat{\bm m}_b\end{bmatrix},
\]
with innovation covariance
\begin{equation}
S = C P C^\top + R,
\qquad
R = \begin{bmatrix} R_a & 0 \\ 0 & R_m \end{bmatrix},
\label{eq:meas-cov}
\end{equation}
where $C$ is the stacked Jacobian from \eqref{eq:accel-jac-att}--\eqref{eq:accel-jac-bias} and \eqref{eq:mag-jac-att}.

\subsection{Physical Interpretation}
\begin{itemize}
\item The accelerometer primarily constrains roll and pitch, while respecting wave accelerations
through $\bm a_w$.
\item The magnetometer anchors yaw against drift, with flexibility to restrict to yaw-only updates.
\item Together they ensure full 3D attitude observability.
\item Inclusion of $\bm b_a(T)$ makes the innovations insensitive to slow sensor thermal drift.
\end{itemize}

\section{Extended State Transition Matrix}
\label{sec:transition}

The extended state vector is
\begin{equation}
x = \begin{bmatrix}
\delta\bm\theta & \bm b_g & \bm v & \bm p & \bm S & \bm a_w & \bm b_a
\end{bmatrix}^\top,
\label{eq:state-vector}
\end{equation}
where each block is $3\times 1$. Depending on configuration, $\bm b_g$ and $\bm b_a$ may be omitted.

\subsection{Attitude Error Dynamics}
From \eqref{eq:att_err_dyn}, the linearized error propagation is
\begin{equation}
\dot{\delta\bm\theta} = -[\bm\omega_b - \bm b_g]_\times \,\delta\bm\theta - \delta\bm b_g + n_\theta.
\label{eq:att-err-dyn2}
\end{equation}
Discretization via Rodrigues’ formula \eqref{eq:rodrigues} yields the discrete block
\begin{equation}
F_{\theta\theta} \;=\; I - \sin\theta [\hat{\bm u}]_\times + (1-\cos\theta)[\hat{\bm u}]_\times^2,
\label{eq:F-att}
\end{equation}
with $\theta = \|\bm\omega_b-\bm b_g\|\Delta$ and $\hat{\bm u}=(\bm\omega_b-\bm b_g)/\|\bm\omega_b-\bm b_g\|$.
For small $\theta$, expand as
\[
F_{\theta\theta} \approx I - [\bm\omega_b-\bm b_g]_\times \Delta + \tfrac{1}{2}[\bm\omega_b-\bm b_g]_\times^2 \Delta^2.
\]

The cross term wrt gyro bias is
\begin{equation}
F_{\theta b_g} = -I\,\Delta.
\label{eq:F-att-bg}
\end{equation}

\subsection{Velocity–Position–Integral Chain}
For one axis, dynamics are
\[
\dot v = a_w,\qquad
\dot p = v,\qquad
\dot S = p.
\]
This yields the companion form matrix
\begin{equation}
A_{vps} =
\begin{bmatrix}
0 & 0 & 0\\
1 & 0 & 0\\
0 & 1 & 0
\end{bmatrix},\qquad
B_{vps} = \begin{bmatrix}1\\0\\0\end{bmatrix}.
\label{eq:Avps}
\end{equation}
Coupled with OU acceleration $\dot a_w = -\tfrac{1}{\tau}a_w + w$, the full
axis dynamics are
\[
\dot{\bm x}_{\rm lin} = 
\underbrace{\begin{bmatrix}
A_{vps} & B_{vps}\\
0 & -\tfrac{1}{\tau}
\end{bmatrix}}_{A_{\rm axis}}
\bm x_{\rm lin} + 
\underbrace{\begin{bmatrix}0\\0\\0\\1\end{bmatrix}}_{G_{\rm axis}}w.
\]

The discrete transition for this $4\times 4$ block is obtained from
Van Loan discretization (Sec.~\ref{sec:van-loan}), giving
\begin{equation}
\Phi_{\rm axis} = e^{A_{\rm axis}\Delta}.
\label{eq:phi-axis}
\end{equation}
Explicit entries involve integrals $E_0,E_1,E_2$ derived in the OU section.

\subsection{OU Acceleration Block}
For each axis:
\begin{equation}
F_{aa} = e^{-\Delta/\tau},\qquad
Q_{aa} = \sigma^2 \big(1-e^{-2\Delta/\tau}\big).
\label{eq:ou-discrete}
\end{equation}
These match the AR(1) equivalent of the continuous OU process.

\subsection{Accelerometer Bias Block}
Accelerometer bias $\bm b_a$ evolves as a random walk:
\begin{equation}
\dot{\bm b}_a = w_{ba},\qquad
Q_{ba,d} = Q_{ba}\Delta.
\label{eq:accel-bias-rw}
\end{equation}
Its discrete transition is
\[
F_{b_ab_a} = I,\qquad
Q_{b_ab_a} = Q_{ba}\Delta.
\]

\subsection{Full Transition Matrix}
Assembling all blocks yields
\begin{equation}
F =
\begin{bmatrix}
F_{\theta\theta} & F_{\theta b_g} & 0 & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0 & 0 & 0\\
0 & 0 & \Phi_{vv} & \Phi_{vp} & \Phi_{vS} & \Phi_{va} & 0\\
0 & 0 & \Phi_{pv} & \Phi_{pp} & \Phi_{pS} & \Phi_{pa} & 0\\
0 & 0 & \Phi_{Sv} & \Phi_{Sp} & \Phi_{SS} & \Phi_{Sa} & 0\\
0 & 0 & \Phi_{av} & \Phi_{ap} & \Phi_{aS} & \Phi_{aa} & 0\\
0 & 0 & 0 & 0 & 0 & 0 & I
\end{bmatrix},
\label{eq:F-full}
\end{equation}
where each $\Phi_{\cdot\cdot}$ block is $3\times 3$ (Kronecker product with $I_3$).
Cross-couplings from OU integrals populate $\Phi_{va},\Phi_{pa},\Phi_{Sa}$,
with exact formulas given in the OU derivation.

\subsection{Process Noise Covariance}
The block structure of $Q$ mirrors that of $F$. In particular:
\begin{itemize}
\item $Q_{\theta\theta}$ and $Q_{\theta b_g}$ from gyro noise,
\item $Q_{vpsa}$ from OU integrals (Eq.~\ref{eq:qd-integral}),
\item $Q_{b_a}$ from random walk bias (Eq.~\ref{eq:accel-bias-rw}).
\end{itemize}
Together these ensure all states remain bounded in variance, even under long integrations.

\section{Kalman Update, Joseph Form, and the Role of the Measurement Covariance}
\label{sec:kalman-update}

This section presents the measurement-update step used throughout the filter for (i) the stacked
accelerometer+magnetometer measurement and (ii) the $S$-pseudo-measurement. We highlight the
\emph{Joseph} covariance update, which is numerically more robust than the basic $P^+=(I-KC)P$ form,
and we discuss how the measurement covariance $R$ influences observability, gain magnitude, and
steady-state performance.

\subsection{General Linearized Measurement Model}
Let the (possibly stacked) measurement be written as
\begin{equation}
\bm y_k = h(x_k) + \bm \nu_k,\qquad \bm \nu_k \sim \mathcal{N}(0,R),
\label{eq:meas-gen}
\end{equation}
with linearization about the predicted state $\hat x_k^-$
\begin{equation}
\hat{\bm y}_k^- \;=\; h(\hat x_k^-),\qquad
C_k \;=\; \left.\frac{\partial h}{\partial x}\right|_{\hat x_k^-}.
\label{eq:meas-linearization}
\end{equation}
The innovation and its covariance are
\begin{align}
\tilde{\bm y}_k &= \bm y_k - \hat{\bm y}_k^-,
\label{eq:innovation}\\
S_k &= C_k P_k^- C_k^\top + R.
\label{eq:innovation-cov}
\end{align}
The Kalman gain is computed by a symmetric positive-definite solve in $S_k$
\begin{equation}
K_k \;=\; P_k^- C_k^\top S_k^{-1}.
\label{eq:kalman-gain}
\end{equation}

\subsection{Joseph-Stabilized Covariance Update}
The \emph{Joseph form} ensures $P_k^+\succeq 0$ up to roundoff and avoids deficit-rank artifacts:
\begin{equation}
P_k^+ \;=\; (I - K_k C_k)\,P_k^-\, (I - K_k C_k)^\top + K_k R K_k^\top.
\label{eq:joseph}
\end{equation}
In practice, we also enforce symmetry by
\begin{equation}
P_k^+ \leftarrow \tfrac{1}{2}\big(P_k^+ + P_k^{+\top}\big),
\label{eq:symmetrize}
\end{equation}
which is benign and combats small numerical asymmetries.

\subsection{Accelerometer + Magnetometer Stack}
For the stacked measurement
\[
\bm y_k = 
\begin{bmatrix}
\bm f_{{\rm meas},k}\\ \bm m_{{\rm meas},k}
\end{bmatrix},\qquad
\hat{\bm y}_k^- =
\begin{bmatrix}
R_{wb}(\hat{\bm a}_{w,k}^- - \bm g) + \hat{\bm b}_{a,k}^-(T_k)\\[2pt]
R_{wb}\,\bm B_w
\end{bmatrix},
\]
the Jacobian takes the block form
\begin{equation}
C_k \;=\;
\begin{bmatrix}
-\,[\hat{\bm f}_{b,k}^-]_\times & 0 & 0 & 0 & 0 & R_{wb} & I_3\\[2pt]
-\,[\hat{\bm m}_{b,k}^-]_\times & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix},
\label{eq:C-acc-mag}
\end{equation}
where the columns correspond to $(\delta\bm\theta,\ \bm b_g,\ \bm v,\ \bm p,\ \bm S,\ \bm a_w,\ \bm b_a)$.
The measurement covariance is block diagonal:
\begin{equation}
R \;=\; 
\begin{bmatrix}
R_a & 0\\ 0 & R_m
\end{bmatrix}.
\label{eq:R-acc-mag}
\end{equation}
Equation \eqref{eq:C-acc-mag} expresses three key physical couplings:
(i) attitude enters both sensors via a skew-symmetric sensitivity,
(ii) the latent world-acceleration \(\bm a_w\) enters the accelerometer through the rotation \(R_{wb}\),
(iii) the accelerometer bias enters additively.

\subsection{Pseudo-Measurement on $S$}
The $S$-pseudo-measurement \((z_S=0)\) uses
\begin{equation}
C_{S} \;=\; \begin{bmatrix} 0 & 0 & 0 & 0 & I_3 & 0 & 0 \end{bmatrix},\qquad
R_S \;=\; \mathrm{diag}(\sigma_{S,x}^2,\sigma_{S,y}^2,\sigma_{S,z}^2).
\label{eq:C-R-S}
\end{equation}
Innovation: $\tilde y_S = - \hat S_k^-$. Gain and update follow \eqref{eq:kalman-gain}--\eqref{eq:joseph}.

\subsection{Role of the Measurement Covariance $R$}
The matrix $R$ determines (i) the relative trust between model and measurements,
(ii) the steady-state gains, and (iii) the balance between noise rejection and responsiveness.

\paragraph{Accelerometer $R_a$.}
Larger $R_a$ reduces the accelerometer’s leverage, protecting attitude from transient linear accelerations
but slowing bias and $a_w$ convergence. Smaller $R_a$ tightens roll/pitch but risks injecting wave-induced
accelerations into attitude unless $\bm a_w$ is modeled (as here).

\paragraph{Magnetometer $R_m$.}
Larger $R_m$ weakens yaw correction (useful near magnetic disturbances). If yaw-only updates are desired,
set the world reference \(\bm B_w\) horizontal; then \([\hat{\bm m}_b]_\times\) only corrects yaw.

\paragraph{Pseudo $R_S$.}
The parameter $R_S$ is a \emph{design knob}: it is not sensor noise, but a regularization weight. 
Making $R_S$ small aggressively suppresses triple-integral drift (pinning $S\!\approx\!0$); making it large
allows slower drift while still bounding covariance growth. In all cases, \eqref{eq:joseph} ensures the update
remains numerically stable.

\subsection{Observability and Conditioning}
With accelerometer and magnetometer, the attitude is fully observable (roll/pitch from gravity, yaw from magnetic field).
The latent OU \(\bm a_w\) decouples true linear acceleration from gravity so that roll/pitch estimates remain unbiased in motion.
The $S$-pseudo-measurement ensures detectability of the triple-integrator chain, preventing uncontrolled variance growth.

\subsection{Post-Update Quaternion Correction}
After the state update, the small-angle correction is applied multiplicatively to the quaternion:
\begin{equation}
\delta q(\delta\bm\theta) \approx \begin{bmatrix}1\\ \tfrac{1}{2}\delta\bm\theta\end{bmatrix},
\qquad
q^+ \;=\; q^- \otimes \delta q(\delta\bm\theta),
\qquad
\delta\bm\theta \leftarrow 0.
\label{eq:quat-correct}
\end{equation}
This preserves unit norm and keeps the attitude error minimal (on the tangent space) for the next cycle.


\section{Numerical Methods for Discretization and Matrix Exponentials}
\label{sec:numerical-methods}

The extended filter requires repeated discretization of continuous-time dynamics.
Three key techniques are employed: Rodrigues’ rotation formula, Van Loan’s
block-matrix exponential method, and Pad\'e(6) approximants with scaling and
squaring. We now detail each.

\subsection{Rodrigues’ Formula for Attitude Propagation}
For a body angular velocity $\bm\omega$ and timestep $\Delta$, the quaternion update
is
\[
q_{k+1} = q_k \otimes \exp\!\left(\tfrac{\Delta}{2}\bm\omega\right).
\]
In matrix form, the equivalent rotation matrix update uses Rodrigues’ formula:
\begin{equation}
R_{k+1} = R_k\left(I + \sin\theta [\hat{\bm u}]_\times +
(1-\cos\theta)[\hat{\bm u}]_\times^2\right),
\label{eq:rodrigues-final}
\end{equation}
with $\theta = \|\bm\omega\|\Delta$ and $\hat{\bm u}=\bm\omega/\|\bm\omega\|$.
For small $\theta$, the series expansion yields
\[
R_{k+1} \approx R_k\Big(I + [\bm\omega]_\times \Delta + \tfrac{1}{2}[\bm\omega]_\times^2 \Delta^2\Big),
\]
which is consistent with the truncated exponential.

\paragraph{Role.}
This exact formula avoids numerical drift and provides a consistent
linearization for Jacobians.

\subsection{Van Loan Discretization for Linear Subsystems}
For linear SDEs of the form
\[
\dot x = A x + G w,\quad \mathbb{E}[w(t)w(s)^\top] = Q_c\delta(t-s),
\]
the discrete-time equivalent over $\Delta$ is
\begin{equation}
\begin{bmatrix}
\Phi & Q_d\\ 0 & \Phi^{-\top}
\end{bmatrix}
=
\exp\!\left(
\begin{bmatrix}
-A\Delta & GQ_cG^\top\Delta\\
0 & A^\top\Delta
\end{bmatrix}
\right).
\label{eq:van-loan-final}
\end{equation}
The transition is $\Phi=e^{A\Delta}$ and the discrete covariance is
$Q_d=\Phi Q\Phi^\top$. This is the \emph{exact} discretization method
for linear Gaussian systems.

\paragraph{Application here.}
For the 12D subsystem $(v,p,S,a_w)$, Van Loan yields the exact coupling
coefficients between OU acceleration and its integrals. This guarantees
bounded variances and eliminates ad-hoc approximations.

\subsection{Pad\'e(6) with Scaling and Squaring}
When $\exp(A\Delta)$ must be computed on embedded targets without matrix
function libraries, we approximate via Pad\'e(6):
\begin{equation}
\exp(A) \approx (V+U)(V-U)^{-1},
\label{eq:pade6}
\end{equation}
where
\begin{align}
U &= A\left(c_2 I + c_6 A^2\right),\\
V &= c_0 I + c_4 A^2 + c_6 A^4,
\end{align}
with coefficients $c_0=1,\;c_2=\tfrac{1}{2},\;c_4=\tfrac{1}{24},\;c_6=\tfrac{1}{720}$.

\paragraph{Scaling and squaring.}
If $\|A\|>\theta$ (with $\theta\approx 3$), set $A\leftarrow A/2^s$,
compute $\exp(A/2^s)$ via \eqref{eq:pade6}, then square $s$ times.

\paragraph{Role.}
This scheme provides stable, efficient evaluation of $\exp(A\Delta)$ for
small fixed matrices (up to $12\times 12$), ensuring agreement with the
desktop Van Loan implementation.

\subsection{Summary}
\begin{itemize}
\item Rodrigues’ formula: exact, closed-form for SO(3), preserves attitude orthogonality.
\item Van Loan: exact state+covariance discretization for linear OU-extended systems.
\item Pad\'e(6): efficient embedded approximation when matrix exponential libraries are unavailable.
\end{itemize}
Together, they provide consistency across desktop prototyping and embedded deployment.

\section{Observability and Identifiability}
\label{sec:observability}

This section analyzes what can (and cannot) be inferred from the proposed sensing setup.
We use a local (linearized) observability perspective for intuition, with emphasis on
the roles of gravity, magnetic field, the OU latent acceleration, and the $S$ pseudo-measurement.

\subsection{Setup and Linearized Model}
Let the extended state be
\[
x^\top=\begin{bmatrix}
\delta\bm\theta^\top & \bm b_g^\top & \bm v^\top & \bm p^\top & \bm S^\top & \bm a_w^\top & \bm b_a^\top
\end{bmatrix}.
\]
Over one step (about a nominal trajectory) the linearized dynamics and output read
\begin{equation}
\dot x = A x + G w,
\qquad
y = C x + \nu,
\label{eq:lin-obs}
\end{equation}
where $A$ is the Jacobian of the continuous dynamics, $G$ the process noise input, and
$C$ the stacked Jacobian of the accelerometer, magnetometer, and (optionally) $S$ pseudo-measurement.
The discrete observability matrix over $L$ steps is
\begin{equation}
\mathcal{O}_L \;\triangleq\; \begin{bmatrix}
C\\
C\Phi\\
C\Phi^2\\
\vdots\\
C\Phi^{L-1}
\end{bmatrix},
\qquad
\Phi = e^{A\Delta},
\label{eq:obs-matrix}
\end{equation}
and local (linear) observability is indicated by $\mathrm{rank}(\mathcal{O}_L)$.

\subsection{Attitude Observability}
\paragraph{Accelerometer alone.} With $\bm f_{\rm meas}=R_{wb}(\bm a_w-\bm g)+\bm b_a+\eta_a$,
and \emph{at rest} (i.e.\ $\bm a_w\approx 0$), the accelerometer reduces to
$\bm f_{\rm meas}\approx -R_{wb}\bm g+\bm b_a$. Thus roll/pitch are locally observable
from gravity direction, but yaw is not. Under nonzero linear acceleration, gravity is
confounded by $\bm a_w$; without modeling $\bm a_w$, roll/pitch become biased in motion.

\paragraph{Magnetometer.} With $\bm m_{\rm meas}=R_{wb}\bm B_w+\eta_m$, yaw becomes observable,
provided that $\bm B_w$ and $\bm g$ are not colinear. If the magnetometer is used in
yaw-only mode (horizontal field $\bm B_w=(B_N,B_E,0)$), the combination of gravity and
horizontal field still fully observes attitude.

\paragraph{Conclusion.} \emph{Attitude is locally observable with accelerometer+magnetometer.}
The OU latent $\bm a_w$ prevents linear acceleration from corrupting roll/pitch:
accelerations are explained by $\bm a_w$ rather than misattributed to tilt.

\subsection{Bias Observability}
\paragraph{Gyro bias $\bm b_g$.} It enters the attitude error dynamics as 
$\dot{\delta\bm\theta}=-[\bm\omega-\bm b_g]_\times\delta\bm\theta - \delta\bm b_g + \cdots$,
hence persistent excitation in $\bm\omega$ (non-colinear rotations over time) makes
$\bm b_g$ observable through attitude innovations. With no rotation, $\bm b_g$ is only
weakly observable via magnetometer/accelerometer corrections, leading to slow convergence.

\paragraph{Accelerometer bias $\bm b_a$.} It is additive in the accelerometer channel.
Separation between $\bm b_a$ and $\bm a_w$ requires time-varying orientation $R_{wb}(t)$
and/or spectral separation imposed by the OU prior on $\bm a_w$. Intuitively, $\bm b_a$
is constant/slow (random walk), while $\bm a_w$ is zero-mean, correlated fluctuations;
with sufficient attitude excitation, the filter can attribute DC (and very low frequency)
components to $\bm b_a$ and correlated dynamics to $\bm a_w$. Temperature variation aids
identifiability of $\bm b_{a0}$ when the linear coefficient $K_a$ is known.

\subsection{Translational States $(\bm v,\bm p,\bm S)$}
Absent any absolute position sensor, global $\bm p$ is not \emph{absolutely} observable
(only up to a drift). However:
\begin{itemize}
\item The OU prior on $\bm a_w$ ensures \emph{bounded} variance for $\bm v$ and $\bm p$
under propagation (in contrast with integrating white acceleration).
\item The $S$ pseudo-measurement renders the triple-integrator chain \emph{detectable}:
low-frequency drift modes are softly constrained, preventing covariance blow-up.
\end{itemize}
Thus the combined system is not fully observable in the strict sense (absolute position
remains gauge-like), but is \emph{stochastically well-posed}: the covariance remains bounded,
and estimates remain physically meaningful over long windows.

\subsection{Rank Arguments (Sketches)}
Let $C_{\rm am}$ be the stacked Jacobian for accelerometer and magnetometer:
\[
C_{\rm am}=
\begin{bmatrix}
-[\hat{\bm f}_b]_\times & 0 & 0 & 0 & 0 & R_{wb} & I_3\\
-[\hat{\bm m}_b]_\times & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}.
\]
\begin{itemize}
\item If $\bm g$ and $\bm B_w$ are not colinear, the columns associated with $\delta\bm\theta$
span $\mathbb{R}^3$ generically; hence attitude is locally observable.
\item The columns for $\bm a_w$ (through $R_{wb}$) and for $\bm b_a$ (through $I_3$)
are linearly independent for time-varying $R_{wb}$, which promotes identifiability.
\item Appending $C_S=[0\;\,0\;\,0\;\,0\;\,I_3\;\,0\;\,0]$ introduces direct sensitivity to $\bm S$,
closing the lowest-frequency drift mode of the chain $(\bm v,\bm p,\bm S)$.
\end{itemize}
Over multiple steps, $\mathcal{O}_L$ gathers the time variations of $R_{wb}(t)$ and the OU dynamics
to lift additional modes. The result is a detectable system with bounded estimation error covariances.


\section{Tuning Guidelines}
\label{sec:tuning}

This section gives practical tuning rules for the OU parameters $(\tau,\sigma)$,
process covariances $Q$, measurement covariances $R$, the pseudo-measurement $R_S$,
and initial covariance $P_0$. Symbols match the code and prior sections.

\subsection{OU Parameters: $\tau$ (Correlation Time) and $\sigma$ (Stationary RMS)}
\paragraph{Role.}
$\tau$ sets the temporal correlation of the latent acceleration $a_w$ via the
autocorrelation $R_a(\Delta)=\sigma^2 e^{-|\Delta|/\tau}$ and the PSD
$S_a(\omega)=\frac{2\sigma^2\tau}{1+(\omega\tau)^2}$, with half-power cutoff
$f_c=\frac{1}{2\pi\tau}$. $\sigma$ sets the stationary RMS magnitude of $a_w$.

\paragraph{Mapping to an acceleration period.}
If the dominant acceleration has period $T_a$, a pragmatic choice is to align the
OU corner $f_c$ to a fraction of the dominant frequency:
\begin{equation}
\tau \;\approx\; \frac{1}{2\pi\,\kappa f_a}
\;=\;
\frac{T_a}{2\pi\,\kappa},
\qquad
\kappa\in[0.5,\,1].
\label{eq:tau-map}
\end{equation}
Choosing $\kappa=1$ sets $f_c=f_a$; $\kappa=0.5$ pushes the OU correlation longer,
smoothing more aggressively.

\paragraph{Selecting $\sigma$.}
Set $\sigma$ to the expected RMS of \emph{non-gravitational} acceleration in the band of interest
(per axis), e.g.\ sea-state-induced specific force. Typical values:
\[
\sigma \in [0.1,\,0.6]\ \mathrm{m/s^2}\quad\text{(calm to rough)}.
\]
In 3D, use a diagonal $\Sigma_{aw}^{\rm stat}=\mathrm{diag}(\sigma_x^2,\sigma_y^2,\sigma_z^2)$
if anisotropy is expected.

\paragraph{Discrete view.}
Given sample period $\Delta$, the discrete OU parameter is $\rho=e^{-\Delta/\tau}$ and the
innovation variance is $\sigma^2(1-\rho^2)$. Ensure $\rho$ is not so close to $1$ that
numerics suffer (e.g., keep $1-\rho \gtrsim 10^{-6}$; if not, increase $\Delta$ or reduce $\tau$ slightly).

\subsection{Process Noise Covariances $Q$}
\paragraph{Gyro bias $Q_{bg}$.}
From Allan-variance data, convert the bias random-walk coefficient $\mathrm{BRW}$ to
\[
Q_{bg} \approx (\mathrm{BRW})^2 I_3,
\]
with $\mathrm{BRW}$ in $\mathrm{(rad/s)/\sqrt{s}}$. As a starting point for MEMS:
$Q_{bg}^{1/2}\in [3\!\times\!10^{-5},\,3\!\times\!10^{-4}]$ rad/s$/\sqrt{\mathrm{s}}$.

\paragraph{Accel bias $Q_{ba}$.}
Similarly, from the bias RW coefficient (in $\mathrm{m/s^2}/\sqrt{\mathrm{s}}$),
set $Q_{ba} \approx (\mathrm{ARW}_{\rm bias})^2 I_3$. Conservative starts:
$Q_{ba}^{1/2}\in [10^{-4},\,10^{-3}]\,\mathrm{m/s^2}/\sqrt{\mathrm{s}}$.

\paragraph{OU continuous power $\Sigma_c$.}
Use $\Sigma_c=\frac{2}{\tau}\Sigma_{aw}^{\rm stat}$ (per Section~\ref{sec:ou-detailed});
the discrete $Q_{d,vpsa}$ is then obtained exactly by Van Loan.

\subsection{Measurement Covariances $R$}
\paragraph{Accelerometer $R_a$.}
Set from sensor noise density. If the datasheet gives $\sigma_{\rm acc}$ per axis (RMS),
use $R_a=\mathrm{diag}(\sigma_{\rm acc,x}^2,\sigma_{\rm acc,y}^2,\sigma_{\rm acc,z}^2)$.
When significant linear accelerations are present, increase $R_a$ moderately to avoid
over-trusting accelerometer innovations on attitude.

\paragraph{Magnetometer $R_m$.}
Use the manufacturer noise floor as baseline. Inflate $R_m$ if the environment is 
magnetically disturbed. For yaw-only behavior, set $\bm B_w$ horizontal; $R_m$ still
reflects sensor noise but you avoid pitch/roll magneto-coupling.

\paragraph{$S$ Pseudo $R_S$.}
$R_S$ is a design regularizer. Smaller values enforce $S\!\approx 0$ more strongly,
suppressing triple-integral drift. A practical approach is to tie $R_S$ to a
\emph{maximum acceptable growth rate} of $S$ under propagation; e.g.\ choose
$\sigma_{S}$ so that a $3\sigma$ excursion corresponds to the largest tolerable $S$
over time scales of interest.

\subsection{Initialization}
\begin{itemize}
\item \textbf{Quaternion.} Initialize from $\{\bm f_{\rm meas}, \bm m_{\rm meas}\}$ using the
accelerometer/magnetometer alignment; if yaw cannot be trusted initially, use accelerometer-only
and accept an arbitrary yaw offset until magnetometer updates correct it.
\item \textbf{Linear states.} Set $\bm v=\bm 0$, $\bm p=\bm 0$, $\bm S=\bm 0$ with conservative
covariances, e.g.\ $\sigma_v\!\approx\!1$ m/s, $\sigma_p\!\approx\!20$ m, $\sigma_S\!\approx\!50$ m$\cdot$s.
\item \textbf{Biases.} Use prior calibration if available; otherwise zero-mean with
$\sigma_{b_g}$ and $\sigma_{b_a}$ broad enough to allow convergence (e.g.\ $0.02$–$0.2$ rad/s for $\bm b_g$,
$0.02$–$0.1$ m/s$^2$ for $\bm b_a$).
\item \textbf{OU.} Initialize $\bm a_w=\bm 0$ with covariance equal to $\Sigma_{aw}^{\rm stat}$.
\end{itemize}

\subsection{Sanity Checks (Residuals and Gains)}
\begin{itemize}
\item Verify innovation whiteness: $\tilde y_k$ should be zero-mean and consistent with $S_k$.
\item Monitor $K_k$: saturation or near-zero gains indicate mis-tuned $R$ or $Q$.
\item Track $P$: enforce symmetry $P\leftarrow \tfrac12(P+P^\top)$; ensure no negative variances.
\item Check $\|q\| \approx 1$ after each update (normalize if needed).
\end{itemize}

\subsection{Practical Numbers (Starting Points)}
At $\Delta\in[0.01,0.02]$ s:
\[
\tau \in [1,\,3]\ \mathrm{s},\qquad
\sigma \in [0.15,\,0.4]\ \mathrm{m/s^2},\qquad
R_a^{1/2} \in [0.01,\,0.03]\ \mathrm{m/s^2},\qquad
R_m^{1/2} \in [50,\,200]\ \mathrm{nT}.
\]
These should be adapted to your specific platform and sea state.


\section{Convergence and Stability}
\label{sec:convergence}

Beyond observability, practical filtering requires stability of the error dynamics and
bounded covariance behavior. We discuss the main mechanisms that ensure convergence.

\subsection{Attitude}
The quaternion MEKF framework ensures that the linearized attitude error dynamics remain
locally exponentially stable in the absence of noise, provided the gain matrices are bounded.
With accelerometer and magnetometer updates, roll, pitch, and yaw are all corrected. The use
of quaternion error states and multiplicative correction avoids singularities and ensures
$SO(3)$-consistency.

\subsection{Velocity and Position}
The OU prior on $\bm a_w$ prevents the double integration of white noise, which would otherwise
cause variance to grow unbounded with $t^3$. Instead, OU-driven $\bm v,\bm p$ form a stationary
linear Gaussian system with bounded steady-state covariance. This is the mathematical reason
why the filter can produce meaningful $\bm v,\bm p$ estimates even without external aiding.

\subsection{Third Integral $S$}
Adding $S$ explicitly and applying the pseudo-measurement renders the system detectable. The
covariance of $S$ remains finite, and numerical coupling between $(\bm v,\bm p)$ and $S$ is
regularized. Without this pseudo-measurement, $P$ would inflate in the nullspace of the
triple integrator.

\subsection{Biases}
Biases $\bm b_g,\bm b_a$ are modeled as random walks. While RW processes are not stationary,
their covariance is bounded by construction because $Q_{bg},Q_{ba}$ are finite. Convergence to
the true biases occurs if there is sufficient excitation: rotation for gyro biases, and tilt
changes or known excitation spectra for accelerometer biases. Temperature-dependent drift is
modeled via a known coefficient $K_a$, which further stabilizes bias estimates over varying
conditions.

\subsection{Effect of Gains and $R$}
The Joseph form update ensures $P^+\succeq 0$. Gains $K_k$ are finite as long as
$R\succ 0$. Too small $R$ may cause filter instability (over-trusting noisy sensors);
too large $R$ leads to slow convergence. Proper tuning per Section~\ref{sec:tuning} ensures
stable, well-damped innovations.


\section{Implementation and Numerical Hygiene}
\label{sec:implementation}

Robust embedded deployment requires attention to numerical details. We summarize the
techniques used in this implementation.

\subsection{Quaternion Normalization}
After every update, the quaternion is normalized:
\[
q \leftarrow \frac{q}{\|q\|}.
\]
Even small floating-point drift can otherwise cause $q$ to leave $SO(3)$ over long runs.

\subsection{Covariance Symmetrization}
After propagation and update, the covariance is symmetrized:
\[
P \leftarrow \tfrac{1}{2}(P+P^\top).
\]
This prevents accumulation of asymmetry due to numerical roundoff, which can otherwise
lead to negative eigenvalues and breakdowns in square-root or LDLT factorizations.

\subsection{Joseph Form}
As emphasized in Section~\ref{sec:kalman-update}, the Joseph update
\[
P^+ = (I-KC)P^-(I-KC)^\top + KRK^\top
\]
is used rather than the simplified $(I-KC)P^-$. This guarantees positive semidefiniteness.

\subsection{Matrix Exponentials}
On desktop platforms, Van Loan discretization uses $\exp(M)$ from Eigen’s MatrixFunctions.
On embedded platforms, $\exp(A)$ is approximated with Pad\'e(6) plus scaling and squaring.
This ensures consistency between simulation and embedded implementations.

\subsection{Handling Small Angles}
For small $\theta$, Rodrigues’ formula and quaternion increments use Taylor expansions to
avoid loss of precision. For example,
\[
\sin\theta \approx \theta - \tfrac{\theta^3}{6},\qquad
1-\cos\theta \approx \tfrac{\theta^2}{2} - \tfrac{\theta^4}{24}.
\]

\subsection{Bias and Temperature Compensation}
Accelerometer biases are corrected by the model
\[
\bm b_a(T) = \bm b_{a0} + K_a\,(T-T_{\rm ref}),
\]
with $T_{\rm ref}\approx 35^\circ{\rm C}$. This linear law is simple but captures the
dominant effect of thermal drift. Gyro biases are assumed temperature-compensated at
hardware level, or sufficiently stable to treat as RW at the filter level.

\subsection{Sanity Monitoring}
In practice, one should monitor:
\begin{itemize}
\item Innovation covariance consistency ($\tilde y^\top S^{-1}\tilde y \sim \chi^2$).
\item Gain magnitudes (no saturation or collapse).
\item Bias estimates (bounded, plausible trends).
\item Quaternion norms (close to 1).
\end{itemize}
These diagnostics help detect sensor faults or mis-tuned parameters.


\section{Future Work}
\label{sec:future-work}

While the presented filter already produces consistent estimates of attitude,
velocity, displacement, and biases under realistic sea-state conditions,
further improvements can be made in the area of \emph{adaptive tuning}.

\subsection{Motivation}
At present, process and measurement noise covariances ($Q$ and $R$) as well as
the OU parameters $(\tau,\sigma)$ are chosen \emph{a priori} from datasheets,
calibration, and sea-state heuristics (see Section~\ref{sec:tuning}).
However, ocean wave spectra and sensor environments can vary significantly:
\begin{itemize}
\item Sea states may shift from calm to rough within hours.
\item Sensor noise levels may change with temperature, aging, or magnetic interference.
\item Platform dynamics (e.g.\ moored vs.\ free-floating buoys) alter excitation and bias observability.
\end{itemize}
A fixed set of tuning parameters cannot optimally capture all conditions.

\subsection{Adaptive OU Parameters}
The OU correlation time $\tau$ and stationary variance $\sigma^2$ could be adapted online:
\begin{itemize}
\item Estimate dominant acceleration period from recent $\bm a_w$ spectra.
\item Map this to $\tau$ via the relation $f_c = 1/(2\pi\tau)$ (see Eq.~\ref{eq:tau-map}).
\item Scale $\sigma$ from the observed RMS of innovations, to reflect actual sea-state accelerations.
\end{itemize}
This would preserve bounded covariance while tailoring dynamics to the encountered waves.

\subsection{Adaptive Measurement Covariances}
Measurement covariances $R_a$ and $R_m$ could be adapted by monitoring residual statistics:
\begin{equation}
\hat R = \frac{1}{N}\sum_{k=1}^N \tilde y_k \tilde y_k^\top,
\end{equation}
with $\tilde y_k$ the innovations. If $\hat R$ exceeds the nominal $R$, inflate $R$ to
prevent over-confidence; if $\hat R$ is consistently smaller, reduce $R$ to allow tighter tracking.

\subsection{Adaptive Process Noise for Biases}
Gyro and accelerometer bias random walks could be adapted based on innovation covariance mismatch.
For example, when residuals show excess low-frequency drift not captured by current $Q_{bg}$,
increase it; when residuals are over-smoothed, decrease it. This prevents both filter divergence
and unnecessary noise injection.

\subsection{Practical Considerations}
Adaptive tuning must be implemented cautiously:
\begin{itemize}
\item Use long-enough windows ($N\gg 1$) for residual statistics to avoid oscillatory gains.
\item Apply upper and lower bounds on $\tau$, $\sigma$, $Q$, $R$ to ensure stability.
\item Couple adaptation with sanity monitors (Section~\ref{sec:implementation}).
\end{itemize}

\subsection{Summary}
The most promising next step is to replace fixed tuning with adaptive laws that update
OU parameters, $R$, and $Q$ based on observed residuals and excitation. This would allow
a single filter configuration to robustly handle calm seas, storm seas, and everything in
between, without manual re-tuning.

\section{Conclusion}
\label{sec:conclusion}

We have developed and analyzed a multiplicative EKF extended with linear
states for velocity, displacement, and their integrals, driven by a latent
Ornstein--Uhlenbeck acceleration model. By combining quaternion-based attitude
propagation, Van Loan discretization for OU-driven integrators, Pad\'e(6)
approximants for embedded matrix exponentials, and pseudo-measurements to
stabilize triple integrals, the filter achieves bounded-error estimates under
realistic ocean wave conditions. Biases are handled explicitly, with additional
temperature-dependent compensation for accelerometer drift. Observability and
stability analyses demonstrate the well-posedness of the approach, and tuning
guidelines offer practical recipes for deployment.

Future work will focus on adaptive tuning of OU parameters and noise covariances,
enabling the same filter structure to self-adjust to varying sea states and sensor
environments without manual reconfiguration.

\vspace{1em}
\noindent\textbf{Acknowledgments.}  
The author thanks the open-source community for foundational implementations
on which this work builds.

\begin{thebibliography}{99}

\bibitem{Jazwinski1970}
Jazwinski, A. H. (1970).  
\emph{Stochastic Processes and Filtering Theory}.  
Academic Press, New York.

\bibitem{BrownHwang1997}
Brown, R. G., and Hwang, P. Y. C. (1997).  
\emph{Introduction to Random Signals and Applied Kalman Filtering}.  
3rd ed., Wiley.

\bibitem{Maybeck1979}
Maybeck, P. S. (1979).  
\emph{Stochastic Models, Estimation, and Control}, Vol. 1.  
Academic Press.

\bibitem{CrassidisMarkley2003}
Crassidis, J. L., and Markley, F. L. (2003).  
“Attitude Estimation Using a Quaternion-Based Extended Kalman Filter.”  
\emph{Journal of Guidance, Control, and Dynamics}, 26(4), 536–542.

\bibitem{Shuster1993}
Shuster, M. D. (1993).  
“A Survey of Attitude Representations.”  
\emph{Journal of the Astronautical Sciences}, 41(4), 439–517.

\bibitem{UhlenbeckOrnstein1930}
Uhlenbeck, G. E., and Ornstein, L. S. (1930).  
“On the Theory of the Brownian Motion.”  
\emph{Physical Review}, 36(5), 823–841.

\bibitem{Gardiner2009}
Gardiner, C. W. (2009).  
\emph{Stochastic Methods: A Handbook for the Natural and Social Sciences}.  
4th ed., Springer.

\bibitem{VanLoan1978}
Van Loan, C. F. (1978).  
“Computing Integrals Involving the Matrix Exponential.”  
\emph{IEEE Transactions on Automatic Control}, 23(3), 395–404.

\bibitem{MolerVanLoan2003}
Moler, C., and Van Loan, C. (2003).  
“Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later.”  
\emph{SIAM Review}, 45(1), 3–49.

\bibitem{Higham2005}
Higham, N. J. (2005).  
“The Scaling and Squaring Method for the Matrix Exponential Revisited.”  
\emph{SIAM Journal on Matrix Analysis and Applications}, 26(4), 1179–1193.

\bibitem{Soderstrom1989}
S{\"o}derstr{\"o}m, T., and Stoica, P. (1989).  
\emph{System Identification}.  
Prentice Hall.

\bibitem{Farrell2012}
Farrell, J. A. (2012).  
\emph{Aided Navigation: GPS with High Rate Sensors}.  
McGraw–Hill, New York.

\bibitem{Shin2005}
Shin, E.-H. (2005).  
“Estimation Techniques for Low-Cost Inertial Navigation.”  
Ph.D. thesis, Dept. of Geomatics Engineering, University of Calgary.

\bibitem{ElSheimy2004}
El-Sheimy, N., Hou, H., and Niu, X. (2004).  
“Analysis and Modeling of Inertial Sensors Using Allan Variance.”  
\emph{IEEE Transactions on Instrumentation and Measurement}, 57(1), 140–149.

\bibitem{TeunissenMontenbruck2017}
Teunissen, P. J. G., and Montenbruck, O. (eds.) (2017).  
\emph{Springer Handbook of Global Navigation Satellite Systems}.  
Springer.

\bibitem{Ochi1998}
Ochi, M. K. (1998).  
\emph{Ocean Waves: The Stochastic Approach}.  
Cambridge University Press.

\bibitem{Holthuijsen2007}
Holthuijsen, L. H. (2007).  
\emph{Waves in Oceanic and Coastal Waters}.  
Cambridge University Press.

\bibitem{Cheng2014}
Cheng, Y., and Farrell, J. A. (2014).  
“Integration of MEMS IMU and Magnetometers for Low-Cost Navigation.”  
\emph{IEEE Transactions on Instrumentation and Measurement}, 63(3), 552–562.

\end{thebibliography}

\end{document}



