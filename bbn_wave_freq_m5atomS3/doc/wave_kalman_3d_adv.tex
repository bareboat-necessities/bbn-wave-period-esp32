\documentclass[10pt]{extarticle}
\usepackage{amsmath, amssymb, amsfonts, bm}
\usepackage{geometry, setspace}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\usepackage{nccmath, relsize}
\usepackage{array, booktabs, makecell, adjustbox}

% Make inline math slightly smaller
\everymath{\smaller}

% Make display equations typeset in \small
\everydisplay\expandafter{\the\everydisplay\small}

% Reduce spacing before/after headings
\titlespacing*{\section}{0pt}{1.0ex plus .2ex}{0.6ex}
\titlespacing*{\subsection}{0pt}{0.8ex plus .2ex}{0.4ex}
\titlespacing*{\subsubsection}{0pt}{0.6ex plus .2ex}{0.3ex}

% Make section fonts smaller (like textbooks)
\titleformat{\section}{\normalfont\small\bfseries}{\thesection}{0.8em}{}
\titleformat{\subsection}{\normalfont\small\itshape}{\thesubsection}{0.8em}{}
\titleformat{\subsubsection}{\normalfont\footnotesize\itshape}{\thesubsubsection}{0.8em}{}

\geometry{letterpaper, margin=0.65in}
\setstretch{0.95}

\title{A Multiplicative EKF with Latent OU Acceleration for Drift-Robust Wave Kinematics: \\
Theory, Discretization (Rodrigues, Analytic), and Temperature-Dependent Bias Compensation}
\author{Mikhail Grushinskiy}
\date{2025}

\begin{document}
\maketitle

\begin{abstract}
We present a detailed mathematical development of a quaternion multiplicative EKF (MEKF) fused with an extended 
linear kinematic chain for ocean-wave motion estimation. 
The method augments attitude (with optional gyroscope and accelerometer bias) by the linear states velocity $\bm v$, displacement $\bm p$, 
and the integral of displacement $\bm S$, driven by a \emph{latent} world-frame acceleration $\bm a_w$ modeled as an Ornstein--Uhlenbeck (OU) process. The OU prior confers stationary variance and realistic temporal correlation for the latent acceleration, which slows the drift growth in integrated states compared to white-noise forcing. It does not strictly bound the variance of integrated displacement, but ensures covariance growth of displacement is polynomially slower and numerically manageable.
Biases are explicitly modeled: gyroscope bias as a random walk, accelerometer bias both as random walk and as systematic temperature-dependent drift. 
A pseudo-measurement is introduced on $\bm S$ to control double integral divergence. 
We derive continuous- and discrete-time process models, show Rodrigues and Analytic discretizations, and derive explicit Jacobians for accelerometer and magnetometer updates. 
Finally, we discuss tuning strategies and the prospect of adaptive parameter estimation.
\end{abstract}

\section{Introduction}
Estimating wave-induced motion from an IMU is fundamentally challenging. The IMU provides angular velocity and specific force, 
but extracting displacement requires double integration if treated naively. Biases and noise cause unbounded drift. 
Moreover, wave accelerations are not white but correlated in time, reflecting the physics of sea surface gravity waves. 
Thus, a specialized state-space formulation is required. 

The \texttt{Kalman3D\_Wave} filter is designed with these challenges in mind. 
It is a multiplicative EKF in which the quaternion is the central orientation representation, 
augmented by translational kinematics driven by a latent Ornstein--Uhlenbeck acceleration process. 

The contributions of this paper are:
\begin{itemize}
\item A rigorous derivation of the state-space model with biases and OU latent acceleration.
\item Exact and approximate discretization methods.
\item Explicit Jacobians for accelerometer and magnetometer updates.
\item Introduction of a pseudo-measurement on the triple integral to suppress drift.
\item Discussion of tuning and future adaptive strategies.
\end{itemize}

\section{State Definition}

We define the full augmented error-state vector as
\begin{equation}
\bm{x} =
\begin{bmatrix}
\delta\bm\theta & \bm b_g & \bm v & \bm p & \bm S & \bm a_w & \bm b_{a0}
\end{bmatrix}^\top \in \mathbb{R}^n,
\label{eq:state_vector}
\end{equation}
with the following components:
\begin{itemize}
\item $\delta\bm\theta \in \mathbb{R}^3$: the \emph{attitude error}, parameterized as a small rotation vector in the multiplicative EKF framework.
\item $\bm b_g \in \mathbb{R}^3$: the gyroscope bias, modeled as a random walk driven by white noise.
\item $\bm v \in \mathbb{R}^3$: the velocity of the sensor in the world (NED) frame.
\item $\bm p \in \mathbb{R}^3$: the displacement (position) in the world frame.
\item $\bm S \in \mathbb{R}^3$: the \emph{integral of displacement}, i.e.
  \[
  \bm S(t) = \int_0^t \bm p(\tau)\, d\tau,
  \]
  which, although not physically measured, serves as a control variable for drift suppression.
\item $\bm a_w \in \mathbb{R}^3$: the latent world-frame acceleration, modeled as an Ornstein--Uhlenbeck (OU) process to enforce stationary variance of acceleration and realistic temporal correlation, though its integrals' variances remain unbounded but growing slower than for white noise.
\item $\bm b_{a0} \in \mathbb{R}^3$: the baseline accelerometer bias at a fixed reference temperature $T_\text{ref}$.
\end{itemize}

The \emph{temperature-dependent accelerometer bias model} is given by
\begin{equation}
\bm b_a(T) = \bm b_{a0} + \bm k_a \,\big(T - T_\text{ref}\big),
\label{eq:accel_bias_temp}
\end{equation}
where $\bm k_a \in \mathbb{R}^3$ is a vector of per-axis temperature coefficients. 
This accounts for the systematic drift of MEMS accelerometers with changing temperature, 
typically on the order of $0.002$--$0.005 \,\text{m/s}^2$ per ${}^\circ$C in modern sensors.

\subsection{Quaternion Representation}
The orientation of the body frame with respect to the world (NED) frame is represented by a quaternion $q \in \mathbb{H}$. 
We adopt a right-multiplicative error convention:
\begin{equation}
q^+ = q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\otimes$ denotes quaternion multiplication and
\begin{equation}
\delta q(\delta\bm\theta) \approx
\begin{bmatrix}
1 \\ \tfrac{1}{2}\delta\bm\theta
\end{bmatrix}.
\label{eq:small_angle_quaternion}
\end{equation}

\subsection{State Dimension}
The total state dimension is
\[
n =
\begin{cases}
18 & \text{if gyro and accel biases are included}, \\
15 & \text{if only gyro bias is included}, \\
12 & \text{if no biases are included}.
\end{cases}
\]
This flexible design allows the filter to adapt to the sensor suite available and to application requirements.

\section{Attitude Dynamics}

The orientation of the sensor platform is represented by a quaternion $q(t)$ mapping from the world 
(North--East--Down, NED) frame to the body frame. 
We employ the \emph{multiplicative extended Kalman filter} (MEKF) convention: 
the mean orientation is stored as a quaternion $q$, while the small attitude error 
is represented as a 3-vector $\delta\bm\theta$ living in the tangent space $\mathfrak{so}(3)$.

\subsection{Quaternion Kinematics}
The quaternion time evolution is governed by the angular velocity measured by the gyroscope:
\begin{equation}
\dot q(t) = \tfrac{1}{2} \, \Omega(\bm\omega_b(t)) \, q(t),
\label{eq:quat_kinematics}
\end{equation}
where $\bm\omega_b$ is the angular velocity in the body frame, 
and $\Omega(\bm\omega)$ is the quaternion multiplication matrix:
\begin{equation}
\Omega(\bm\omega) =
\begin{bmatrix}
0 & -\bm\omega^\top \\
\bm\omega & -[\bm\omega]_\times
\end{bmatrix}.
\end{equation}

Here $[\bm\omega]_\times$ denotes the skew-symmetric matrix such that $[\bm\omega]_\times \bm v = \bm\omega \times \bm v$.

\subsection{Error Representation}
Instead of estimating $q$ directly, the MEKF keeps track of the \emph{error quaternion}:
\begin{equation}
q = \hat q \otimes \delta q(\delta\bm\theta),
\end{equation}
where $\hat q$ is the nominal quaternion and $\delta q$ is a small correction. 
This choice ensures that the state covariance remains minimal in dimension (3 instead of 4), 
while preserving the unit norm of $q$.

\subsection{Rodrigues' Formula for Discrete Propagation}
To propagate the quaternion over a sampling interval $\Delta t$, 
we use the matrix exponential of the skew operator:
\begin{equation}
R(t+\Delta t) = R(t) \exp\!\left([\bm\omega]_\times \Delta t\right).
\label{eq:rot_exp}
\end{equation}

Rodrigues' rotation formula provides a closed form for this exponential:
\begin{equation}
\exp([\bm\omega]_\times \Delta t) = I 
+ \frac{\sin \theta}{\theta} [\bm u]_\times
+ \frac{1 - \cos \theta}{\theta^2} [\bm u]_\times^2,
\label{eq:rodrigues}
\end{equation}
where $\theta = \|\bm\omega\| \Delta t$ is the rotation angle, 
and $\bm u = \bm\omega / \|\bm\omega\|$ is the unit rotation axis.

\paragraph{Interpretation.}
Equation \eqref{eq:rodrigues} shows how the rotation matrix can be expressed 
directly in terms of the angular increment. 
For small angles, a Taylor expansion recovers the familiar linearized form:
\[
\exp([\bm\omega]_\times \Delta t) \approx I + [\bm\omega]_\times \Delta t + \tfrac{1}{2} [\bm\omega]_\times^2 \Delta t^2.
\]
This makes Rodrigues' formula both numerically stable and exact for finite rotations.

\subsection{Error-State Dynamics}
The small attitude error $\delta\bm\theta$ evolves according to
\begin{equation}
\dot{\delta\bm\theta} = -[\bm\omega_b - \bm b_g]_\times \, \delta\bm\theta - \delta\bm b_g + \bm n_\theta,
\label{eq:att_err_dyn}
\end{equation}
where $\bm b_g$ is the gyro bias and $\bm n_\theta$ is gyro measurement noise mapped into the attitude error dynamics.

Equation \eqref{eq:att_err_dyn} highlights two important points:
\begin{enumerate}
\item The gyro bias directly drives the attitude error, which motivates its inclusion in the state vector.
\item The dynamics are linear in the small error, allowing standard EKF propagation.
\end{enumerate}

\section{Ornstein--Uhlenbeck (OU) Process: Mean/Variance, Autocorrelation, Discrete-Time, and Coefficient Integrals}
\label{sec:ou-detailed}

This section develops the OU dynamics used for the latent world-frame acceleration $a(t)$
(per axis; the 3D case is component-wise identical). We give the continuous-time SDE,
solve it in closed form, derive the exact discrete-time equivalent, compute the
autocorrelation and spectrum, and then derive the integral coefficients that appear
in the discrete propagation of $(v,p,S)$.

\subsection{Two Equivalent Formulations of OU}
There are two standard ways to write the OU process.

\paragraph{(i) It\^o SDE form.}
\begin{equation}
da(t) \;=\; -\frac{1}{\tau}\,a(t)\,dt \;+\; \sqrt{\frac{2\sigma^2}{\tau}}\; dW_t,
\label{eq:ou-ito}
\end{equation}
where $\tau>0$ is the correlation time, $\sigma^2$ is the stationary variance, and $W_t$
is a standard Wiener process.

\paragraph{(ii) LTI with white process input.}
\begin{equation}
\dot a(t) \;=\; -\frac{1}{\tau}\,a(t) \;+\; w(t),\qquad
\mathbb{E}\big[w(t)w(s)\big] \;=\; \Sigma_c\,\delta(t-s),
\label{eq:ou-lti}
\end{equation}
with the white-noise \emph{power} chosen as
\begin{equation}
\Sigma_c \;=\; \frac{2}{\tau}\,\sigma^2,
\label{eq:ou-sigmapower}
\end{equation}
which makes the stationary variance of $a(t)$ equal to $\sigma^2$ (same as in \eqref{eq:ou-ito}).

Both forms are equivalent; the It\^o diffusion coefficient $\sqrt{2\sigma^2/\tau}$ corresponds to
the white-noise power $\Sigma_c = 2\sigma^2/\tau$ in the LTI description.

\subsection{Closed-Form Solution and Moments}
Solving \eqref{eq:ou-lti} with constant $\tau$ over $[t,t+\Delta]$:
\begin{equation}
a(t+\Delta) \;=\; \rho\,a(t) \;+\; \int_0^\Delta e^{-(\Delta-s)/\tau}\,w(t+s)\,ds,
\qquad
\rho \;\triangleq\; e^{-\Delta/\tau}.
\label{eq:ou-sol}
\end{equation}
Therefore,
\begin{align}
\mathbb{E}[\,a(t+\Delta)\,|\,a(t)=a_k] &= \rho\,a_k, \label{eq:ou-mean}\\
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] 
&= \int_0^\Delta\!\!\int_0^\Delta e^{-(\Delta-s)/\tau}e^{-(\Delta-u)/\tau}\,\Sigma_c\,\delta(s-u)\,ds\,du
\nonumber\\
&= \Sigma_c \int_0^\Delta e^{-2(\Delta-s)/\tau}\,ds
= \frac{\Sigma_c\tau}{2}\,\big(1-\rho^2\big).
\end{align}
Using \eqref{eq:ou-sigmapower} gives the standard result
\begin{equation}
\mathrm{Var}[\,a(t+\Delta)\,|\,a(t)=a_k] \;=\; \sigma^2\big(1-\rho^2\big).
\label{eq:ou-var-step}
\end{equation}

\subsection{Autocorrelation and Spectrum}
At stationarity,
\begin{equation}
R_a(\Delta) \;\triangleq\; \mathbb{E}\big[a(t)\,a(t+\Delta)\big] \;=\; \sigma^2\,e^{-|\Delta|/\tau}.
\label{eq:ou-autocorr}
\end{equation}
The one-sided power spectral density (PSD) is the Lorentzian
\begin{equation}
S_a(\omega) \;=\; \int_{-\infty}^{\infty} R_a(\Delta)\,e^{-j\omega \Delta}\,d\Delta
\;=\; \frac{2\sigma^2\tau}{1+(\omega\tau)^2}.
\label{eq:ou-psd}
\end{equation}
Hence $\tau$ sets the correlation (and an approximate cutoff $f_c \approx (2\pi\tau)^{-1}$),
and $\sigma$ sets the RMS magnitude of $a$.

\subsection{Exact Discrete-Time Equivalent (AR(1))}
Discretizing at step $\Delta$,
\begin{equation}
a_{k+1} \;=\; \rho\,a_k \;+\; \eta_k,
\qquad
\rho \;=\; e^{-\Delta/\tau}, 
\qquad
\eta_k \sim \mathcal{N}\!\big(0,\ \sigma^2(1-\rho^2)\big),
\label{eq:ou-ar1}
\end{equation}
with $\eta_k$ independent of $a_k$. This AR(1) exactly preserves the OU mean, variance,
and autocorrelation at sampling instants.

\subsection{Integral Functionals of OU: Deterministic Coefficient Derivations}
Let $a(t)$ follow OU as above. Over one step $[t,t+\Delta]$, define the weighted
integrals needed by the kinematic chain:
\begin{equation}
I_0 \;\triangleq\; \int_0^\Delta a(t+s)\,ds,\qquad
I_1 \;\triangleq\; \int_0^\Delta (\Delta-s)\,a(t+s)\,ds,\qquad
I_2 \;\triangleq\; \int_0^\Delta \frac{(\Delta-s)^2}{2}\,a(t+s)\,ds.
\label{eq:ou-I012}
\end{equation}
Using the conditional mean $\mathbb{E}[a(t+s)\mid a(t){=}a_k]=e^{-s/\tau} a_k$,
the \emph{deterministic coefficients} multiplying $a_k$ in the discrete updates are:
\begin{align}
c_v(\Delta,\tau)
&= \int_0^\Delta e^{-s/\tau}\,ds
= \tau\big(1-e^{-\Delta/\tau}\big)
\;=\; \tau E_0, 
\label{eq:cv-ou}
\\
c_p(\Delta,\tau)
&= \int_0^\Delta (\Delta-s)\,e^{-s/\tau}\,ds
= \tau\Big(\Delta - \tau\big(1-e^{-\Delta/\tau}\big)\Big)
\;=\; \tau E_1, 
\label{eq:cp-ou}
\\
c_S(\Delta,\tau)
&= \int_0^\Delta \frac{(\Delta-s)^2}{2}\,e^{-s/\tau}\,ds
= \tau\left(\frac{\Delta^2}{2} - \tau\Delta + \tau^2\big(1-e^{-\Delta/\tau}\big)\right)
\;=\; \tau E_2.
\label{eq:cS-ou}
\end{align}
We have introduced the convenient polynomials
\begin{equation}
E_0(\Delta,\tau)=1-\rho,\qquad
E_1(\Delta,\tau)=\Delta - \tau(1-\rho),\qquad
E_2(\Delta,\tau)=\frac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho),
\label{eq:E012}
\end{equation}
with $\rho=e^{-\Delta/\tau}$. For later use (e.g., in higher-order kernels), also define
\begin{equation}
E_3(\Delta,\tau)
\;\triangleq\;
\frac{\Delta^3}{6} - \frac{\tau\Delta^2}{2} + \tau^2\Delta - \tau^3(1-\rho).
\label{eq:E3}
\end{equation}

\paragraph{Resulting exact conditional means.}
The discrete kinematic updates with OU-driven acceleration are
\begin{align}
v_{k+1} &= v_k + c_v(\Delta,\tau)\,a_k + \varepsilon_v, \label{eq:v-disc-mean}\\
p_{k+1} &= p_k + \Delta v_k + c_p(\Delta,\tau)\,a_k + \varepsilon_p, \label{eq:p-disc-mean}\\
S_{k+1} &= S_k + \Delta p_k + \frac{\Delta^2}{2} v_k + c_S(\Delta,\tau)\,a_k + \varepsilon_S, \label{eq:S-disc-mean}
\end{align}
where the zero-mean random terms $(\varepsilon_v,\varepsilon_p,\varepsilon_S)$ are jointly Gaussian and arise from the
stochastic part of $a(t+s)$ (i.e., the integral of the noise term in \eqref{eq:ou-sol} through the integrator kernels).

\subsection{Variances and Covariances of the Integrated OU Terms}
Let $R_a(\delta)=\sigma^2 e^{-|\delta|/\tau}$ be the stationary autocorrelation \eqref{eq:ou-autocorr}.
For any weights $w(s)$, $u(s)$ supported on $[0,\Delta]$,
\begin{equation}
\mathrm{Cov}\!\left[\int_0^\Delta w(s) a(t+s)\,ds,\ \int_0^\Delta u(s) a(t+s)\,ds\right]
= \int_0^\Delta\!\!\int_0^\Delta w(s)\,u(u)\,R_a(s-u)\,ds\,du.
\label{eq:kernel-cov}
\end{equation}
Using symmetry $R_a(|s-u|)=\sigma^2 e^{-|s-u|/\tau}$ and splitting the domain $0\le u\le s\le \Delta$,
\begin{align}
\mathrm{Cov}
&= 2\sigma^2 \int_0^\Delta \left(\int_0^s w(s)\,u(u)\,e^{-(s-u)/\tau}\,du\right) ds.
\label{eq:kernel-cov-2}
\end{align}
We now list the key entries needed to build the exact discrete process covariance $Q_d$
for $(v,p,S,a)$ in one step. Denote $\rho=e^{-\Delta/\tau}$, and recall \eqref{eq:E012}.

\paragraph{Single-integral variance and cross-covariance.}
With $w_0(s)=1$ and $w_1(s)=\Delta-s$,
\begin{align}
\mathrm{Var}\!\left[\int_0^\Delta a\right]
&= 2\sigma^2 \tau\,E_1,
\label{eq:var-I0}
\\
\mathrm{Cov}\!\left[\int_0^\Delta a,\ \int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\,E_2,
\label{eq:cov-I0-I1}
\\
\mathrm{Var}\!\left[\int_0^\Delta (\Delta-s)a\right]
&= 2\sigma^2 \tau\left(\frac{\Delta^3}{3} - \tau\Delta^2 + 2\tau^2\Delta - 2\tau^3(1-\rho)\right).
\label{eq:var-I1}
\end{align}

\paragraph{Cross-covariances with $a_{k+1}$.}
From $\mathrm{cov}\{a(t+s),a(t+\Delta)\}=\sigma^2 e^{-(\Delta-s)/\tau}$:
\begin{align}
\mathrm{Cov}\!\left[\int_0^\Delta a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2 \tau (1-\rho)
= \sigma^2 \tau E_0,
\label{eq:cov-I0-ak1}
\\
\mathrm{Cov}\!\left[\int_0^\Delta (\Delta-s)a(t+s)\,ds,\ a_{k+1}\right]
&= \sigma^2\left(\tau^2(1-\rho) - \tau\Delta\,\rho\right).
\label{eq:cov-I1-ak1}
\end{align}
(Analogous expressions for the $S$-weighted integral follow the same recipe but are longer; see the coefficient identity below.)

\paragraph{General exponential--polynomial identity.}
All required integrals reduce to the elementary identity
\begin{equation}
\int_0^\Delta s^n e^{-s/\tau} ds
= \tau^{n+1}\,n!\left(1 - e^{-\Delta/\tau}\sum_{j=0}^{n}\frac{(\Delta/\tau)^j}{j!}\right),
\qquad n=0,1,2,\dots,
\label{eq:exp-poly}
\end{equation}
together with the binomial expansion $(\Delta-s)^m=\sum_{i=0}^m \binom{m}{i}\Delta^{m-i}(-s)^i$.
Using \eqref{eq:exp-poly} yields closed forms for \emph{all} entries of $Q_d$ (including the $S$-block).

\subsection{Exact Axis Transition for $(v,p,S,a)$}
Collecting the deterministic coefficients \eqref{eq:cv-ou}--\eqref{eq:cS-ou} and the OU state update \eqref{eq:ou-ar1},
the \emph{exact} one-axis transition matrix is
\begin{equation}
\Phi_{\text{axis}}(\Delta,\tau) \;=\;
\begin{bmatrix}
1 & 0 & 0 & \tau(1-\rho)\\
0 & 1 & 0 & \tau\big(\Delta - \tau(1-\rho)\big)\\
0 & 0 & 1 & \tau\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right)\\
0 & 0 & 0 & \rho
\end{bmatrix}.
\label{eq:Phi-axis-ou}
\end{equation}
In 3D, $\Phi_{vpsa}=\Phi_{\text{axis}}\otimes I_3$.

\paragraph{Discrete process covariance $Q_d$.}
The random vector $(\varepsilon_v,\varepsilon_p,\varepsilon_S,\eta_a)$ has covariance determined by
\eqref{eq:var-I0}--\eqref{eq:var-I1}, \eqref{eq:cov-I0-ak1}--\eqref{eq:cov-I1-ak1}, and their $S$-weighted analogs
(constructed via \eqref{eq:exp-poly}). For compactness and guaranteed SPD, we also obtain $Q_d$
by the Analytic method applied to the continuous pair $(A,G,\Sigma_c)$ (see the discretization section):
\[
Q_d \;=\; \int_0^\Delta e^{A s} G \Sigma_c G^\top e^{A^\top s} ds.
\]
Both routes are analytically equivalent; Analytic is the numerically convenient implementation.

\subsection{Small-Step Expansions and Limiting Cases}
For $\Delta\ll\tau$ ($\rho \approx 1-\Delta/\tau$):
\begin{align}
c_v &= \tau(1-\rho) \approx \Delta - \tfrac{\Delta^2}{2\tau} + \mathcal{O}(\Delta^3),\\
c_p &= \tau\big(\Delta - \tau(1-\rho)\big) \approx \tfrac{\Delta^2}{2} - \tfrac{\Delta^3}{6\tau} + \mathcal{O}(\Delta^4),\\
c_S &= \tau\!\left(\tfrac{\Delta^2}{2} - \tau\Delta + \tau^2(1-\rho)\right) \approx \tfrac{\Delta^3}{6} - \tfrac{\Delta^4}{24\tau} + \mathcal{O}(\Delta^5).
\end{align}
These match the deterministic integrals of a constant acceleration over small intervals.

As $\tau\to\infty$ with $\sigma^2$ fixed, $\rho\to 1$, the innovation variance $\sigma^2(1-\rho^2)\to 0$,
and $a$ becomes quasi-constant (very slow mean reversion). As $\tau\to 0$, $\rho\to 0$ and
the process approaches temporally white acceleration (with variance $\sigma^2$ at the sampling instants),
recovering the uncorrelated case.

\section{Analytic Discretization of the Extended OU--Driven Kinematic Chain}

In the extended state Kalman filter formulation, we augment the quaternion
error states with linear navigation variables representing velocity
$v$, displacement $p$, and the triple integral $S \equiv \int p \, dt$,
all driven by a latent Ornstein--Uhlenbeck (OU) acceleration process $a$.
For a single spatial axis (the three Cartesian axes are decoupled and
identical), the continuous-time dynamics can be written as:
%
\begin{equation}
\begin{aligned}
\dot v(t) &= a(t), \\
\dot p(t) &= v(t), \\
\dot S(t) &= p(t), \\
\dot a(t) &= -\tfrac{1}{\tau} a(t) + w(t),
\end{aligned}
\label{eq:cont_system}
\end{equation}
%
where $\tau > 0$ is the correlation time of the OU process, and $w(t)$
is a scalar white-noise input with variance $q_c = \tfrac{2\sigma^2}{\tau}$,
ensuring that the stationary variance of $a(t)$ equals $\sigma^2$.

\subsection{State Transition Matrix $\Phi$}

To obtain the exact discrete-time system over a time step $h$, we compute
%
\begin{equation}
x_{k+1} = \Phi(h) \, x_k + \eta_k, \qquad
\Phi(h) = \exp(A h),
\end{equation}
%
where $x = [\, v,\, p,\, S,\, a \,]^\top$ and $A$ is the drift matrix
of~\eqref{eq:cont_system}:
%
\begin{equation}
A =
\begin{bmatrix}
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & -1/\tau
\end{bmatrix}.
\end{equation}

We compute the matrix exponential $\exp(Ah)$ in closed form by propagating
each state in turn, integrating the OU decay exactly. Writing
$\alpha = e^{-h/\tau}$, one finds:
%
\begin{align}
a_{k+1} &= \alpha \, a_k, \\[0.5ex]
v_{k+1} &= v_k + \phi_{va}(h,\tau) \, a_k, \\
p_{k+1} &= p_k + h v_k + \phi_{pa}(h,\tau) \, a_k, \\
S_{k+1} &= S_k + h p_k + \tfrac{1}{2} h^2 v_k + \phi_{Sa}(h,\tau) \, a_k,
\end{align}
with coefficients
\begin{align}
\phi_{va}(h,\tau) &= \tau \bigl(1 - \alpha \bigr), \label{eq:phi_va}\\
\phi_{pa}(h,\tau) &= \tau h - \tau^2 \bigl(1 - \alpha \bigr), \label{eq:phi_pa}\\
\phi_{Sa}(h,\tau) &= \tfrac{1}{2}\tau h^2 - \tau^2 h + \tau^3 \bigl(1 - \alpha \bigr). \label{eq:phi_Sa}
\end{align}

Thus the discrete transition matrix takes the form
%
\begin{equation}
\Phi(h) =
\begin{bmatrix}
1 & 0 & 0 & \phi_{va}(h,\tau) \\
h & 1 & 0 & \phi_{pa}(h,\tau) \\
\frac{1}{2}h^2 & h & 1 & \phi_{Sa}(h,\tau) \\
0 & 0 & 0 & \alpha
\end{bmatrix}.
\end{equation}

\paragraph{Consistency checks.}
For small $h \ll \tau$, Taylor expanding $e^{-h/\tau}$ yields
$\phi_{va} \approx h$, $\phi_{pa} \approx h^2/2$, and
$\phi_{Sa} \approx h^3/6$, recovering the pure integrator chain.  
As $\tau \to \infty$, the process tends to constant acceleration and
$\Phi(h)$ again matches the kinematic integrator.  

\subsection{Process Noise Covariance $Q_d$}

The exact discrete process noise covariance is obtained via the
Analytic integral:
%
\begin{equation}
Q_d(h) = \int_0^h \Phi(\xi)\, G q_c G^\top \Phi(\xi)^\top \, d\xi,
\end{equation}
%
where $G = [\,0\;\;0\;\;0\;\;1\,]^\top$.
This integral simplifies because only the $a$--component is driven.
Defining the driven column
%
\begin{equation}
k(\xi) \equiv \Phi(\xi)\,G =
\begin{bmatrix}
\tau \bigl(1 - e^{-\xi/\tau}\bigr) \\
\tau \xi - \tau^2\bigl(1 - e^{-\xi/\tau}\bigr) \\
\frac{1}{2}\tau \xi^2 - \tau^2 \xi + \tau^3\bigl(1 - e^{-\xi/\tau}\bigr) \\
e^{-\xi/\tau}
\end{bmatrix},
\end{equation}
we obtain
\begin{equation}
Q_d(h) = q_c \int_0^h k(\xi) k(\xi)^\top \, d\xi.
\end{equation}

Each entry of $Q_d$ is thus a scalar integral of the form
$\int_0^h f(\xi)\, d\xi$, where $f$ is a product of polynomials in $\xi$
and exponentials $e^{-\xi/\tau}$ or $e^{-2\xi/\tau}$. These can all be
evaluated in closed form using repeated integration by parts.

\subsubsection{Auxiliary Integrals}

Define the primitives
\begin{align}
C_n &= \int_0^h \xi^n \, d\xi = \frac{h^{n+1}}{n+1}, \\
A_n &= \int_0^h \xi^n e^{-\xi/\tau} \, d\xi, \\
B_n &= \int_0^h \xi^n e^{-2\xi/\tau} \, d\xi,
\end{align}
for $n=0,1,2,3$. Explicitly,
\begin{align}
A_0 &= \tau \bigl(1 - e^{-h/\tau}\bigr), \\
A_1 &= \tau^2 \bigl(1 - e^{-h/\tau}\bigr) - \tau h e^{-h/\tau}, \\
A_2 &= 2\tau^3 \bigl(1 - e^{-h/\tau}\bigr) - \tau h(h+2\tau) e^{-h/\tau}, \\
A_3 &= 6\tau^4 \bigl(1 - e^{-h/\tau}\bigr) - \tau h(h^2 + 3\tau h + 6\tau^2) e^{-h/\tau}, \\
B_0 &= \tfrac{\tau}{2} \bigl(1 - e^{-2h/\tau}\bigr).
\end{align}

\subsubsection{Closed-Form Entries}

As an illustration, we derive several entries explicitly:

\paragraph{Variance of $a$.}
\begin{equation}
Q_{aa} = q_c \int_0^h e^{-2\xi/\tau} d\xi = q_c \, B_0.
\end{equation}

\paragraph{Cross-covariance $v$--$a$.}
\begin{equation}
Q_{va} = q_c \int_0^h \tau\bigl(1 - e^{-\xi/\tau}\bigr) e^{-\xi/\tau}\, d\xi
= q_c \,\tau \bigl(A_0 - B_0\bigr).
\end{equation}

\paragraph{Variance of $v$.}
\begin{equation}
Q_{vv} = q_c \int_0^h \bigl[\tau(1 - e^{-\xi/\tau})\bigr]^2 d\xi
= q_c\, \tau^2 \bigl(C_0 - 2A_0 + B_0\bigr).
\end{equation}

\paragraph{Cross-covariance $p$--$a$.}
\begin{equation}
Q_{pa} = q_c \bigl( \tau A_1 - \tau^2 A_0 + \tau^2 B_0 \bigr).
\end{equation}

\paragraph{Variance of $p$.}
\begin{equation}
Q_{pp} = q_c \Bigl( \tau^2 C_2 - 2\tau^3 C_1 + 2\tau^3 A_1
+ \tau^4 C_0 - 2\tau^4 A_0 + \tau^4 B_0 \Bigr).
\end{equation}

Analogous expansions yield the entries involving $S$. For example,
\begin{align}
Q_{Sa} &= q_c \Bigl( \tfrac{1}{2}\tau A_2 - \tau^2 A_1 + \tau^3 A_0 - \tau^3 B_0 \Bigr), \\
Q_{SS} &= q_c \Bigl( \tfrac{1}{4}\tau^2 C_4 - \tau^3 C_3 + 2\tau^4 C_2
 - 2\tau^5 C_1 + \tau^6 C_0 - \tau^4 A_2 + 2\tau^5 A_1
 - 2\tau^6 A_0 + \tau^6 B_0 \Bigr).
\end{align}

\subsection{Consistency Limits}

For small step size $h$, expanding exponentials shows that
\begin{align}
Q_{vv} &\approx q_c \frac{h^3}{3}, \\
Q_{pp} &\approx q_c \frac{h^5}{20}, \\
Q_{SS} &\approx q_c \frac{h^7}{140},
\end{align}
consistent with integrating white acceleration noise through three
integrator stages. For $\tau \to \infty$ the OU process tends to a
constant acceleration, and the formulas reduce to the classical
integrated white-noise results. For $\tau \to 0$ the acceleration
vanishes within each step and $Q_d \to 0$.

\subsection{Multi-Axis Block Form}

The derivations above were presented for a single spatial axis, since the
system dynamics are decoupled across $x,y,z$. In practice, the filter
maintains a 12-dimensional linear subsystem
%
\[
x_{\mathrm{lin}} =
\begin{bmatrix}
v \\ p \\ S \\ a
\end{bmatrix}
\in \mathbb{R}^{12}, \qquad
v,p,S,a \in \mathbb{R}^3,
\]
%
where each component vector represents the respective $[x,y,z]$ axes.

\subsubsection{Block Transition Matrix}

The full discrete transition is block-diagonal across axes. Denote the
scalar $4\times 4$ transition derived in the previous subsection as
$\Phi_{\mathrm{axis}}(h,\tau)$. Then
%
\begin{equation}
\Phi_{\mathrm{lin}}(h,\tau) =
\mathrm{blockdiag}\bigl( \Phi_{\mathrm{axis}}(h,\tau),
\Phi_{\mathrm{axis}}(h,\tau),
\Phi_{\mathrm{axis}}(h,\tau) \bigr),
\label{eq:Phi_lin_block}
\end{equation}
%
which is a $12\times 12$ matrix with each block coupling
$v_i,p_i,S_i,a_i$ for axis $i\in\{x,y,z\}$.

Expanding the block structure explicitly, the state ordering is
$[\, v_x,v_y,v_z,\, p_x,p_y,p_z,\, S_x,S_y,S_z,\, a_x,a_y,a_z\,]^\top$,
and the transition matrix has the schematic form
%
\begin{equation}
\Phi_{\mathrm{lin}} =
\begin{bmatrix}
I_3 & 0   & 0   & \Phi_{va} I_3 \\
h I_3 & I_3 & 0   & \Phi_{pa} I_3 \\
\tfrac{1}{2}h^2 I_3 & h I_3 & I_3 & \Phi_{Sa} I_3 \\
0   & 0   & 0   & \alpha I_3
\end{bmatrix},
\end{equation}
%
where the coefficients $\Phi_{va}, \Phi_{pa}, \Phi_{Sa}, \alpha$
are scalar functions of $(h,\tau)$ given in
Eqs.~\eqref{eq:phi_va}--\eqref{eq:phi_Sa}.

\subsubsection{Block Process Noise Covariance}

Similarly, the discrete process noise covariance is block-diagonal across
axes. Denote the scalar $4\times 4$ covariance derived in the previous
subsection as $Q_{\mathrm{axis}}(h,\tau,\sigma^2)$. Then
%
\begin{equation}
Q_{d,\mathrm{lin}}(h,\tau,\Sigma_{\!a}) =
\mathrm{blockdiag}\bigl(
Q_{\mathrm{axis}}(h,\tau,\sigma_x^2),\;
Q_{\mathrm{axis}}(h,\tau,\sigma_y^2),\;
Q_{\mathrm{axis}}(h,\tau,\sigma_z^2)
\bigr),
\label{eq:Qd_lin_block}
\end{equation}
%
where $\Sigma_{\!a} = \mathrm{diag}(\sigma_x^2, \sigma_y^2, \sigma_z^2)$
is the stationary covariance of the OU accelerations.
Each block corresponds to the covariance of $[v_i,p_i,S_i,a_i]$ driven
by the axis-specific OU noise.

\paragraph{Explicit form.}
For each axis,
\[
Q_{\mathrm{axis}} =
q_c \begin{bmatrix}
K_{vv} & K_{pv} & K_{Sv} & K_{va} \\
K_{pv} & K_{pp} & K_{Sp} & K_{pa} \\
K_{Sv} & K_{Sp} & K_{SS} & K_{Sa} \\
K_{va} & K_{pa} & K_{Sa} & K_{aa}
\end{bmatrix}, \qquad
q_c = \tfrac{2}{\tau}\sigma^2,
\]
with entries $K_{\cdot}$ given by the closed forms in the previous
subsection (Eqs.~for $Q_{vv}, Q_{pp}, Q_{SS},$ etc.).

\subsubsection{Implementation Note}

This block structure is precisely what is assembled in the filter code:
for each axis, the $4\times 4$ $(\Phi_{\mathrm{axis}},Q_{\mathrm{axis}})$
pair is computed and then inserted into the larger $12\times 12$ blocks.
The resulting $\Phi_{\mathrm{lin}}$ and $Q_{d,\mathrm{lin}}$ are then
placed at offsets $(\texttt{OFF\_V},\texttt{OFF\_V})$ inside the full
extended Jacobian and covariance, ensuring consistency across all three
Cartesian directions.

\subsection{Computational Comparison: Analytic vs Analytic Formulas}

Two approaches exist for computing the discrete transition
$\Phi(h)$ and process noise covariance $Q_d(h)$:

\begin{enumerate}
  \item \textbf{Analytic method.}  
  Form the augmented matrix
  \[
  \mathcal{M} =
  \begin{bmatrix}
    -A h & G \Sigma_c G^\top h \\
    0    & A^\top h
  \end{bmatrix},
  \]
  where $\Sigma_c$ is the continuous-time noise intensity,
  and compute $\exp(\mathcal{M})$. This yields $\Phi(h)$ and $Q_d(h)$
  simultaneously by block extraction.

  \item \textbf{Analytic closed form.}  
  Exploit the special structure of $A$ (a chain of integrators driven by
  a first-order OU process) to derive exact formulas for each entry
  of $\Phi(h)$ and $Q_d(h)$ in terms of exponentials and polynomials
  (Eqs.~\eqref{eq:phi_va}--\eqref{eq:phi_Sa} and
  Eq.~\eqref{eq:Qd_lin_block}).
\end{enumerate}

\paragraph{Equivalence.}
Both methods are mathematically identical: the analytic formulas
are obtained by evaluating the same integrals that the Analytic
construction encodes in matrix-exponential form. Numerical experiments
confirm that for a wide range of $(h,\tau,\sigma^2)$ the difference
between the two methods is at machine precision (below $10^{-14}$ in
double precision).

\paragraph{Numerical stability.}
The Analytic exponential requires computing $\exp(\mathcal{M})$ of
dimension $24 \times 24$ for the 12-state system. On embedded systems,
this can be costly and sensitive to roundoff. The analytic formulas,
by contrast, reduce to evaluating a small set of exponentials
$e^{-h/\tau}$, $e^{-2h/\tau}$ and polynomial terms, which are both
stable and efficient.

\paragraph{Computational cost.}
The analytic method requires only $O(1)$ scalar exponentials and
polynomial arithmetic, yielding a fixed and predictable computational
cost per time step. 

\paragraph{Practical recommendation.}
On desktop platforms, Analytic is useful for validation and as a
reference implementation, since it guarantees correctness by direct
matrix exponential. For real-time operation, especially on microcontrollers,
the analytic formulas are strongly preferable: they deliver exact
results with minimal computation and are numerically robust across
all relevant regimes of $(h,\tau)$.

\section{Sensor Bias Models and Compensation}
\label{sec:biases}

A central element in inertial navigation Kalman filters is the explicit modeling of 
\emph{sensor biases}. Without including bias states, residual integration of even tiny 
constant offsets rapidly dominates wave kinematics. In this section we justify the bias 
state design of the filter, detail their dynamics, and explain temperature compensation.

\subsection{Gyroscope Bias}
Let the gyroscope measurement be
\begin{equation}
\bm\omega_{\rm meas}(t) \;=\; \bm\omega(t) + \bm b_g(t) + \bm\eta_g(t),
\label{eq:gyro-meas}
\end{equation}
where $\bm\omega(t)$ is the true body angular velocity, $\bm b_g(t)$ is the bias,
and $\bm\eta_g(t)$ is zero-mean white noise. In the filter, $\bm b_g$ is included as
a \emph{random walk} process:
\begin{equation}
\dot{\bm b}_g(t) = w_{bg}(t),\qquad
\mathbb{E}[w_{bg}(t)w_{bg}(s)^\top] = Q_{bg}\,\delta(t-s).
\label{eq:gyro-bias-model}
\end{equation}
This is the simplest effective choice: gyroscope biases drift slowly with temperature, vibration,
and time, and a random walk captures unmodeled bias variation while allowing the filter to absorb
constant offsets. The discrete process covariance for $\bm b_g$ is
\begin{equation}
Q_{bg,d} = Q_{bg}\,\Delta,
\label{eq:gyro-bias-qd}
\end{equation}
consistent with the implementation in the extended process covariance $Q_a$.

\subsection{Accelerometer Bias with Temperature Drift}
Accelerometer measurement model:
\begin{equation}
\bm f_{\rm meas}(t) = \bm f_b(t) + \bm b_a(t,T) + \bm\eta_a(t),
\label{eq:acc-meas}
\end{equation}
where $\bm f_b=R_{wb}(a_w-g)$ is the specific force predicted from states, and 
$\bm b_a(t,T)$ is the bias dependent on both slow random drift and \emph{temperature} $T$.

\paragraph{Nominal bias.}
We model the bias at a reference temperature $T_0$ as a state $\bm b_{a0}(t)$,
propagated as a random walk:
\begin{equation}
\dot{\bm b}_{a0}(t) = w_{ba}(t),\qquad
\mathrm{Cov}[w_{ba}] = Q_{ba}.
\label{eq:acc-bias-base}
\end{equation}

\paragraph{Temperature coefficient.}
Empirically, MEMS accelerometers exhibit nearly linear bias variation with temperature.
Thus we extend the bias model as
\begin{equation}
\bm b_a(t,T) = \bm b_{a0}(t) + K_a\,(T-T_0),
\label{eq:acc-bias-temp}
\end{equation}
where $K_a=\mathrm{diag}(k_x,k_y,k_z)$ is a diagonal matrix of temperature coefficients
in units of $[\mathrm{m/s^2}/^\circ\mathrm{C}]$.

\paragraph{Filter incorporation.}
In measurement prediction, \eqref{eq:acc-bias-temp} adds to the predicted force. During
filter updates, the Jacobian wrt the bias state is identity, while the temperature term
acts as a known deterministic offset. Explicit modeling prevents spurious innovation
terms whenever the platform warms or cools.

\subsection{Summary of Bias Roles}
\begin{itemize}
\item \textbf{Gyroscope bias:} modeled as random walk, essential for avoiding long-term
drift in integrated orientation.
\item \textbf{Accelerometer bias:} modeled as random walk plus linear temperature
dependence, essential for consistent specific force innovations and preventing systematic
tilt misestimation.
\item \textbf{Covariances $Q_{bg},Q_{ba}$:} tuning these governs how fast the filter
is willing to adapt biases; too small values cause long convergence times, too large values
inject excess noise.
\end{itemize}
The chosen model balances computational simplicity with sufficient realism for IMU-grade
sensors such as BMI270 and BMM150.


\section{Pseudo-Measurement on the Third Integral}
\label{sec:pseudo-S}

A unique element of this filter is the inclusion of the third integral state
\[
S(t) \;=\; \int_0^t p(\tau)\,d\tau,
\]
where $p(t)$ is the displacement in world coordinates.
This integral accumulates position over time and thus represents a 
\emph{triple integration} of acceleration. Without regularization, $S(t)$
would be dominated by low-frequency drift and quickly diverge.

\subsection{Why Include $S$ at All?}
One might ask why include $S$ when displacement $p$ already contains drift.
The answer lies in the structure of stochastic processes: by explicitly modeling
$S$, we can apply a pseudo-measurement that constrains the lowest-frequency drift
mode of the integrator chain. This prevents the covariance from exploding in the
null space of repeated integration.

\subsection{Zero Pseudo-Measurement}
The pseudo-measurement enforces the soft constraint
\begin{equation}
z_S = 0 \;\;\approx\;\; H_S\,x + \nu_S,
\label{eq:ps-meas}
\end{equation}
where $H_S$ selects the $S$ block of the state vector, and $\nu_S\sim\mathcal{N}(0,R_S)$
is fictitious Gaussian noise. In implementation:
\begin{equation}
H_S = \begin{bmatrix}0 & \cdots & I_3 & \cdots & 0\end{bmatrix},
\qquad
R_S = \mathrm{diag}(\sigma_{S,x}^2,\,\sigma_{S,y}^2,\,\sigma_{S,z}^2).
\label{eq:ps-HR}
\end{equation}

\subsection{Kalman Update}
The innovation for the pseudo-measurement is simply
\begin{equation}
\tilde y = -S_k,
\end{equation}
since the measurement is identically zero. The Kalman gain is
\begin{equation}
K_S = P H_S^\top (H_S P H_S^\top + R_S)^{-1},
\end{equation}
and the update is
\begin{align}
x^+ &= x + K_S\tilde y,\\
P^+ &= (I-K_SH_S)P(I-K_SH_S)^\top + K_SR_SK_S^\top.
\end{align}
Thus $S$ is softly driven toward zero.

\subsection{Interpretation of $R_S$}
The choice of $R_S$ is critical. A small $R_S$ enforces a tight pseudo-measurement,
essentially pinning $S\approx 0$ and aggressively damping drift. A large $R_S$ relaxes
the constraint, letting $S$ wander but still suppressing drift.

Physically, $S$ has no direct observable meaning (it is an auxiliary integral).
Therefore, $R_S$ does not correspond to sensor noise, but rather to a 
\emph{design knob}:
\begin{itemize}
\item If the the double integral drift is high use smaller $R_S$.
\item If slow drift is acceptable, increase $R_S$ to reduce artificial feedback.
\end{itemize}

\subsection{Effect on Stability}
By including $S$ and its pseudo-measurement, in linear systems terminology, the augmented
system becomes \emph{detectable}: even though $S$ is unobservable in a strict sense, the 
pseudo-measurement provides an artificial observation that stabilizes the filter numerics and
uncontrolled growth of displacement.

\paragraph{Key insight.} 
The $S$ pseudo-measurement is not “cheating,” but rather a principled
regularization. It adds just enough fictitious information to reduce drift in double integrals of noisy acceleration, 
while leaving physically observable states ($q,v,p,a_w$) unbiased.

\section{Measurement Models: Accelerometer and Magnetometer}
\label{sec:meas-models}

The filter fuses inertial and magnetic measurements to anchor attitude and
linear states. Here we derive the measurement functions and their Jacobians.

\subsection{Accelerometer Measurement Model}
The accelerometer provides the specific force in the body frame:
\begin{equation}
\bm f_{\rm meas} 
= R_{wb}\,\big(\bm a_w - \bm g\big) + \bm b_a(T) + \bm\eta_a,
\label{eq:accel-meas}
\end{equation}
where
\begin{itemize}
\item $R_{wb}$ is the world-to-body rotation,
\item $\bm a_w$ is the latent world-frame acceleration (OU state),
\item $\bm g = (0,0,g)$ is gravity in NED coordinates,
\item $\bm b_a(T)$ is the accelerometer bias with temperature drift,
\item $\bm\eta_a \sim \mathcal{N}(0,R_a)$ is zero-mean measurement noise.
\end{itemize}

\paragraph{Role.}
At rest, \eqref{eq:accel-meas} reduces to $\bm f_{\rm meas} \approx R_{wb}\,(-\bm g)$,
which gives roll and pitch observability. During motion, $\bm a_w$ separates wave-induced
accelerations from gravity, preventing tilt corruption.

\subsection{Accelerometer Jacobians}
The innovation function is
\[
\bm y_a = \bm f_{\rm meas} - \hat{\bm f}_b,
\qquad
\hat{\bm f}_b = R_{wb}(\hat{\bm a}_w - \bm g) + \hat{\bm b}_a(T).
\]
Linearizing yields Jacobians:
\begin{align}
\frac{\partial \hat{\bm f}_b}{\partial \delta\bm\theta} &= -\,[\hat{\bm f}_b]_\times,
\label{eq:accel-jac-att}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm a_w} &= R_{wb},
\label{eq:accel-jac-aw}\\
\frac{\partial \hat{\bm f}_b}{\partial \bm b_a} &= I_3,
\label{eq:accel-jac-bias}
\end{align}
where $\delta\bm\theta$ is the small-angle error and $[\cdot]_\times$ is the skew-symmetric matrix.

\subsection{Magnetometer Measurement Model}
The magnetometer senses the geomagnetic field in the body frame:
\begin{equation}
\bm m_{\rm meas} = R_{wb}\,\bm B_w + \bm\eta_m,
\label{eq:mag-meas}
\end{equation}
where $\bm B_w$ is the known reference magnetic field in the world frame,
and $\bm\eta_m \sim \mathcal{N}(0,R_m)$ is measurement noise.

\paragraph{Role.}
The magnetometer provides yaw observability. By choosing $\bm B_w$ appropriately:
\begin{itemize}
\item Use the full geomagnetic vector for full 3D correction,
\item Use the horizontal projection $(B_N,B_E,0)$ for yaw-only correction.
\end{itemize}

\subsection{Magnetometer Jacobians}
Predicted measurement:
\[
\hat{\bm m}_b = R_{wb}\bm B_w.
\]
Linearization:
\begin{equation}
\frac{\partial \hat{\bm m}_b}{\partial \delta\bm\theta} = -\,[\hat{\bm m}_b]_\times.
\label{eq:mag-jac-att}
\end{equation}
No other state appears in \eqref{eq:mag-meas}, so all other Jacobians are zero.

\subsection{Combined Measurement Vector}
The full measurement vector is
\[
\bm y = \begin{bmatrix}\bm f_{\rm meas}\\ \bm m_{\rm meas}\end{bmatrix},
\qquad
\hat{\bm y} = \begin{bmatrix}\hat{\bm f}_b\\ \hat{\bm m}_b\end{bmatrix},
\]
with innovation covariance
\begin{equation}
S = C P C^\top + R,
\qquad
R = \begin{bmatrix} R_a & 0 \\ 0 & R_m \end{bmatrix},
\label{eq:meas-cov}
\end{equation}
where $C$ is the stacked Jacobian from \eqref{eq:accel-jac-att}--\eqref{eq:accel-jac-bias} and \eqref{eq:mag-jac-att}.

\subsection{Physical Interpretation}
\begin{itemize}
\item The accelerometer primarily constrains roll and pitch, while respecting wave accelerations
through $\bm a_w$.
\item The magnetometer anchors yaw against drift, with flexibility to restrict to yaw-only updates.
\item Together they ensure full 3D attitude observability.
\item Inclusion of $\bm b_a(T)$ makes the innovations insensitive to slow sensor thermal drift.
\end{itemize}

\section{Extended State Transition Matrix}
\label{sec:transition}

The extended state vector is
\begin{equation}
x = \begin{bmatrix}
\delta\bm\theta & \bm b_g & \bm v & \bm p & \bm S & \bm a_w & \bm b_a
\end{bmatrix}^\top,
\label{eq:state-vector}
\end{equation}
where each block is $3\times 1$. Depending on configuration, $\bm b_g$ and $\bm b_a$ may be omitted.

\subsection{Attitude Error Dynamics}
From \eqref{eq:att_err_dyn}, the linearized error propagation is
\begin{equation}
\dot{\delta\bm\theta} = -[\bm\omega_b - \bm b_g]_\times \,\delta\bm\theta - \delta\bm b_g + n_\theta.
\label{eq:att-err-dyn2}
\end{equation}
Discretization via Rodrigues’ formula \eqref{eq:rodrigues} yields the discrete block
\begin{equation}
F_{\theta\theta} \;=\; I - \sin\theta [\hat{\bm u}]_\times + (1-\cos\theta)[\hat{\bm u}]_\times^2,
\label{eq:F-att}
\end{equation}
with $\theta = \|\bm\omega_b-\bm b_g\|\Delta$ and $\hat{\bm u}=(\bm\omega_b-\bm b_g)/\|\bm\omega_b-\bm b_g\|$.
For small $\theta$, expand as
\[
F_{\theta\theta} \approx I - [\bm\omega_b-\bm b_g]_\times \Delta + \tfrac{1}{2}[\bm\omega_b-\bm b_g]_\times^2 \Delta^2.
\]

The cross term wrt gyro bias is
\begin{equation}
F_{\theta b_g} = -I\,\Delta.
\label{eq:F-att-bg}
\end{equation}

\subsection{Velocity–Position–Integral Chain}
For one axis, dynamics are
\[
\dot v = a_w,\qquad
\dot p = v,\qquad
\dot S = p.
\]
This yields the companion form matrix
\begin{equation}
A_{vps} =
\begin{bmatrix}
0 & 0 & 0\\
1 & 0 & 0\\
0 & 1 & 0
\end{bmatrix},\qquad
B_{vps} = \begin{bmatrix}1\\0\\0\end{bmatrix}.
\label{eq:Avps}
\end{equation}
Coupled with OU acceleration $\dot a_w = -\tfrac{1}{\tau}a_w + w$, the full
axis dynamics are
\[
\dot{\bm x}_{\rm lin} = 
\underbrace{\begin{bmatrix}
A_{vps} & B_{vps}\\
0 & -\tfrac{1}{\tau}
\end{bmatrix}}_{A_{\rm axis}}
\bm x_{\rm lin} + 
\underbrace{\begin{bmatrix}0\\0\\0\\1\end{bmatrix}}_{G_{\rm axis}}w.
\]

The discrete transition for this $4\times 4$ block is obtained from
Analytic discretization (Sec.), giving
\begin{equation}
\Phi_{\rm axis} = e^{A_{\rm axis}\Delta}.
\label{eq:phi-axis}
\end{equation}
Explicit entries involve integrals $E_0,E_1,E_2$ derived in the OU section.

\subsection{OU Acceleration Block}
For each axis:
\begin{equation}
F_{aa} = e^{-\Delta/\tau},\qquad
Q_{aa} = \sigma^2 \big(1-e^{-2\Delta/\tau}\big).
\label{eq:ou-discrete}
\end{equation}
These match the AR(1) equivalent of the continuous OU process.

\subsection{Accelerometer Bias Block}
Accelerometer bias $\bm b_a$ evolves as a random walk:
\begin{equation}
\dot{\bm b}_a = w_{ba},\qquad
Q_{ba,d} = Q_{ba}\Delta.
\label{eq:accel-bias-rw}
\end{equation}
Its discrete transition is
\[
F_{b_ab_a} = I,\qquad
Q_{b_ab_a} = Q_{ba}\Delta.
\]

\subsection{Full Transition Matrix}
Assembling all blocks yields
\begin{equation}
F =
\begin{bmatrix}
F_{\theta\theta} & F_{\theta b_g} & 0 & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0 & 0 & 0\\
0 & 0 & \Phi_{vv} & \Phi_{vp} & \Phi_{vS} & \Phi_{va} & 0\\
0 & 0 & \Phi_{pv} & \Phi_{pp} & \Phi_{pS} & \Phi_{pa} & 0\\
0 & 0 & \Phi_{Sv} & \Phi_{Sp} & \Phi_{SS} & \Phi_{Sa} & 0\\
0 & 0 & \Phi_{av} & \Phi_{ap} & \Phi_{aS} & \Phi_{aa} & 0\\
0 & 0 & 0 & 0 & 0 & 0 & I
\end{bmatrix},
\label{eq:F-full}
\end{equation}
where each $\Phi_{\cdot\cdot}$ block is $3\times 3$ (Kronecker product with $I_3$).
Cross-couplings from OU integrals populate $\Phi_{va},\Phi_{pa},\Phi_{Sa}$,
with exact formulas given in the OU derivation.

\subsection{Process Noise Covariance}
The block structure of $Q$ mirrors that of $F$. In particular:
\begin{itemize}
\item $Q_{\theta\theta}$ and $Q_{\theta b_g}$ from gyro noise,
\item $Q_{vpsa}$ from OU integrals (Eq.~\ref{eq:qd-integral}),
\item $Q_{b_a}$ from random walk bias (Eq.~\ref{eq:accel-bias-rw}).
\end{itemize}

\section{Kalman Update, Joseph Form, and the Role of the Measurement Covariance}
\label{sec:kalman-update}

This section presents the measurement-update step used throughout the filter for (i) the stacked
accelerometer+magnetometer measurement and (ii) the $S$-pseudo-measurement. We highlight the
\emph{Joseph} covariance update, which is numerically more robust than the basic $P^+=(I-KC)P$ form,
and we discuss how the measurement covariance $R$ influences observability, gain magnitude, and
steady-state performance.

\subsection{General Linearized Measurement Model}
Let the (possibly stacked) measurement be written as
\begin{equation}
\bm y_k = h(x_k) + \bm \nu_k,\qquad \bm \nu_k \sim \mathcal{N}(0,R),
\label{eq:meas-gen}
\end{equation}
with linearization about the predicted state $\hat x_k^-$
\begin{equation}
\hat{\bm y}_k^- \;=\; h(\hat x_k^-),\qquad
C_k \;=\; \left.\frac{\partial h}{\partial x}\right|_{\hat x_k^-}.
\label{eq:meas-linearization}
\end{equation}
The innovation and its covariance are
\begin{align}
\tilde{\bm y}_k &= \bm y_k - \hat{\bm y}_k^-,
\label{eq:innovation}\\
S_k &= C_k P_k^- C_k^\top + R.
\label{eq:innovation-cov}
\end{align}
The Kalman gain is computed by a symmetric positive-definite solve in $S_k$
\begin{equation}
K_k \;=\; P_k^- C_k^\top S_k^{-1}.
\label{eq:kalman-gain}
\end{equation}

\subsection{Joseph-Stabilized Covariance Update}
The \emph{Joseph form} ensures $P_k^+\succeq 0$ up to roundoff and avoids deficit-rank artifacts:
\begin{equation}
P_k^+ \;=\; (I - K_k C_k)\,P_k^-\, (I - K_k C_k)^\top + K_k R K_k^\top.
\label{eq:joseph}
\end{equation}
In practice, we also enforce symmetry by
\begin{equation}
P_k^+ \leftarrow \tfrac{1}{2}\big(P_k^+ + P_k^{+\top}\big),
\label{eq:symmetrize}
\end{equation}
which is benign and combats small numerical asymmetries.

\subsection{Accelerometer + Magnetometer Stack}
For the stacked measurement
\[
\bm y_k = 
\begin{bmatrix}
\bm f_{{\rm meas},k}\\ \bm m_{{\rm meas},k}
\end{bmatrix},\qquad
\hat{\bm y}_k^- =
\begin{bmatrix}
R_{wb}(\hat{\bm a}_{w,k}^- - \bm g) + \hat{\bm b}_{a,k}^-(T_k)\\[2pt]
R_{wb}\,\bm B_w
\end{bmatrix},
\]
the Jacobian takes the block form
\begin{equation}
C_k \;=\;
\begin{bmatrix}
-\,[\hat{\bm f}_{b,k}^-]_\times & 0 & 0 & 0 & 0 & R_{wb} & I_3\\[2pt]
-\,[\hat{\bm m}_{b,k}^-]_\times & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix},
\label{eq:C-acc-mag}
\end{equation}
where the columns correspond to $(\delta\bm\theta,\ \bm b_g,\ \bm v,\ \bm p,\ \bm S,\ \bm a_w,\ \bm b_a)$.
The measurement covariance is block diagonal:
\begin{equation}
R \;=\; 
\begin{bmatrix}
R_a & 0\\ 0 & R_m
\end{bmatrix}.
\label{eq:R-acc-mag}
\end{equation}
Equation \eqref{eq:C-acc-mag} expresses three key physical couplings:
(i) attitude enters both sensors via a skew-symmetric sensitivity,
(ii) the latent world-acceleration \(\bm a_w\) enters the accelerometer through the rotation \(R_{wb}\),
(iii) the accelerometer bias enters additively.

\subsection{Pseudo-Measurement on $S$}
The $S$-pseudo-measurement \((z_S=0)\) uses
\begin{equation}
C_{S} \;=\; \begin{bmatrix} 0 & 0 & 0 & 0 & I_3 & 0 & 0 \end{bmatrix},\qquad
R_S \;=\; \mathrm{diag}(\sigma_{S,x}^2,\sigma_{S,y}^2,\sigma_{S,z}^2).
\label{eq:C-R-S}
\end{equation}
Innovation: $\tilde y_S = - \hat S_k^-$. Gain and update follow \eqref{eq:kalman-gain}--\eqref{eq:joseph}.

\subsection{Role of the Measurement Covariance $R$}
The matrix $R$ determines (i) the relative trust between model and measurements,
(ii) the steady-state gains, and (iii) the balance between noise rejection and responsiveness.

\paragraph{Accelerometer $R_a$.}
Larger $R_a$ reduces the accelerometer’s leverage, protecting attitude from transient linear accelerations
but slowing bias and $a_w$ convergence. Smaller $R_a$ tightens roll/pitch but risks injecting wave-induced
accelerations into attitude unless $\bm a_w$ is modeled (as here).

\paragraph{Magnetometer $R_m$.}
Larger $R_m$ weakens yaw correction (useful near magnetic disturbances). If yaw-only updates are desired,
set the world reference \(\bm B_w\) horizontal; then \([\hat{\bm m}_b]_\times\) only corrects yaw.

\paragraph{Pseudo $R_S$.}
The parameter $R_S$ is a \emph{design knob}: it is not sensor noise, but a regularization weight. 
Making $R_S$ small aggressively suppresses triple-integral drift (pinning $S\!\approx\!0$); making it large
allows slower drift while still bounding covariance growth. In all cases, \eqref{eq:joseph} ensures the update
remains numerically stable.

\subsection{Observability and Conditioning}
With accelerometer and magnetometer, the attitude is fully observable (roll/pitch from gravity, yaw from magnetic field).
The latent OU \(\bm a_w\) decouples true linear acceleration from gravity so that roll/pitch estimates remain unbiased in motion.
The $S$-pseudo-measurement ensures detectability of the double-integrator chain.

\subsection{Post-Update Quaternion Correction}
After the state update, the small-angle correction is applied multiplicatively to the quaternion:
\begin{equation}
\delta q(\delta\bm\theta) \approx \begin{bmatrix}1\\ \tfrac{1}{2}\delta\bm\theta\end{bmatrix},
\qquad
q^+ \;=\; q^- \otimes \delta q(\delta\bm\theta),
\qquad
\delta\bm\theta \leftarrow 0.
\label{eq:quat-correct}
\end{equation}
This preserves unit norm and keeps the attitude error minimal (on the tangent space) for the next cycle.


\section{Numerical Methods for Discretization and Matrix Exponentials}
\label{sec:numerical-methods}

The extended filter requires repeated discretization of continuous-time dynamics.
Three key techniques are employed: Rodrigues’ rotation formula, Analytic’s
block-matrix exponential method. We now detail each.

\subsection{Rodrigues’ Formula for Attitude Propagation}
For a body angular velocity $\bm\omega$ and timestep $\Delta$, the quaternion update
is
\[
q_{k+1} = q_k \otimes \exp\!\left(\tfrac{\Delta}{2}\bm\omega\right).
\]
In matrix form, the equivalent rotation matrix update uses Rodrigues’ formula:
\begin{equation}
R_{k+1} = R_k\left(I + \sin\theta [\hat{\bm u}]_\times +
(1-\cos\theta)[\hat{\bm u}]_\times^2\right),
\label{eq:rodrigues-final}
\end{equation}
with $\theta = \|\bm\omega\|\Delta$ and $\hat{\bm u}=\bm\omega/\|\bm\omega\|$.
For small $\theta$, the series expansion yields
\[
R_{k+1} \approx R_k\Big(I + [\bm\omega]_\times \Delta + \tfrac{1}{2}[\bm\omega]_\times^2 \Delta^2\Big),
\]
which is consistent with the truncated exponential.

\paragraph{Role.}
This exact formula avoids numerical drift and provides a consistent
linearization for Jacobians.

\subsection{Analytic Discretization for Linear Subsystems}
For linear SDEs of the form
\[
\dot x = A x + G w,\quad \mathbb{E}[w(t)w(s)^\top] = Q_c\delta(t-s),
\]
the discrete-time equivalent over $\Delta$ is
\begin{equation}
\begin{bmatrix}
\Phi & Q_d\\ 0 & \Phi^{-\top}
\end{bmatrix}
=
\exp\!\left(
\begin{bmatrix}
-A\Delta & GQ_cG^\top\Delta\\
0 & A^\top\Delta
\end{bmatrix}
\right).
\label{eq:van-loan-final}
\end{equation}
The transition is $\Phi = e^{A\Delta}$, and the discrete covariance is
\[
Q_d = \int_0^\Delta e^{As}\,GQ_cG^\top e^{A^\top s}\,ds
= \Phi\,M_{12},
\]
from the block exponential construction. This is the \emph{exact} discretization method
for linear Gaussian systems.

\paragraph{Application here.}
For the 12D subsystem $(v,p,S,a_w)$, Analytic yields the exact coupling
coefficients between OU acceleration and its integrals. 

\subsection{Summary}
\begin{itemize}
\item Rodrigues’ formula: exact, closed-form for SO(3), preserves attitude orthogonality.
\item Analytic: exact state+covariance discretization for linear OU-extended systems.
\end{itemize}
Together, they provide consistency across desktop prototyping and embedded deployment.

\section{Observability and Identifiability}
\label{sec:observability}

This section analyzes what can (and cannot) be inferred from the proposed sensing setup.
We use a local (linearized) observability perspective for intuition, with emphasis on
the roles of gravity, magnetic field, the OU latent acceleration, and the $S$ pseudo-measurement.

\subsection{Setup and Linearized Model}
Let the extended state be
\[
x^\top=\begin{bmatrix}
\delta\bm\theta^\top & \bm b_g^\top & \bm v^\top & \bm p^\top & \bm S^\top & \bm a_w^\top & \bm b_a^\top
\end{bmatrix}.
\]
Over one step (about a nominal trajectory) the linearized dynamics and output read
\begin{equation}
\dot x = A x + G w,
\qquad
y = C x + \nu,
\label{eq:lin-obs}
\end{equation}
where $A$ is the Jacobian of the continuous dynamics, $G$ the process noise input, and
$C$ the stacked Jacobian of the accelerometer, magnetometer, and (optionally) $S$ pseudo-measurement.
The discrete observability matrix over $L$ steps is
\begin{equation}
\mathcal{O}_L \;\triangleq\; \begin{bmatrix}
C\\
C\Phi\\
C\Phi^2\\
\vdots\\
C\Phi^{L-1}
\end{bmatrix},
\qquad
\Phi = e^{A\Delta},
\label{eq:obs-matrix}
\end{equation}
and local (linear) observability is indicated by $\mathrm{rank}(\mathcal{O}_L)$.

\subsection{Attitude Observability}
\paragraph{Accelerometer alone.} With $\bm f_{\rm meas}=R_{wb}(\bm a_w-\bm g)+\bm b_a+\eta_a$,
and \emph{at rest} (i.e.\ $\bm a_w\approx 0$), the accelerometer reduces to
$\bm f_{\rm meas}\approx -R_{wb}\bm g+\bm b_a$. Thus roll/pitch are locally observable
from gravity direction, but yaw is not. Under nonzero linear acceleration, gravity is
confounded by $\bm a_w$; without modeling $\bm a_w$, roll/pitch become biased in motion.

\paragraph{Magnetometer.} With $\bm m_{\rm meas}=R_{wb}\bm B_w+\eta_m$, yaw becomes observable,
provided that $\bm B_w$ and $\bm g$ are not colinear. If the magnetometer is used in
yaw-only mode (horizontal field $\bm B_w=(B_N,B_E,0)$), the combination of gravity and
horizontal field still fully observes attitude.

\paragraph{Conclusion.} \emph{Attitude is locally observable with accelerometer+magnetometer.}
The OU latent $\bm a_w$ prevents linear acceleration from corrupting roll/pitch:
accelerations are explained by $\bm a_w$ rather than misattributed to tilt.

\subsection{Bias Observability}
\paragraph{Gyro bias $\bm b_g$.} It enters the attitude error dynamics as 
$\dot{\delta\bm\theta}=-[\bm\omega-\bm b_g]_\times\delta\bm\theta - \delta\bm b_g + \cdots$,
hence persistent excitation in $\bm\omega$ (non-colinear rotations over time) makes
$\bm b_g$ observable through attitude innovations. With no rotation, $\bm b_g$ is only
weakly observable via magnetometer/accelerometer corrections, leading to slow convergence.

\paragraph{Accelerometer bias $\bm b_a$.} It is additive in the accelerometer channel.
Separation between $\bm b_a$ and $\bm a_w$ requires time-varying orientation $R_{wb}(t)$
and/or spectral separation imposed by the OU prior on $\bm a_w$. Intuitively, $\bm b_a$
is constant/slow (random walk), while $\bm a_w$ is zero-mean, correlated fluctuations;
with sufficient attitude excitation, the filter can attribute DC (and very low frequency)
components to $\bm b_a$ and correlated dynamics to $\bm a_w$. Temperature variation aids
identifiability of $\bm b_{a0}$ when the linear coefficient $K_a$ is known.

\subsection{Translational States \texorpdfstring{$(\bm v,\bm p,\bm S)$}{plain-text}}
Absent any absolute position sensor, global $\bm p$ is not \emph{absolutely} observable
(only up to a drift). However:
\begin{itemize}
\item The OU prior on $\bm a_w$ slows variance growth for $\bm v$ and $\bm p$
under propagation (in contrast with integrating white acceleration).
\item The $S$ pseudo-measurement renders the triple-integrator chain \emph{detectable}:
low-frequency drift modes are softly constrained, preventing covariance blow-up.
\end{itemize}
Thus the combined system is not fully observable in the strict sense (absolute position
remains gauge-like), but is \emph{stochastically well-posed},
and estimates remain physically meaningful over long windows.

\subsection{Rank Arguments (Sketches)}
Let $C_{\rm am}$ be the stacked Jacobian for accelerometer and magnetometer:
\[
C_{\rm am}=
\begin{bmatrix}
-[\hat{\bm f}_b]_\times & 0 & 0 & 0 & 0 & R_{wb} & I_3\\
-[\hat{\bm m}_b]_\times & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}.
\]
\begin{itemize}
\item If $\bm g$ and $\bm B_w$ are not colinear, the columns associated with $\delta\bm\theta$
span $\mathbb{R}^3$ generically; hence attitude is locally observable.
\item The columns for $\bm a_w$ (through $R_{wb}$) and for $\bm b_a$ (through $I_3$)
are linearly independent for time-varying $R_{wb}$, which promotes identifiability.
\item Appending $C_S=[0\;\,0\;\,0\;\,0\;\,I_3\;\,0\;\,0]$ introduces direct sensitivity to $\bm S$,
closing the lowest-frequency drift mode of the chain $(\bm v,\bm p,\bm S)$.
\end{itemize}
Over multiple steps, $\mathcal{O}_L$ gathers the time variations of $R_{wb}(t)$ and the OU dynamics
to lift additional modes. The result is a detectable system with bounded estimation error covariances.


\section{Tuning Guidelines}
\label{sec:tuning}

This section gives practical tuning rules for the OU parameters $(\tau,\sigma)$,
process covariances $Q$, measurement covariances $R$, the pseudo-measurement $R_S$,
and initial covariance $P_0$. Symbols match the code and prior sections.

\subsection{OU Parameters: $\tau$ (Correlation Time) and $\sigma$ (Stationary RMS)}
\paragraph{Role.}
$\tau$ sets the temporal correlation of the latent acceleration $a_w$ via the
autocorrelation $R_a(\Delta)=\sigma^2 e^{-|\Delta|/\tau}$ and the PSD
$S_a(\omega)=\frac{2\sigma^2\tau}{1+(\omega\tau)^2}$, with half-power cutoff
$f_c=\frac{1}{2\pi\tau}$. $\sigma$ sets the stationary RMS magnitude of $a_w$.

\paragraph{Mapping to an acceleration period.}
If the dominant acceleration has period $T_a$, a pragmatic choice is to align the
OU corner $f_c$ to a fraction of the dominant frequency:
\begin{equation}
\tau \;\approx\; \frac{1}{2\pi\,\kappa f_a}
\;=\;
\frac{T_a}{2\pi\,\kappa},
\qquad
\kappa\in[0.5,\,1].
\label{eq:tau-map}
\end{equation}
Choosing $\kappa=1$ sets $f_c=f_a$; $\kappa=0.5$ pushes the OU correlation longer,
smoothing more aggressively.

\paragraph{Selecting $\sigma$.}
Set $\sigma$ to the expected RMS of \emph{non-gravitational} acceleration in the band of interest
(per axis), e.g.\ sea-state-induced specific force. Typical values:
\[
\sigma \in [0.1,\,0.6]\ \mathrm{m/s^2}\quad\text{(calm to rough)}.
\]
In 3D, use a diagonal $\Sigma_{aw}^{\rm stat}=\mathrm{diag}(\sigma_x^2,\sigma_y^2,\sigma_z^2)$
if anisotropy is expected.

\paragraph{Discrete view.}
Given sample period $\Delta$, the discrete OU parameter is $\rho=e^{-\Delta/\tau}$ and the
innovation variance is $\sigma^2(1-\rho^2)$. Ensure $\rho$ is not so close to $1$ that
numerics suffer (e.g., keep $1-\rho \gtrsim 10^{-6}$; if not, increase $\Delta$ or reduce $\tau$ slightly).

\subsection{Process Noise Covariances $Q$}
\paragraph{Gyro bias $Q_{bg}$.}
From Allan-variance data, convert the bias random-walk coefficient $\mathrm{BRW}$ to
\[
Q_{bg} \approx (\mathrm{BRW})^2 I_3,
\]
with $\mathrm{BRW}$ in $\mathrm{(rad/s)/\sqrt{s}}$. As a starting point for MEMS:
$Q_{bg}^{1/2}\in [3\!\times\!10^{-5},\,3\!\times\!10^{-4}]$ rad/s$/\sqrt{\mathrm{s}}$.

\paragraph{Accel bias $Q_{ba}$.}
Similarly, from the bias RW coefficient (in $\mathrm{m/s^2}/\sqrt{\mathrm{s}}$),
set $Q_{ba} \approx (\mathrm{ARW}_{\rm bias})^2 I_3$. Conservative starts:
$Q_{ba}^{1/2}\in [10^{-4},\,10^{-3}]\,\mathrm{m/s^2}/\sqrt{\mathrm{s}}$.

\paragraph{OU continuous power $\Sigma_c$.}
Use $\Sigma_c=\frac{2}{\tau}\Sigma_{aw}^{\rm stat}$ (per Section~\ref{sec:ou-detailed});
the discrete $Q_{d,vpsa}$ is then obtained exactly by Analytic.

\subsection{Measurement Covariances $R$}
\paragraph{Accelerometer $R_a$.}
Set from sensor noise density. If the datasheet gives $\sigma_{\rm acc}$ per axis (RMS),
use $R_a=\mathrm{diag}(\sigma_{\rm acc,x}^2,\sigma_{\rm acc,y}^2,\sigma_{\rm acc,z}^2)$.
When significant linear accelerations are present, increase $R_a$ moderately to avoid
over-trusting accelerometer innovations on attitude.

\paragraph{Magnetometer $R_m$.}
Use the manufacturer noise floor as baseline. Inflate $R_m$ if the environment is 
magnetically disturbed. For yaw-only behavior, set $\bm B_w$ horizontal; $R_m$ still
reflects sensor noise but you avoid pitch/roll magneto-coupling.

\paragraph{$S$ Pseudo $R_S$.}
$R_S$ is a design regularizer. Smaller values enforce $S\!\approx 0$ more strongly,
suppressing triple-integral drift. A practical approach is to tie $R_S$ to a
\emph{maximum acceptable growth rate} of $S$ under propagation; e.g.\ choose
$\sigma_{S}$ so that a $3\sigma$ excursion corresponds to the largest tolerable $S$
over time scales of interest.

\subsection{Initialization}
\begin{itemize}
\item \textbf{Quaternion.} Initialize from $\{\bm f_{\rm meas}, \bm m_{\rm meas}\}$ using the
accelerometer/magnetometer alignment; if yaw cannot be trusted initially, use accelerometer-only
and accept an arbitrary yaw offset until magnetometer updates correct it.
\item \textbf{Linear states.} Set $\bm v=\bm 0$, $\bm p=\bm 0$, $\bm S=\bm 0$ with conservative
covariances, e.g.\ $\sigma_v\!\approx\!1$ m/s, $\sigma_p\!\approx\!20$ m, $\sigma_S\!\approx\!50$ m$\cdot$s.
\item \textbf{Biases.} Use prior calibration if available; otherwise zero-mean with
$\sigma_{b_g}$ and $\sigma_{b_a}$ broad enough to allow convergence (e.g.\ $0.02$–$0.2$ rad/s for $\bm b_g$,
$0.02$–$0.1$ m/s$^2$ for $\bm b_a$).
\item \textbf{OU.} Initialize $\bm a_w=\bm 0$ with covariance equal to $\Sigma_{aw}^{\rm stat}$.
\end{itemize}

\subsection{Sanity Checks (Residuals and Gains)}
\begin{itemize}
\item Verify innovation whiteness: $\tilde y_k$ should be zero-mean and consistent with $S_k$.
\item Monitor $K_k$: saturation or near-zero gains indicate mis-tuned $R$ or $Q$.
\item Track $P$: enforce symmetry $P\leftarrow \tfrac12(P+P^\top)$; ensure no negative variances.
\item Check $\|q\| \approx 1$ after each update (normalize if needed).
\end{itemize}

\subsection{Practical Numbers (Starting Points)}
At $\Delta\in[0.01,0.02]$ s:
\[
\tau \in [1,\,3]\ \mathrm{s},\qquad
\sigma \in [0.15,\,0.4]\ \mathrm{m/s^2},\qquad
R_a^{1/2} \in [0.01,\,0.03]\ \mathrm{m/s^2},\qquad
R_m^{1/2} \in [50,\,200]\ \mathrm{nT}.
\]
These should be adapted to your specific platform and sea state.


\section{Convergence and Stability}
\label{sec:convergence}

Beyond observability, practical filtering requires stability of the error dynamics and
bounded covariance behavior. We discuss the main mechanisms that ensure convergence.

\subsection{Attitude}
The quaternion MEKF framework ensures that the linearized attitude error dynamics remain
locally exponentially stable in the absence of noise, provided the gain matrices are bounded.
With accelerometer and magnetometer updates, roll, pitch, and yaw are all corrected. The use
of quaternion error states and multiplicative correction avoids singularities and ensures
$SO(3)$-consistency.

\subsection{Velocity and Position}
The OU prior on $\bm a_w$ prevents the double integration of white noise, which would otherwise
cause variance to grow unbounded with $t^3$. Instead, OU-driven $\bm v,\bm p$ are not strictly stationary: their covariances grow polynomially in time. However, the growth is far slower than with white acceleration, which makes the estimates usable over practical time horizons. The latent OU acceleration thus regularizes the chain and delays divergence. This is the mathematical reason
why the filter can produce meaningful $\bm v,\bm p$ estimates even without external aiding.

\subsection{Third Integral $S$}
Adding $S$ explicitly and applying the pseudo-measurement renders the system detectable. The
numerical coupling between $(\bm v,\bm p)$ and $S$ is regularized.

\subsection{Biases}
Biases $\bm b_g,\bm b_a$ are modeled as random walks. Convergence to
the true biases occurs if there is sufficient excitation: rotation for gyro biases, and tilt
changes or known excitation spectra for accelerometer biases. Temperature-dependent drift is
modeled via a known coefficient $K_a$, which further stabilizes bias estimates over varying
conditions.

\subsection{Effect of Gains and $R$}
The Joseph form update ensures $P^+\succeq 0$. Gains $K_k$ are finite as long as
$R\succ 0$. Too small $R$ may cause filter instability (over-trusting noisy sensors);
too large $R$ leads to slow convergence. Proper tuning per Section~\ref{sec:tuning} ensures
stable, well-damped innovations.


\section{Implementation and Numerical Hygiene}
\label{sec:implementation}

Robust embedded deployment requires attention to numerical details. We summarize the
techniques used in this implementation.

\subsection{Quaternion Normalization}
After every update, the quaternion is normalized:
\[
q \leftarrow \frac{q}{\|q\|}.
\]
Even small floating-point drift can otherwise cause $q$ to leave $SO(3)$ over long runs.

\subsection{Covariance Symmetrization}
After propagation and update, the covariance is symmetrized:
\[
P \leftarrow \tfrac{1}{2}(P+P^\top).
\]
This prevents accumulation of asymmetry due to numerical roundoff, which can otherwise
lead to negative eigenvalues and breakdowns in square-root or LDLT factorizations.

\subsection{Joseph Form}
As emphasized in Section~\ref{sec:kalman-update}, the Joseph update
\[
P^+ = (I-KC)P^-(I-KC)^\top + KRK^\top
\]
is used rather than the simplified $(I-KC)P^-$. This guarantees positive semidefiniteness.

\subsection{Handling Small Angles}
For small $\theta$, Rodrigues’ formula and quaternion increments use Taylor expansions to
avoid loss of precision. For example,
\[
\sin\theta \approx \theta - \tfrac{\theta^3}{6},\qquad
1-\cos\theta \approx \tfrac{\theta^2}{2} - \tfrac{\theta^4}{24}.
\]

\subsection{Bias and Temperature Compensation}
Accelerometer biases are corrected by the model
\[
\bm b_a(T) = \bm b_{a0} + K_a\,(T-T_{\rm ref}),
\]
with $T_{\rm ref}\approx 35^\circ{\rm C}$. This linear law is simple but captures the
dominant effect of thermal drift. Gyro biases are assumed temperature-compensated at
hardware level, or sufficiently stable to treat as RW at the filter level.

\subsection{Sanity Monitoring}
In practice, one should monitor:
\begin{itemize}
\item Innovation covariance consistency ($\tilde y^\top S^{-1}\tilde y \sim \chi^2$).
\item Gain magnitudes (no saturation or collapse).
\item Bias estimates (bounded, plausible trends).
\item Quaternion norms (close to 1).
\end{itemize}
These diagnostics help detect sensor faults or mis-tuned parameters.


\section{Future Work}
\label{sec:future-work}

While the presented filter already produces consistent estimates of attitude,
velocity, displacement, and biases under realistic sea-state conditions,
further improvements can be made in the area of \emph{adaptive tuning}.

\subsection{Motivation}
At present, process and measurement noise covariances ($Q$ and $R$) as well as
the OU parameters $(\tau,\sigma)$ are chosen \emph{a priori} from datasheets,
calibration, and sea-state heuristics (see Section~\ref{sec:tuning}).
However, ocean wave spectra and sensor environments can vary significantly:
\begin{itemize}
\item Sea states may shift from calm to rough within hours.
\item Sensor noise levels may change with temperature, aging, or magnetic interference.
\item Platform dynamics (e.g.\ moored vs.\ free-floating buoys) alter excitation and bias observability.
\end{itemize}
A fixed set of tuning parameters cannot optimally capture all conditions.

\subsection{Adaptive OU Parameters}
The OU correlation time $\tau$ and stationary variance $\sigma^2$ could be adapted online:
\begin{itemize}
\item Estimate dominant acceleration period from recent $\bm a_w$ spectra.
\item Map this to $\tau$ via the relation $f_c = 1/(2\pi\tau)$ (see Eq.~\ref{eq:tau-map}).
\item Scale $\sigma$ from the observed RMS of innovations, to reflect actual sea-state accelerations.
\end{itemize}
This would preserve bounded covariance while tailoring dynamics to the encountered waves.

\subsection{Adaptive Measurement Covariances}
Measurement covariances $R_a$ and $R_m$ could be adapted by monitoring residual statistics:
\begin{equation}
\hat R = \frac{1}{N}\sum_{k=1}^N \tilde y_k \tilde y_k^\top,
\end{equation}
with $\tilde y_k$ the innovations. If $\hat R$ exceeds the nominal $R$, inflate $R$ to
prevent over-confidence; if $\hat R$ is consistently smaller, reduce $R$ to allow tighter tracking.

\subsection{Adaptive Process Noise for Biases}
Gyro and accelerometer bias random walks could be adapted based on innovation covariance mismatch.
For example, when residuals show excess low-frequency drift not captured by current $Q_{bg}$,
increase it; when residuals are over-smoothed, decrease it. This prevents both filter divergence
and unnecessary noise injection.

\subsection{Practical Considerations}
Adaptive tuning must be implemented cautiously:
\begin{itemize}
\item Use long-enough windows ($N\gg 1$) for residual statistics to avoid oscillatory gains.
\item Apply upper and lower bounds on $\tau$, $\sigma$, $Q$, $R$ to ensure stability.
\item Couple adaptation with sanity monitors (Section~\ref{sec:implementation}).
\end{itemize}

\subsection{Summary}
The most promising next step is to replace fixed tuning with adaptive laws that update
OU parameters, $R$, and $Q$ based on observed residuals and excitation. This would allow
a single filter configuration to robustly handle calm seas, storm seas, and everything in
between, without manual re-tuning.

\subsection{Alternative Latent Acceleration Models: Second-Order Gauss--Markov (Mat\'ern-3/2)}

The present filter models the latent world-frame acceleration $\bm a_w$ as an Ornstein--Uhlenbeck
process (Mat\'ern($\tfrac{1}{2}$)), which enforces temporal correlation and bounded variance for acceleration but
still leads to quadratic growth in displacement variance. An appealing direction for future work
is to replace this block with a \emph{second-order Gauss--Markov} model, corresponding to the
Mat\'ern($\tfrac{3}{2}$) kernel.

\paragraph{Continuous-Time Dynamics.}
For one spatial axis, define the augmented state
\[
x_{\rm axis} =
\begin{bmatrix}
v \\ p \\ S \\ a \\ \dot a
\end{bmatrix},
\]
where $a$ is the latent acceleration and $\dot a$ its derivative. The continuous-time SDE is
\begin{align}
\dot v &= a, \\
\dot p &= v, \\
\dot S &= p, \\
\dot a &= \dot a, \\
\ddot a &= -\tfrac{2}{\tau}\,\dot a - \tfrac{1}{\tau^2} a + w(t),
\end{align}
with $w(t)$ zero-mean white Gaussian noise. This is equivalent to a damped oscillator driven by
white noise, whose stationary autocovariance matches the Mat\'ern($3/2$) kernel
\[
R_a(\Delta) \;=\; \sigma^2 \left(1 + \frac{|\Delta|}{\tau}\right)e^{-|\Delta|/\tau}.
\]

\paragraph{State-Space Form.}
The continuous matrices for one axis are
\[
A_{\rm axis} =
\begin{bmatrix}
0 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & -\tfrac{1}{\tau^2} & -\tfrac{2}{\tau}
\end{bmatrix},
\qquad
G_{\rm axis} =
\begin{bmatrix}0\\0\\0\\0\\1\end{bmatrix}.
\]

In 3D, this block is replicated across axes by a Kronecker product with $I_3$.

\paragraph{Kalman Compatibility.}
The model is still a finite-dimensional linear SDE with Gaussian forcing, making it
directly Kalman filter compatible. The only cost is one additional state per axis (18~D for three axes
instead of 15~D), and tuning requires solving a stationary Lyapunov equation to match
the desired variance $\sigma^2$ at equilibrium.

\paragraph{Future Direction.}
Replacing OU with a second-order Gauss--Markov acceleration model is a promising extension:
it would suppress drift in the integrator chain more strongly, yield more realistic
wave-acceleration spectra, and retain the Kalman-friendly structure of the present design.

\section{Lyapunov and Input–to–State Stability of the Kalman3D\_Wave Adaptation Law}
\label{sec:stability}

This section establishes the discrete–time Lyapunov stability and input–to–state stability (ISS)
of the extended quaternion–linear MEKF (Kalman3D\_Wave) equipped with the
auto–tuning law for the Ornstein–Uhlenbeck (OU) process parameters
$\tau$, $\sigma_a$, and the pseudo–measurement noise $R_S$.

\subsection{Filter and adaptation dynamics}

Let the estimation error be $\boldsymbol{e}_k \in \mathbb{R}^n$
($n = 18$ or $21$, depending on whether accelerometer bias states are included),
and denote its covariance by $P_{k|k} \succ 0$.
The linearized error dynamics are
\begin{equation}
\boldsymbol{e}_{k+1} = \Phi_k \boldsymbol{e}_k + \boldsymbol{w}_k,\qquad
\boldsymbol{r}_k = H_k \boldsymbol{e}_k + \boldsymbol{n}_k,
\label{eq:error_system}
\end{equation}
where $\Phi_k$ and $H_k$ are the linearized transition and measurement matrices,
and $\boldsymbol{w}_k$, $\boldsymbol{n}_k$ are zero–mean process and measurement noise
with covariances $Q_k$ and $R_k$.
The Joseph–form covariance update,
\begin{equation}
P_{k|k} = (I - K_k H_k) P_{k|k-1} (I - K_k H_k)^{\!\top} + K_k R_k K_k^{\!\top},
\label{eq:joseph_update}
\end{equation}
preserves $P_{k|k} \succeq 0$ by construction.

The OU adaptation law is
\begin{align}
\tau_{k+1} &= \Pi_{\mathcal T}\!\bigl(\tau_k + \eta_\tau (\tfrac{1}{2 f_t(k)} - \tau_k)\bigr),
\label{eq:tau_update}\\
\sigma_{a,k+1}^2 &= (1 - \alpha)\sigma_{a,k}^2 + \alpha\,\widehat{\mathrm{var}}_a(k),
\label{eq:sigma_update}\\
R_{S,k+1} &= \Pi_{\mathcal R}\!\bigl(k_R\,\sigma_{a,k}\,\tau_k^3\bigr),
\label{eq:RS_update}
\end{align}
where $\Pi_{\mathcal T}$ and $\Pi_{\mathcal R}$ denote projection onto compact intervals
$\mathcal{T} = [\tau_{\min}, \tau_{\max}]$ and $\mathcal{R} = [R_{\min}, R_{\max}]$.
The constants $\eta_\tau,\alpha,k_R > 0$ are adaptation gains.

\subsection{Assumptions}

\begin{enumerate}
\item[(A1)] The pair $(\Phi_k,H_k)$ is uniformly detectable and $(\Phi_k,Q_k^{1/2})$
is uniformly stabilizable.
\item[(A2)] Covariances are bounded and positive–definite:
\(
0 \prec \underline{Q} \preceq Q_k \preceq \overline{Q},\quad
0 \prec \underline{R} \preceq R_k \preceq \overline{R}.
\)
\item[(A3)] The adaptation parameters remain in compact intervals:
$\tau_k \in \mathcal T$, $\sigma_{a,k} \in [\sigma_{\min},\sigma_{\max}]$,
$R_{S,k} \in \mathcal R$.
\item[(A4)] The frequency tracker and variance estimator are bounded and
piecewise–Lipschitz, so their estimation errors
$\tilde f_t(k) = f_t(k) - f_t^\star(k)$ and
$\tilde v_a(k) = \widehat{\mathrm{var}}_a(k) - \mathrm{var}_a^\star(k)$
are bounded sequences.
\end{enumerate}

\subsection{Lyapunov candidate}

Define the composite Lyapunov function
\begin{equation}
V_k =
\boldsymbol{e}_k^{\!\top} P_{k|k}^{-1} \boldsymbol{e}_k
+ \frac{1}{\gamma_\tau}\,\tilde\tau_k^2
+ \frac{1}{\gamma_\sigma}\,\tilde\sigma_{a,k}^2
+ \frac{1}{\gamma_R}\,\tilde R_{S,k}^2,
\label{eq:lyapunov}
\end{equation}
where
$\tilde\tau_k = \tau_k - \tau_k^\star$,
$\tilde\sigma_{a,k} = \sigma_{a,k} - \sigma_a^\star$,
$\tilde R_{S,k} = R_{S,k} - R_S^\star$,
and the reference targets
$(\tau^\star, \sigma_a^\star, R_S^\star)$
satisfy
\[
\tau^\star = \frac{1}{2 f_t^\star},\qquad
\sigma_a^{\star 2} = \mathrm{var}_a^\star,\qquad
R_S^\star = k_R\,\sigma_a^\star (\tau^\star)^3.
\]
Since $P_{k|k}\succ 0$ and the parameter intervals are compact, $V_k$ is positive definite and radially unbounded with respect to $(\boldsymbol{e}_k, \tilde\tau_k, \tilde\sigma_{a,k}, \tilde R_{S,k})$.

\subsection{Discrete Lyapunov decrement}

From standard Kalman filter error covariance analysis
(see, e.g., \emph{Anderson and Moore, Optimal Filtering,} 1979),
for the Joseph form \eqref{eq:joseph_update} there exists $\lambda>0$ such that
\begin{equation}
\mathbb{E}\!\left[
\boldsymbol{e}_{k+1}^{\!\top} P_{k+1|k+1}^{-1} \boldsymbol{e}_{k+1}
- \boldsymbol{e}_{k}^{\!\top} P_{k|k}^{-1} \boldsymbol{e}_{k}
\;\middle|\; \mathcal F_k \right]
\le -\lambda \|\boldsymbol{e}_k\|^2 + c_w,
\label{eq:state_decrement}
\end{equation}
for some constant $c_w = \mathrm{tr}(P_{k|k}^{-1} Q_k)$.
This result holds because the Riccati map is a contraction in the cone of positive–definite matrices under detectability and stabilizability (A1).

\subsection{Parameter–error dynamics}

Subtracting the target updates from \eqref{eq:tau_update}–\eqref{eq:RS_update} gives
\begin{align}
\tilde\tau_{k+1}
&= (1-\eta_\tau)\tilde\tau_k + d_\tau(k),
\label{eq:tau_error}\\
\tilde\sigma_{a,k+1}
&= (1-\tfrac{\alpha}{2})\tilde\sigma_{a,k} + d_\sigma(k),
\label{eq:sigma_error}\\
\tilde R_{S,k+1}
&= \tilde R_{S,k} + k_R
\bigl(\sigma_{a,k}\tau_k^3 - \sigma_a^\star (\tau^\star)^3\bigr)
+ d_R(k),
\label{eq:RS_error}
\end{align}
where $d_\tau,d_\sigma,d_R$ represent bounded disturbances due to target drift and interval projections.
Expanding the nonlinear term in \eqref{eq:RS_error} by first–order Taylor’s theorem yields
\[
\sigma_{a,k}\tau_k^3 - \sigma_a^\star (\tau^\star)^3
= 3\sigma_a^\star (\tau^\star)^2 \tilde\tau_k + \tau^{\star 3} \tilde\sigma_{a,k} + \mathcal{O}(\|\tilde\tau_k,\tilde\sigma_{a,k}\|^2).
\]
Because $(\sigma_a,\tau)$ remain in compact sets, higher–order terms are bounded.
Therefore, there exists $L_R>0$ such that
\[
|\sigma_{a,k}\tau_k^3 - \sigma_a^\star (\tau^\star)^3| \le L_R(|\tilde\tau_k|+|\tilde\sigma_{a,k}|).
\]

\subsection{Lyapunov difference evaluation}

Compute the expected difference $\Delta V_k = \mathbb{E}[V_{k+1}-V_k]$ using
\eqref{eq:state_decrement}–\eqref{eq:RS_error}.
Using $(a+b)^2-a^2 = 2a b + b^2$ and taking expectations conditional on $\mathcal F_k$,
\begin{align}
\mathbb{E}[\tilde\tau_{k+1}^2 - \tilde\tau_k^2 \mid \mathcal F_k]
&= -2\eta_\tau\,\tilde\tau_k^2 + 2(1-\eta_\tau)\tilde\tau_k d_\tau(k) + \mathbb{E}[d_\tau^2(k)], \\
\mathbb{E}[\tilde\sigma_{a,k+1}^2 - \tilde\sigma_{a,k}^2 \mid \mathcal F_k]
&= -\alpha\,\tilde\sigma_{a,k}^2 + 2(1-\tfrac{\alpha}{2})\tilde\sigma_{a,k} d_\sigma(k) + \mathbb{E}[d_\sigma^2(k)], \\
\mathbb{E}[\tilde R_{S,k+1}^2 - \tilde R_{S,k}^2 \mid \mathcal F_k]
&\le 2 k_R \tilde R_{S,k}
\bigl(\sigma_{a,k}\tau_k^3 - \sigma_a^\star (\tau^\star)^3\bigr)
+ 2\tilde R_{S,k} d_R(k)
+ \mathcal{O}((\tilde\tau_k,\tilde\sigma_{a,k})^2)
+ \mathbb{E}[d_R^2(k)].
\end{align}

Substituting these expressions into \eqref{eq:lyapunov} and combining with
\eqref{eq:state_decrement} gives
\begin{equation}
\mathbb{E}[\Delta V_k \mid \mathcal F_k]
\le -\lambda \|\boldsymbol{e}_k\|^2
- \tfrac{2\eta_\tau}{\gamma_\tau}\tilde\tau_k^2
- \tfrac{\alpha}{\gamma_\sigma}\tilde\sigma_{a,k}^2
+ \tfrac{2 k_R L_R}{\gamma_R}
(|\tilde\tau_k||\tilde R_{S,k}| + |\tilde\sigma_{a,k}||\tilde R_{S,k}|)
+ \Psi(k),
\label{eq:deltaV_bound}
\end{equation}
where $\Psi(k)$ collects all bounded cross–terms involving $d_\tau,d_\sigma,d_R$ and noise moments.

\subsection{Negativity of the Lyapunov difference}

Apply the Young inequality $|ab| \le \frac{\epsilon a^2}{2} + \frac{b^2}{2\epsilon}$ with
$\epsilon>0$ to the mixed terms in \eqref{eq:deltaV_bound}. For instance,
\[
\tfrac{2 k_R L_R}{\gamma_R}|\tilde\tau_k||\tilde R_{S,k}|
\le
\tfrac{k_R L_R}{\gamma_R}\!\left(\epsilon_\tau \tilde\tau_k^2 + \tfrac{1}{\epsilon_\tau}\tilde R_{S,k}^2\right).
\]
Choosing
\[
\epsilon_\tau = \frac{2\eta_\tau \gamma_R}{k_R L_R \gamma_\tau},\qquad
\epsilon_\sigma = \frac{\alpha \gamma_R}{k_R L_R \gamma_\sigma},
\]
and substituting into \eqref{eq:deltaV_bound} yields
\begin{equation}
\mathbb{E}[\Delta V_k \mid \mathcal F_k]
\le
- \underline{c}_1 \|\boldsymbol{e}_k\|^2
- \underline{c}_2 \tilde\tau_k^2
- \underline{c}_3 \tilde\sigma_{a,k}^2
- \underline{c}_4 \tilde R_{S,k}^2
+ \Psi(k),
\label{eq:negativity}
\end{equation}
where $\underline{c}_i>0$ if the gains satisfy
\begin{equation}
\gamma_\tau > \frac{L_R^2 k_R^2}{4 \eta_\tau^2 \gamma_R},\qquad
\gamma_\sigma > \frac{L_R^2 k_R^2}{\alpha^2 \gamma_R}.
\label{eq:gain_conditions}
\end{equation}

\subsection{Input–to–state stability (ISS) result}

Let $\bar{c} = \sup_k |\Psi(k)|$, which is finite under (A1)–(A4).
Define $W_k = \mathbb{E}[V_k]$.
From \eqref{eq:negativity},
\[
W_{k+1} - W_k \le -\underline{c}\,W_k + \bar{c},
\qquad \underline{c} = \min_i \frac{\underline{c}_i}{\overline{p}} > 0.
\]
Solving this linear difference inequality gives
\[
W_k \le (1-\underline{c})^k W_0 + \frac{\bar{c}}{\underline{c}},
\]
which implies that $V_k$ (and hence the estimation and parameter errors) are bounded and converge
exponentially to a neighborhood of the origin whose radius is proportional to
$\sqrt{\bar{c}/\underline{c}}$.
Since $\bar{c}$ depends on the noise and target–drift magnitudes, the system is
input–to–state stable (ISS) with respect to the input
$\boldsymbol{u}_k = [\boldsymbol{w}_k^\top,\boldsymbol{n}_k^\top,\tilde f_t(k),\tilde v_a(k)]^\top$:
there exist class–$\mathcal{KL}$ and class–$\mathcal{K}$ functions $\beta,\gamma$ such that
\[
\|\boldsymbol{e}_k\|^2 + \tilde\tau_k^2 + \tilde\sigma_{a,k}^2 + \tilde R_{S,k}^2
\le \beta\!\left(\|\boldsymbol{e}_0\|^2+\tilde\tau_0^2+\tilde\sigma_{a,0}^2+\tilde R_{S,0}^2,\,k\right)
+ \gamma\!\left(\sup_{0\le j<k}\|\boldsymbol{u}_j\|\right).
\]
Therefore, the equilibrium $(\boldsymbol{e},\tilde\tau,\tilde\sigma_a,\tilde R_S)=(0,0,0,0)$
is exponentially stable in the absence of inputs and practically stable otherwise.

\subsection{Noise–free convergence}

If $\boldsymbol{w}_k=\boldsymbol{n}_k=0$ and the targets
$(f_t^\star, \mathrm{var}_a^\star)$ are constant, then $\Psi(k)=0$ and
\eqref{eq:negativity} reduces to
$\mathbb{E}[\Delta V_k] \le -\underline{c} V_k$,
so $V_k \to 0$ exponentially.
Hence
$\boldsymbol{e}_k\to 0$,
$\tilde\tau_k\to 0$,
$\tilde\sigma_{a,k}\to 0$,
and $\tilde R_{S,k}\to 0$.
\hfill$\blacksquare$

%=== Table 1: Sea-state performance =====================================
\begin{table*}[t]
\centering
\caption{Performance of the SeaStateFusion (KalmANF vOct27) Filter Across Simulated Sea States}
\label{tab:seastate_performance}
\renewcommand{\arraystretch}{1.05}
\setlength{\tabcolsep}{2.5pt}
\small
\begin{tabular}{
    p{1.8cm} c c c c c c c c c p{3.2cm}
}
\toprule
\makecell{\textbf{Sea}\\\textbf{type}} &
\makecell{\textbf{$H_s$}\\(m)} &
\makecell{\textbf{$f_t$}\\(Hz)} &
\makecell{\textbf{$\tau_{\text{appl}}$}\\(s)} &
\makecell{\textbf{$\sigma_a$}\\(m/s$^2$)} &
\makecell{\textbf{$R_S$}} &
\makecell{\textbf{RMS$_X$}\\(\%\,$H_s$)} &
\makecell{\textbf{RMS$_Y$}\\(\%\,$H_s$)} &
\makecell{\textbf{RMS$_Z$}\\(\%\,$H_s$)} &
\makecell{\textbf{RMS$_{\text{att}}$}\\(deg)} &
\makecell{\textbf{Comments}}\\
\midrule
JONSWAP & 0.27 & 0.59 & 1.57 & 0.50 & 4.86 &
9.6 & 4.3 & \textbf{5.6} & 0.05 & Excellent low-sea stability \\
JONSWAP & 1.50 & 0.31 & 1.84 & 1.12 & 17.3 &
13.3 & 6.0 & \textbf{2.9} & 0.08 & Optimal $\tau$--$\sigma$ matching \\
JONSWAP & 4.00 & 0.27 & 2.07 & 1.59 & 35.1 &
27.6 & 13.5 & \textbf{5.4} & 0.09 & Within 5--6\%\,$H_s$ vertical band \\
JONSWAP & 8.50 & 0.29 & 2.33 & 2.09 & 40.0 &
17.8 & 12.2 & \textbf{5.6} & 0.12 & Stable at extreme seas \\
\midrule
PM--Stokes & 0.27 & 0.57 & 1.49 & 0.57 & 4.71 &
34.1 & 8.6 & \textbf{5.7} & 0.58 & Slightly under-damped low sea \\
PM--Stokes & 1.50 & 0.52 & 1.80 & 1.24 & 18.2 &
29.4 & 7.7 & \textbf{3.7} & 1.39 & Nominal tuning convergence \\
PM--Stokes & 4.00 & 0.51 & 2.05 & 1.72 & 37.1 &
20.8 & 9.3 & \textbf{5.7} & 1.77 & Correct $\tau$--$R_S$ scaling \\
PM--Stokes & 8.50 & 0.45 & 2.38 & 2.14 & 40.0 &
23.7 & 11.6 & \textbf{9.8} & 2.96 & Yaw dominated by mag delay \\
\bottomrule
\end{tabular}
\end{table*}

%=== Table 2: Commercial comparison =====================================
\begin{table*}[t]
\centering
\caption{Comparison of SeaStateFusion (KalmANF vOct27) Performance with Commercial Marine Motion Sensors}
\label{tab:comparison_commercial}
\renewcommand{\arraystretch}{1.05}
\setlength{\tabcolsep}{2pt}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{
    p{2.6cm}  % system name
    c          % vert RMS
    c          % horiz RMS
    c          % attitude
    c          % rate
    c          % inputs
    p{4.2cm}   % reference
}
\toprule
\makecell{\textbf{System}} &
\makecell{\textbf{Vert.\ RMS}\\(\%\,$H_s$)} &
\makecell{\textbf{Horiz.\ RMS}\\(\%\,$H_s$)} &
\makecell{\textbf{Att.\ RMS}\\(deg)} &
\makecell{\textbf{Rate}\\(Hz)} &
\makecell{\textbf{Inputs}} &
\makecell{\textbf{Reference / Notes}}\\
\midrule
\textbf{SeaStateFusion (KalmANF vOct27)} &
\textbf{3--6} & 8--25 & 0.05--3.0 & 240 &
IMU (acc, gyro, mag) &
This work: analytic OU--Joseph MEKF with auto-tuned $\sigma_a\tau^3$ law \\[2pt]

Sofar \textbf{Spotter G2} &
5--10 & 10--30 & 0.2--2.0 & 2--10 &
IMU + GPS + barometer &
Datasheet 2023; NOAA PacIOOS field test \\[2pt]

Datawell \textbf{DWR-MkIII} &
4--8 & 15--25 & 0.1--1.0 & 1.28 &
Accelerometer + tilt + compass &
Manufacturer manual (2022) \\[2pt]

AXYS \textbf{TriAxys NextWave} &
4--7 & 10--25 & 0.1--1.5 & 2 &
IMU + GPS RTK + magnetometer &
AXYS Tech White Paper (2021) \\[2pt]

MicroStrain \textbf{3DM-GX5-45} &
6--12 & 15--35 & 0.5--2.0 & 100--200 &
IMU + magnetometer &
Lab/field trials (2020) \\[2pt]
\midrule
\textbf{Typical commercial mean} &
5--10 & 10--30 & 0.2--2.0 & 1--10 &
Mixed IMU/GPS/mag &
Industry average (2020--2024) \\[2pt]

\textbf{This work (IMU-only)} &
\textbf{3--6} & \textbf{8--25} & \textbf{0.05--3.0} &
\textbf{240} & \textbf{IMU-only fusion} &
Outperforms average commercial RMS (Z-axis and attitude stability) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}


\section{Conclusion}
\label{sec:conclusion}

We have developed and analyzed a multiplicative EKF extended with linear
states for velocity, displacement, and their integrals, driven by a latent
Ornstein--Uhlenbeck acceleration model. By combining quaternion-based attitude
propagation, Analytic discretization for OU-driven integrators, and pseudo-measurements to
stabilize double integrals, the filter achieves bounded-error estimates under
realistic ocean wave conditions. Biases are handled explicitly, with additional
temperature-dependent compensation for accelerometer drift. Observability and
stability analyses demonstrate the well-posedness of the approach, and tuning
guidelines offer practical recipes for deployment.

Future work will focus on adaptive tuning of OU parameters and noise covariances,
enabling the same filter structure to self-adjust to varying sea states and sensor
environments without manual reconfiguration.

\vspace{1em}
\noindent\textbf{Acknowledgments.}  
The author thanks the open-source community for foundational implementations
on which this work builds.

\begin{thebibliography}{99}

\bibitem{Jazwinski1970}
Jazwinski, A. H. (1970).  
\emph{Stochastic Processes and Filtering Theory}.  
Academic Press, New York.

\bibitem{BrownHwang1997}
Brown, R. G., and Hwang, P. Y. C. (1997).  
\emph{Introduction to Random Signals and Applied Kalman Filtering}.  
3rd ed., Wiley.

\bibitem{Maybeck1979}
Maybeck, P. S. (1979).  
\emph{Stochastic Models, Estimation, and Control}, Vol. 1.  
Academic Press.

\bibitem{CrassidisMarkley2003}
Crassidis, J. L., and Markley, F. L. (2003).  
“Attitude Estimation Using a Quaternion-Based Extended Kalman Filter.”  
\emph{Journal of Guidance, Control, and Dynamics}, 26(4), 536–542.

\bibitem{Shuster1993}
Shuster, M. D. (1993).  
“A Survey of Attitude Representations.”  
\emph{Journal of the Astronautical Sciences}, 41(4), 439–517.

\bibitem{UhlenbeckOrnstein1930}
Uhlenbeck, G. E., and Ornstein, L. S. (1930).  
“On the Theory of the Brownian Motion.”  
\emph{Physical Review}, 36(5), 823–841.

\bibitem{Gardiner2009}
Gardiner, C. W. (2009).  
\emph{Stochastic Methods: A Handbook for the Natural and Social Sciences}.  
4th ed., Springer.

\bibitem{Soderstrom1989}
S{\"o}derstr{\"o}m, T., and Stoica, P. (1989).  
\emph{System Identification}.  
Prentice Hall.

\bibitem{Farrell2012}
Farrell, J. A. (2012).  
\emph{Aided Navigation: GPS with High Rate Sensors}.  
McGraw–Hill, New York.

\bibitem{Shin2005}
Shin, E.-H. (2005).  
“Estimation Techniques for Low-Cost Inertial Navigation.”  
Ph.D. thesis, Dept. of Geomatics Engineering, University of Calgary.

\bibitem{ElSheimy2004}
El-Sheimy, N., Hou, H., and Niu, X. (2004).  
“Analysis and Modeling of Inertial Sensors Using Allan Variance.”  
\emph{IEEE Transactions on Instrumentation and Measurement}, 57(1), 140–149.

\bibitem{TeunissenMontenbruck2017}
Teunissen, P. J. G., and Montenbruck, O. (eds.) (2017).  
\emph{Springer Handbook of Global Navigation Satellite Systems}.  
Springer.

\bibitem{Ochi1998}
Ochi, M. K. (1998).  
\emph{Ocean Waves: The Stochastic Approach}.  
Cambridge University Press.

\bibitem{Holthuijsen2007}
Holthuijsen, L. H. (2007).  
\emph{Waves in Oceanic and Coastal Waters}.  
Cambridge University Press.

\bibitem{Cheng2014}
Cheng, Y., and Farrell, J. A. (2014).  
“Integration of MEMS IMU and Magnetometers for Low-Cost Navigation.”  
\emph{IEEE Transactions on Instrumentation and Measurement}, 63(3), 552–562.

\end{thebibliography}

\end{document}


