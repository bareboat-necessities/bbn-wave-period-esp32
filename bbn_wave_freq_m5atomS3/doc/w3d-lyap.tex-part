\section{Lyapunov / ISS Stability of the Adaptive Law $R_S \propto \sigma_a \tau^3$}
\label{sec:lyap-iss}

We establish input–to–state stability (ISS) of the estimation error under the adaptive
pseudo-measurement weighting
\[
R_S(\theta) = \mathrm{diag}(r_{Sx}, r_{Sy}, r_{Sz}), \qquad
r_{Si} = k_i\;\sigma_a\,\tau^3,
\]
where $\theta \!=\! (\sigma_a,\tau)$ are adapted online and $k_i>0$ are fixed anisotropy
coefficients (possibly $k_x,k_y \ll k_z$).
We analyze the extended Q–MEKF linearized about the operating point after attitude
lock (Sec.~\ref{sec:analytic}, \ref{sec:quat}), focusing on the translational OU chain
\(
\dot v = a_w,\;\dot p = v,\;\dot S = p,\;\dot a_w = -(1/\tau)a_w + \sqrt{q_c}\,w
\),
with $q_c=2\sigma_a^2/\tau$. The complete estimator uses Joseph updates and PSD projection
(Sec.~\ref{sec:cross-cov}).

\subsection*{Assumptions}
\begin{itemize}[before=\small, itemsep=2pt, topsep=2pt,
  labelsep=0.6em, labelwidth=2.2em, labelindent=0pt, leftmargin=!]
\item[A1] \textbf{Bounded sampling and small linearization error.}
Sampling $h \in (0,\bar h]$ such that the discrete transition $\Phi(h,\tau)$ matches the analytic form
(Sec.~\ref{sec:analytic}); linearization error is Lipschitz on the compact set considered.
\item[A2] \textbf{Noise bounds.}
Gyro, accelerometer, magnetometer, and pseudo-measurement noises satisfy
$\|n_g\|,\|n_a\|,\|n_m\|,\|n_S\| \le \bar n$; the OU driver $w$ has finite second moment on each interval.
\item[A3] \textbf{Parameter compactness via projection.}
\[
\Theta \;=\; \{(\sigma_a,\tau)\;:\;\underline\sigma \le \sigma_a \le \overline\sigma,\;
\underline\tau \le \tau \le \overline\tau\},
\]
enforced by a projection $\Pi_\Theta(\cdot)$.
\item[A4] \textbf{Rate-limited adaptation.} There exists $\rho>0$ such that
$\|\theta_{k+1}-\theta_k\|\le \rho$ for all $k$ (per-step clamp/rate limit).
\item[A5] \textbf{Smooth dependence.}
$\Phi(\theta)$ and $K(\theta)$ are Lipschitz on $\Theta$ with constants $L_\Phi,L_K$.
\item[A6] \textbf{CQLF for the frozen closed loop.}
Let $A(\theta):=\Phi(\theta)-K(\theta)C\,\Phi(\theta)$. There exist $P\succ 0$ and $\mu\in(0,1)$ such that
\begin{equation}
\label{eq:cqlf}
A(\theta)^\top P\,A(\theta) \;\preceq\; (1-\mu)\,P \qquad \forall\,\theta\in\Theta .
\end{equation}
\item[A7] \textbf{Explicit adaptation law.}
$\theta_{k+1} = \Pi_\Theta(\theta_k - \Gamma\nabla_\theta \mathcal{L}(e_k,\theta_k))$,  
with step matrix $\Gamma=\mathrm{diag}(\gamma_\sigma,\gamma_\tau)$.
\item[A8] \textbf{Gradient regularity and small step.}
$\nabla_\theta\mathcal{L}$ is $L_\theta$-Lipschitz and $\Gamma$ is small enough so that
$\|\theta_{k+1}-\theta_k\|\le\rho<\rho^\star$ (bounded-rate adaptation).
\end{itemize}

\noindent
We write the stacked estimation error $e := x-x^\star$ for the linear translational
subsystem (including $a_w$), with $x^\star$ the true OU-driven state.
Let $\tilde\theta := \hat\theta - \theta^\star$ denote parameter error relative to the
ideal stationary values $(\sigma_a^\star,\tau^\star)$ for the current sea-state.
Disturbances $d_k$ aggregate process/measurement noise, linearization residue, and bounded coupling from attitude.

\begin{lemma}[Parameter-variation mismatch bound]\label{lem:delta}
Let $A(\theta)=\Phi(\theta)-K(\theta)C\Phi(\theta)$ and assume \textup{A4–A5}.
Then for $\Delta_k := A(\theta_{k+1})-A(\theta_k)$,
\[
\fitcol{
\|\Delta_k\| \;\le\; \Big(L_\Phi + L_K\,\|C\|\,\|\Phi\| + \|K\|\,\|C\|\,L_\Phi\Big)\,\rho \;=:\; L_A\,\rho .
}
\]
\end{lemma}

\begin{proof}
Mean-value expansion of $\Phi,K$ over compact $\Theta$ and the triangle inequality.
\end{proof}

\begin{lemma}[Corrected one-step Lyapunov decrement]\label{lem:onestep-corrected}
Under \textup{A1–A6}, with $V(e)=e^\top P e$ and $P,\mu$ as in \eqref{eq:cqlf}, the true
time-varying error update
\[
e_{k+1} = A(\theta_k)e_k + \Delta_k e_k + d_k
\]
satisfies
\[
V(e_{k+1}) \le (1-\mu + c_1L_A^2\rho^2)\,V(e_k) + c_d\|d_k\|^2,
\]
where $c_1=\tfrac{\lambda_{\max}(P)}{\lambda_{\min}(P)}$ and $c_d>0$ depends on bounds of $A(\theta),P$ on $\Theta$.
\end{lemma}

\begin{proof}
Expand
\[
\fitcol{
V(e_{k+1}) = e_k^\top(A_k+\Delta_k)^\top P (A_k+\Delta_k)e_k + 2e_k^\top(A_k+\Delta_k)^\top P d_k + d_k^\top P d_k.
}
\]
Apply \eqref{eq:cqlf}, the Rayleigh quotient
$\lambda_{\min}(P)\|e_k\|^2 \le e_k^\top P e_k \le \lambda_{\max}(P)\|e_k\|^2$,
and Young’s inequality. Collect terms to obtain
$V(e_{k+1}) \le (1-\mu + c_1\|\Delta_k\|^2)V(e_k) + c_d\|d_k\|^2$.
Finally substitute $\|\Delta_k\|\le L_A\rho$.
\end{proof}

\begin{lemma}[Coupled parameter update bound]\label{lem:coupled}
Assume \textup{A7–A8}. Then for $\tilde\theta_k=\hat\theta_k-\theta^\star$,
\[
\fitcol{
\|\tilde\theta_{k+1}\|^2 \;\le\; (1-\eta)\|\tilde\theta_k\|^2 + c_\theta\|e_k\|^2,
}
\]
where $\eta>0$ depends on the step size $\Gamma$ and the cocoercivity of $\nabla_\theta\mathcal{L}$,
and $c_\theta$ depends on its $L_\theta$-Lipschitz constant.
\end{lemma}

\begin{proof}[Sketch]
Projection is nonexpansive; gradient steps with small $\Gamma$ are averaged contractions.
Expanding $\|\tilde\theta_{k+1}\|^2$ and applying Lipschitz and cocoercivity bounds yields the inequality.
\end{proof}

\begin{theorem*}[ISS of the adaptive estimator (augmented state)]\label{thm:iss-aug}
Let $W_k := V(e_k) + \alpha\|\tilde\theta_k\|^2$ for some $\alpha>0$.
Under \textup{A1–A8} and $\rho<\rho^\star$ from Lemma~\ref{lem:onestep-corrected},
there exist class-$\mathcal{KL}$ and class-$\mathcal{K}$ functions $\beta,\gamma$ such that
\[
\fitcol{
\|e_k\| + \|\tilde\theta_k\| \le \beta(\|e_0\|+\|\tilde\theta_0\|,k)
 + \gamma\!\Big(\sup_{0\le j<k}\|d_j\|\Big).
}
\]
If $d_k\!\to\!0$ then $(e_k,\tilde\theta_k)\!\to\!0$; if $d_k$ is bounded, both remain bounded.
\end{theorem*}

\begin{proof}
Combine Lemmas~\ref{lem:onestep-corrected} and \ref{lem:coupled}:
\[
\fitcol{
W_{k+1} \le (1-\mu+c_1L_A^2\rho^2)V(e_k)
 + c_d\|d_k\|^2 + \alpha((1-\eta)\|\tilde\theta_k\|^2+c_\theta\|e_k\|^2).
}
\]
Select $\alpha$ small enough that the $\|e_k\|^2$ coefficient is negative.
Then $W_{k+1}-W_k \le -\varepsilon V(e_k) - \alpha\eta\|\tilde\theta_k\|^2 + c_d\|d_k\|^2$,
which is an ISS Lyapunov inequality; the discrete ISS theorem (Sontag–Wang, 1995)
implies the stated bound.
\end{proof}

\paragraph{Interpretation.}
The augmented system $(e_k,\tilde\theta_k)$ is input–to–state stable:
with small per-step parameter change $\rho$ and bounded noise $d_k$, both errors remain bounded,
and they converge when disturbances vanish. The scaling $R_S=k_i\sigma_a\tau^3$ does not destabilize
the filter—it maintains uniform stability across sea states.

\subsection*{How to verify the CQLF (A6) in practice}
Discretize a grid of $(\sigma_a,\tau)$ in $\Theta$ and solve
\[
A(\theta_i)^\top P A(\theta_i) \preceq (1-\mu)P, \qquad P\succ0
\]
for a common $P,\mu$ using an LMI solver (e.g.\ \texttt{feasp}, \texttt{CVX}, or \texttt{YALMIP}/\texttt{MOSEK}).
If infeasible: (i) narrow $\Theta$; (ii) raise $R_S$ floors; (iii) slow adaptation (reduce $\rho$);
or (iv) allow a parameter-dependent $P(\theta)$ (LPV approach).

\subsection*{Implementation checklist (A1–A8)}
\begin{enumerate}\itemsep2pt
\item Projection: enforce $\hat\sigma_a\!\in[\underline\sigma,\overline\sigma]$,
$\hat\tau\!\in[\underline\tau,\overline\tau]$.
\item Rate limit: clamp $\|\theta_{k+1}-\theta_k\|\!\le\!\rho<\rho^\star$.
\item Noise floors: keep $Q\succeq q_{\min}I$, $R,R_S\succeq r_{\min}I$.
\item Timescale separation: update $(\hat\sigma_a,\hat\tau)$ slower than $(v,p,S)$ filter.
\item Anisotropy: $R_S=\mathrm{diag}(k_x,k_y,k_z)\sigma_a\tau^3$ with $k_x,k_y\!\ll\!k_z$.
\end{enumerate}

\section*{Appendix: Why $R_S \propto \sigma_a \tau^3$ (Dimensional and Energy Justification)}
\label{app:rs-scaling}

\paragraph{Notation and units.}
$a_w$ is OU with std.\ $\sigma_a$ and correlation $\tau$,
\[
\fitcol{
\dot a_w = -\tfrac{1}{\tau}a_w + \sqrt{q_c}\,w, \qquad q_c = \tfrac{2\sigma_a^2}{\tau}.
}
\]
The chain $\dot v=a_w,\;\dot p=v,\;\dot S=p$ implies $S$ is the triple time integral of $a_w$.
$R_S$ is treated as a standard deviation ($R_S^2$ used in covariance).

\begin{lemma}[Dimensional scaling]\label{lem:dim}
Typical magnitude over one $\tau$: $\|S\|_{\text{typ}}=\mathcal{O}(\sigma_a\tau^3)$.
\end{lemma}

\begin{proof}
Each integration multiplies by $\tau$: $v\sim\sigma_a\tau$, $p\sim\sigma_a\tau^2$, $S\sim\sigma_a\tau^3$.
\end{proof}

\paragraph{Spectral justification.}
PSD of $a_w$: $S_a(\omega)=\tfrac{2\sigma_a^2\tau}{1+\omega^2\tau^2}$.
Transfer $H_S(j\omega)=1/(j\omega)^3$; with cutoff $\omega_{\min}\!\sim\!1/\tau$,
\[
\fitcol{
\operatorname{Var}[S] \approx \tfrac{1}{2\pi}\!\int_{1/\tau}^{\infty}\!\!\frac{2\sigma_a^2\tau}{(1+\omega^2\tau^2)\omega^6}d\omega
\;=\;\Theta(\sigma_a^2\tau^6).
}
\]
Hence $\mathrm{std}(S)\sim C\,\sigma_a\tau^3$ with $C\!=\!\sqrt{1/(5\pi)}$.

\paragraph{Result.}
Choosing
\[
R_S = k_i\sigma_a\tau^3
\quad\Longleftrightarrow\quad
R_S^2 = k_i^2\sigma_a^2\tau^6
\]
makes the innovation SNR roughly invariant to sea-state energy or correlation length,
consistent with the discrete $Q_d^{(1)}$ scaling derived in Sec.~\ref{sec:analytic}.
