\section{Lyapunov / ISS Stability of the Adaptive Law $R_S \propto \sigma_a \tau^3$}
\label{sec:lyap-iss}

We establish input–to–state stability (ISS) of the estimation error under the adaptive
pseudo-measurement weighting
\[
R_S(\theta) = \mathrm{diag}(r_{Sx}, r_{Sy}, r_{Sz}), \qquad
r_{Si} = k_i\;\sigma_a\,\tau^3,
\]
where $\theta \!=\! (\sigma_a,\tau)$ are adapted online and $k_i>0$ are fixed anisotropy
coefficients (possibly $k_x,k_y \ll k_z$).
We analyze the extended Q–MEKF linearized about the operating point after attitude
lock (Sec.~\ref{sec:analytic}, \ref{sec:quat}), focusing on the translational OU chain
\(
\dot v = a_w,\;\dot p = v,\;\dot S = p,\;\dot a_w = -(1/\tau)a_w + \sqrt{q_c}\,w
\),
with $q_c=2\sigma_a^2/\tau$. The complete estimator uses Joseph updates and PSD projection
(Sec.~\ref{sec:cross-cov}).

\subsection*{Assumptions}
\begin{itemize}\itemsep2pt
\item[A1] \textbf{Bounded sampling and small linearization error.}
Sampling $h \in (0,\bar h]$ such that the discrete transition $\Phi(h,\tau)$ matches the analytic form
(Sec.~\ref{sec:analytic}); linearization error is Lipschitz on the compact set considered.
\item[A2] \textbf{Noise bounds.}
Gyro, accelerometer, magnetometer, and pseudo-measurement noises satisfy
$\|n_g\|,\|n_a\|,\|n_m\|,\|n_S\| \le \bar n$; the OU driver $w$ has finite second moment on each interval.
\item[A3] \textbf{Parameter compactness via projection.}
\[
\Theta \;=\; \{(\sigma_a,\tau)\;:\;\underline\sigma \le \sigma_a \le \overline\sigma,\;
\underline\tau \le \tau \le \overline\tau\},
\]
enforced by a projection $\Pi_\Theta(\cdot)$.
\item[A4] \textbf{Rate-limited adaptation.} There exists $\rho>0$ such that
$\|\theta_{k+1}-\theta_k\|\le \rho$ for all $k$ (per-step clamp/rate limit).
\item[A5] \textbf{Smooth dependence.}
$\Phi(\theta)$ and $K(\theta)$ are Lipschitz on $\Theta$ with constants $L_\Phi,L_K$.
\item[A6] \textbf{CQLF for the frozen closed loop.}
Let $A(\theta):=\Phi(\theta)-K(\theta)C\,\Phi(\theta)$. There exist $P\succ 0$ and $\mu\in(0,1)$ such that
\begin{equation}
\label{eq:cqlf}
A(\theta)^\top P\,A(\theta) \;\preceq\; (1-\mu)\,P \qquad \forall\,\theta\in\Theta .
\end{equation}
\end{itemize}

\noindent
We write the stacked estimation error $e := x-x^\star$ for the linear translational
subsystem (including $a_w$), with $x^\star$ the true OU-driven state. Let
$\tilde\theta := \hat\theta - \theta^\star$ denote parameter error relative to the
ideal stationary values $(\sigma_a^\star,\tau^\star)$ for the current sea-state.
Disturbances $d_k$ aggregate process/measurement noise, linearization residue, and bounded coupling from attitude.

\begin{lemma}[Parameter-variation mismatch bound]\label{lem:delta}
Let $A(\theta)=\Phi(\theta)-K(\theta)C\Phi(\theta)$ and assume \textup{A4–A5}.
Then for $\Delta_k := A(\theta_{k+1})-A(\theta_k)$,
\[
\|\Delta_k\| \;\le\; \Big(L_\Phi + L_K\,\|C\|\,\|\Phi\| + \|K\|\,\|C\|\,L_\Phi\Big)\,\rho \;=:\; L_A\,\rho .
\]
\end{lemma}

\begin{proof}
By mean-value expansion on $\Phi$ and $K$ over the compact $\Theta$ and the triangle inequality.
\end{proof}

\begin{lemma}[One-step Lyapunov decrement with perturbation]\label{lem:onestep}
Under \textup{A1–A6}, with $V(e)=e^\top P e$ and $P,\mu$ as in \eqref{eq:cqlf}, the true
time-varying error update
\[
e_{k+1} \;=\; A(\theta_k)e_k \;+\; \Delta_k e_k \;+\; d_k
\]
satisfies
\[
V(e_{k+1})-V(e_k) \;\le\; -\tfrac{\mu}{4}\,e_k^\top P e_k \;+\; c_d \|d_k\|^2
\]
for all $k$ provided $\rho<\rho^\star:=\sqrt{\mu/(4c_1)}/L_A$, where $c_1,c_d>0$
depend on $P$ and uniform bounds on $A(\theta)$ on $\Theta$.
\end{lemma}

\begin{proof}
Expand
\[
\Delta V_k \!=\! e_k^\top\!(A^\top P A - P)e_k
+ 2 e_k^\top A^\top P (\Delta_k e_k + d_k) + \|\Delta_k e_k + d_k\|_{P}^2 .
\]
Use \eqref{eq:cqlf} for the first term, the inequality $2x^\top Py \le \eta x^\top P x + \eta^{-1}y^\top P y$
with $\eta=\mu/2$, and Lemma~\ref{lem:delta} for $\|\Delta_k\|$. Collect constants to get
\[
\Delta V_k \;\le\; -\tfrac{\mu}{2} e_k^\top P e_k + c_1 \|\Delta_k\|^2 e_k^\top P e_k + c_d \|d_k\|^2.
\]
Impose $\|\Delta_k\|\le L_A \rho < \sqrt{\mu/(4c_1)}$ to obtain the stated bound.
\end{proof}

\begin{theorem*}[ISS of the adaptive estimator]\label{thm:iss}
Under \textup{A1–A6} with $\rho<\rho^\star$, there exist class-$\mathcal{KL}$
and class-$\mathcal{K}$ functions $\beta,\gamma$ such that
\[
\|e_k\| \;\le\; \beta(\|e_0\|,k) \;+\; \gamma\!\left(\sup_{0\le j<k}\|d_j\|\right).
\]
In particular, if $d_k\!\to\!0$ then $e_k\!\to\!0$; if $d_k$ is bounded, then $e_k$ is bounded.
\end{theorem*}

\begin{proof}
Lemma~\ref{lem:onestep} yields a discrete Lyapunov ISS difference inequality for $V(e)=e^\top P e$.
Standard discrete-time ISS Lyapunov theorems (Sontag–Wang; Jiang–Mareels) give the bound with
$\beta(r,k)=\sqrt{\tfrac{\lambda_{\max}(P)}{\lambda_{\min}(P)}}\,(1-\mu/4)^{k/2}r$
and $\gamma(s)=\sqrt{\tfrac{c_d}{\lambda_{\min}(P)\,\mu/4}}\,s$ (up to constants).
\end{proof}

\paragraph{What ISS means and what this guarantees.}
A discrete-time system $x_{k+1}=f(x_k,u_k)$ is \emph{ISS} if there exist class-$\mathcal{KL}$
and class-$\mathcal{K}$ functions $\beta,\gamma$ with
$\|x_k\| \le \beta(\|x_0\|,k) + \gamma(\sup_{0\le j<k}\|u_j\|)$:
the homogeneous response decays geometrically and the forced response is bounded by the input size.
Here, the “input” is the aggregate disturbance $d_k$ (sensor/process noise, linearization residue),
while parameter adaptation appears only via the rate limit $\rho$ that is absorbed into the
Lyapunov decrement condition. The theorem guarantees:
(i) the adaptive $R_S=k\,\sigma_a\tau^3$ law cannot destabilize the estimator if the per-step
parameter change is small enough; (ii) error transients decay exponentially when disturbances cease;
(iii) with bounded disturbances, estimation errors remain bounded uniformly over all
$\theta\in\Theta$.

\paragraph{Why the $R_S\!\propto\!\sigma_a\tau^3$ scaling is Lyapunov-compatible.}
The OU driver injects variance into the triple-integrator chain in proportion to
$\sigma_a^2$ and powers of $\tau$ (Sec.~\ref{sec:analytic}). Choosing
$R_S^{-1} \propto (\sigma_a\tau^3)^{-1}$ preserves the balance between process-noise
energy injection and correction gain across changing sea states, which helps a single
$P\succ 0$ satisfy \eqref{eq:cqlf} uniformly on $\Theta$.

\subsection*{How to verify the CQLF in practice}
To check Assumption~A6, discretize a grid of $(\sigma_a,\tau)$ corners in $\Theta$ and solve the LMIs
\[
A(\theta_i)^\top P A(\theta_i) \preceq (1-\mu)P,\qquad P\succ0
\]
for a single $P,\mu$. If feasible on the grid (and $A(\theta)$ is smooth), this certifies
\eqref{eq:cqlf} on $\Theta$. If infeasible, tighten $\Theta$ (projection clamps), increase
measurement margins (e.g., floors on $R_S$), or slow adaptation (reduce $\rho$) until feasible.

\subsection*{Implementation checklist (matching A1–A6)}
\begin{enumerate}\itemsep2pt
\item \textbf{Projection (A3):} enforce $\hat\sigma_a\!\in[\underline\sigma,\overline\sigma]$,
$\hat\tau\!\in[\underline\tau,\overline\tau]$.
\item \textbf{Rate limit (A4):} clamp $\|\theta_{k+1}-\theta_k\| \le \rho$; choose $\rho<\rho^\star$ from Lemma~\ref{lem:onestep}.
\item \textbf{Noise floors:} keep $Q \succeq q_{\min}I$, $R,R_S \succeq r_{\min}I$ for uniform PD innovation covariances.
\item \textbf{Timescale separation:} update $(\hat\sigma_a,\hat\tau)$ slower than the $(v,p,S)$ Kalman time constant.
\item \textbf{Anisotropy:} $R_S=\mathrm{diag}(k_x,k_y,k_z)\,\sigma_a\tau^3$ with $k_x,k_y\!\ll\!k_z$ is admissible; the proof is unchanged.
\end{enumerate}

