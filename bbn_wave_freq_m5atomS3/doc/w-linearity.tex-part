% =====================================================
\section{Linearity and the Matrix Exponential}
\label{sec:linearity}

The Kalman filter prediction step requires mapping a continuous-time
stochastic differential equation (SDE)
\[
\dot x(t) = F(t)x(t) + G(t)w(t),
\]
to its discrete-time equivalent over a finite sampling interval $h$.
This section explains why our process model is \emph{locally linear time-invariant (LTI)}
within one integration step,
why the state transition matrix is the matrix exponential $\Phi = e^{Fh}$,
and how the discrete covariance $Q_d$ arises from the continuous-time noise density $Q_c$.

% -----------------------------------------------------
\subsection{Local Linearity and the Piecewise-Constant Assumption}
\label{sec:local_lti}

Within each sampling interval $[t_k,t_k+h]$, the quantities
$\omega_m$, $b_g$, $\tau$, and $Q_c$ can be assumed constant:
the IMU sampling rate ($100$--$400\,$Hz) is orders of magnitude faster than
the bias and wave parameter variation.
Under this assumption, the system reduces to
\[
\dot x = F x + G w, \qquad w \sim \mathcal{N}(0,Q_c),
\]
with constant $(F,G,Q_c)$ on that interval.
The solution is therefore the LTI system response
\[
x(t_k+h) = e^{Fh}x(t_k)
  + \int_0^h e^{F(h-s)}G\,w(s)\,ds.
\]
This motivates defining the discrete state transition matrix
\[
\Phi = e^{Fh}.
\]

This assumption yields first-order accuracy in $h$ (local truncation error $O(h^2)$),
adequate for high-rate inertial propagation.

% -----------------------------------------------------
\subsection{Matrix Exponential as the Unique LTI Propagator}
\label{sec:matrix_exponential}

For $\dot x = F x$ with constant $F$ and initial condition $x(0)=x_0$,
Picard iteration gives
\[
x(t) = \sum_{k=0}^{\infty} \frac{t^k}{k!}F^k x_0,
\]
which is recognized as the matrix exponential
\[
e^{F t} = I + Ft + \tfrac{1}{2!}F^2 t^2 + \tfrac{1}{3!}F^3 t^3 + \cdots.
\]
The matrix exponential is the unique operator satisfying
$\frac{d}{dt}e^{Ft} = F e^{Ft}$ and $e^{F0}=I$.

Our system matrix $F$ is block lower-triangular:
\[
F = 
\begin{bmatrix}
F_\text{att} & 0 & 0\\
F_{\text{coupl}} & F_\text{lin} & 0\\
0 & 0 & F_\text{bias}
\end{bmatrix}.
\]
Hence $e^{Fh}$ preserves this structure,
\[
e^{Fh} =
\begin{bmatrix}
e^{F_\text{att}h} & 0 & 0\\
* & e^{F_\text{lin}h} & 0\\
0 & 0 & e^{F_\text{bias}h}
\end{bmatrix},
\]
allowing $\Phi_\text{att}$ and $\Phi_\text{lin}$ to be computed
independently for the attitude and OU-driven kinematic subsystems.

% -----------------------------------------------------
\subsection{Derivation of the Discrete Covariance}
\label{sec:discrete_covariance}

The continuous-time covariance $P(t)=\mathbb{E}[x x^\top]$
obeys the Lyapunov equation
\[
\dot P = F P + P F^\top + G Q_c G^\top.
\]
Integrating from $t_k$ to $t_k+h$ yields
\[
P_{k+1|k} = e^{Fh} P_{k|k} e^{F^\top h} + Q_d,
\]
where the discrete process covariance is
\begin{equation}
Q_d = \int_0^h e^{F(h-s)}\,G Q_c G^\top\,e^{F^\top(h-s)}\,ds.
\label{eq:Qd_integral}
\end{equation}
This integral is exact for constant $F$, $G$, and $Q_c$.

We present three mathematically equivalent routes to compute $Q_d$.

\paragraph{1) Van Loan augmentation (general, robust)}
Form the augmented $2n\times 2n$ matrix
\[
\mathcal{A} =
\begin{bmatrix}
 -F & G Q_c G^\top \\[3pt]
  0 & F^\top
\end{bmatrix},
\qquad
e^{\mathcal{A}h} =
\begin{bmatrix}
 * & Q_d \\[3pt]
  0 & *
\end{bmatrix}.
\]
This identity (Van Loan, 1978) directly yields $Q_d$.
It is numerically stable for small to medium systems
when computed via scaling–squaring with Padé approximation.
For large sparse systems, we use the analytic block method below.

\paragraph{2) Analytic axis-wise integration}
For the OU-driven 4-state axis subsystem
$x_\text{axis}=[v,p,S,a_w]^\top$ with
\[
\dot x_\text{axis}=F_\text{axis} x_\text{axis} + G_\text{axis}\eta_a,
\]
we substitute $F_\text{axis}$ and $G_\text{axis}$ and
integrate \eqref{eq:Qd_integral} in closed form.
The resulting expressions yield the coefficients
$A_1(h/\tau)$ and $A_2(h/\tau)$ used in
Section~\ref{sec:ou_discretization}.
This method exploits the sparsity and identical structure of each axis.

\paragraph{3) Maclaurin small-step series}
For small $x=h/\tau$, $e^{-x}\approx1-x+\tfrac{1}{2}x^2-\tfrac{1}{6}x^3+\dots$
causes cancellation in \eqref{eq:Qd_integral}.
Expanding $\Phi=e^{Fh}$ and the integral directly in $x$
and retaining terms up to $O(x^5)$
avoids catastrophic loss of precision.
These series are used in our implementation when $x<10^{-2}$.

\begin{lemma}[Equivalence of formulations]
For constant $(F,G,Q_c)$,
the Van Loan, analytic, and series formulations of $Q_d$ are mathematically identical.
\end{lemma}
\begin{proof}[Sketch]
Differentiate \eqref{eq:Qd_integral} with respect to $h$ and show that each
formulation satisfies the same differential Lyapunov equation
$\dot Q_d = F Q_d + Q_d F^\top + G Q_c G^\top$
with $Q_d(0)=0$.
\end{proof}

% -----------------------------------------------------
\subsection{Stability and Conditioning of $\Phi$}
\label{sec:stability_phi}

If all eigenvalues of $F$ satisfy $\Re(\lambda_i)\le0$,
then $\|e^{Fh}\|\le 1$ for all $h>0$.
This holds for our system because:
\begin{itemize}
  \item The OU block has eigenvalues $-1/\tau$ (strictly stable);
  \item The integrator chain has eigenvalue $0$ (marginally stable);
  \item Coupling terms are strictly lower-triangular.
\end{itemize}
Hence the overall transition $\Phi$ is stable in the discrete-time sense.
To maintain numerical symmetry,
we always enforce $Q_d\leftarrow\tfrac{1}{2}(Q_d+Q_d^\top)$
and project to the positive semidefinite cone if necessary.

% -----------------------------------------------------
\subsection{Time-Varying $F(t)$ and First-Order Accuracy}
\label{sec:time_varying_F}

When $F(t)$ varies during the step,
the exact transition is the \emph{time-ordered exponential}
\[
\Phi(t_k+h,t_k) = 
\mathcal{T}\exp\!\left(\int_{t_k}^{t_k+h}F(t)\,dt\right),
\]
which reduces to $e^{Fh}$ only if $F$ is constant.
Approximating $F(t)\!\approx\!F(t_k)$ yields a local error $O(h^2)$,
acceptable for high-rate IMU propagation.
Higher-order schemes (midpoint or Runge–Kutta integration of $F$)
are unnecessary here because measurement updates dominate discretization error.

% -----------------------------------------------------
\subsection{Units Consistency Check}
\label{sec:units_check}

Dimensional analysis confirms the formulation:
\begin{itemize}
  \item $\Phi$ is unitless (maps state to state);
  \item $Q_c$ has units of quantity$^2$ per second;
  \item $Q_d$ accumulates this over $h$ (quantity$^2$).
\end{itemize}
For example, for a random walk $\dot b=n_b$ with scalar density $q_b$,
the discrete variance is simply $Q_{d,bb}=q_b\,h$.

% -----------------------------------------------------
\subsection{Practical Implementation Summary}
\label{sec:linearity_summary}

\begin{itemize}
  \item For attitude/bias: compute $\Phi_\text{att}=e^{F_\text{att}h}$ via Rodrigues formula for constant angular rate.
  \item For OU-driven kinematics: use the analytic $4\times4$ formulas
        $\Phi_{\text{axis}}, Q_{d,\text{axis}}$ (next section) with Maclaurin fallback.
  \item After each propagation: symmetrize and project $Q_d$ to PSD;
        use Joseph form in covariance update for guaranteed positive semidefiniteness.
\end{itemize}

\vspace{1ex}
The next section derives the closed-form expressions
for $\Phi_{\text{axis}}$ and $Q_{d,\text{axis}}$
used to discretize the OU-driven kinematic chain.

\noindent\textbf{References:}
\cite{jazwinski1970,vanloan1978integrating,maybeck1979,crassidis2012}.
